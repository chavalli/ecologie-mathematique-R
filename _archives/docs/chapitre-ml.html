<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>11 Introduction à l’autoapprentissage | Analyse et modélisation d’agroécosystèmes</title>
  <meta name="description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe." />
  <meta name="generator" content="bookdown 0.18 and GitBook 2.6.7" />

  <meta property="og:title" content="11 Introduction à l’autoapprentissage | Analyse et modélisation d’agroécosystèmes" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="11 Introduction à l’autoapprentissage | Analyse et modélisation d’agroécosystèmes" />
  
  <meta name="twitter:description" content="Ce cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe." />
  

<meta name="author" content="Serge-Étienne Parent" />


<meta name="date" content="2020-04-30" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chapitre-outliers.html"/>
<link rel="next" href="chapitre-temps.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.2.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.0.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.0.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.52.2/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.52.2/plotly-latest.min.js"></script>
<script src="libs/viz-1.8.2/viz.js"></script>
<link href="libs/DiagrammeR-styles-0.2/styles.css" rel="stylesheet" />
<script src="libs/grViz-binding-1.0.5/grViz.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>
<script src="libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.3/leaflet-providers-plugin.js"></script>
<script src="libs/Leaflet.Sync-0.0.5/L.Map.Sync.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a><ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#définitions"><i class="fa fa-check"></i><b>1.1</b> Définitions</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#à-qui-sadresse-ce-manuel"><i class="fa fa-check"></i><b>1.2</b> À qui s’adresse ce manuel?</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#les-logiciels-libres"><i class="fa fa-check"></i><b>1.3</b> Les logiciels libres</a></li>
<li class="chapter" data-level="1.4" data-path="index.html"><a href="index.html#langage-de-programmation"><i class="fa fa-check"></i><b>1.4</b> Langage de programmation</a><ul>
<li class="chapter" data-level="1.4.1" data-path="index.html"><a href="index.html#r"><i class="fa fa-check"></i><b>1.4.1</b> R</a></li>
<li class="chapter" data-level="1.4.2" data-path="index.html"><a href="index.html#pourquoi-pas-python"><i class="fa fa-check"></i><b>1.4.2</b> Pourquoi pas Python?</a></li>
<li class="chapter" data-level="1.4.3" data-path="index.html"><a href="index.html#pourquoi-pas-matlab"><i class="fa fa-check"></i><b>1.4.3</b> Pourquoi pas Matlab?</a></li>
<li class="chapter" data-level="1.4.4" data-path="index.html"><a href="index.html#et-sas"><i class="fa fa-check"></i><b>1.4.4</b> Et… SAS?</a></li>
<li class="chapter" data-level="1.4.5" data-path="index.html"><a href="index.html#mais-pourquoi-pas-______"><i class="fa fa-check"></i><b>1.4.5</b> Mais pourquoi pas ______ ?</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="index.html"><a href="index.html#contenu-du-manuel"><i class="fa fa-check"></i><b>1.5</b> Contenu du manuel</a></li>
<li class="chapter" data-level="1.6" data-path="index.html"><a href="index.html#objectifs-généraux"><i class="fa fa-check"></i><b>1.6</b> Objectifs généraux</a></li>
<li class="chapter" data-level="1.7" data-path="index.html"><a href="index.html#lectures-complémentaires"><i class="fa fa-check"></i><b>1.7</b> Lectures complémentaires</a><ul>
<li class="chapter" data-level="1.7.1" data-path="index.html"><a href="index.html#écologie-mathématique"><i class="fa fa-check"></i><b>1.7.1</b> Écologie mathématique</a></li>
<li class="chapter" data-level="1.7.2" data-path="index.html"><a href="index.html#programmation"><i class="fa fa-check"></i><b>1.7.2</b> Programmation</a></li>
<li class="chapter" data-level="1.7.3" data-path="index.html"><a href="index.html#divers"><i class="fa fa-check"></i><b>1.7.3</b> Divers</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="index.html"><a href="index.html#besoin-daide"><i class="fa fa-check"></i><b>1.8</b> Besoin d’aide?</a></li>
<li class="chapter" data-level="1.9" data-path="index.html"><a href="index.html#à-propos-de-lauteur"><i class="fa fa-check"></i><b>1.9</b> À propos de l’auteur</a></li>
<li class="chapter" data-level="1.10" data-path="index.html"><a href="index.html#un-cours-complémentaire-à-dautres-cours"><i class="fa fa-check"></i><b>1.10</b> Un cours complémentaire à d’autres cours</a></li>
<li class="chapter" data-level="1.11" data-path="index.html"><a href="index.html#contribuer-au-manuel"><i class="fa fa-check"></i><b>1.11</b> Contribuer au manuel</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html"><i class="fa fa-check"></i><b>2</b> La science des données avec R</a><ul>
<li class="chapter" data-level="2.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#statistiques-ou-science-des-données"><i class="fa fa-check"></i><b>2.1</b> Statistiques ou science des données?</a></li>
<li class="chapter" data-level="2.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#débuter-en-r"><i class="fa fa-check"></i><b>2.2</b> Débuter en R</a></li>
<li class="chapter" data-level="2.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#préparer-son-flux-de-travail"><i class="fa fa-check"></i><b>2.3</b> Préparer son flux de travail</a><ul>
<li class="chapter" data-level="2.3.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-classique"><i class="fa fa-check"></i><b>2.3.1</b> Installation classique</a></li>
<li class="chapter" data-level="2.3.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installation-avec-anaconda"><i class="fa fa-check"></i><b>2.3.2</b> Installation avec Anaconda</a></li>
<li class="chapter" data-level="2.3.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#utilisation-infonuagique"><i class="fa fa-check"></i><b>2.3.3</b> Utilisation infonuagique</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#premiers-pas-avec-r"><i class="fa fa-check"></i><b>2.4</b> Premiers pas avec R</a><ul>
<li class="chapter" data-level="2.4.1" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#types-de-données"><i class="fa fa-check"></i><b>2.4.1</b> Types de données</a></li>
<li class="chapter" data-level="2.4.2" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-collections-de-données"><i class="fa fa-check"></i><b>2.4.2</b> Les collections de données</a></li>
<li class="chapter" data-level="2.4.3" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-fonctions"><i class="fa fa-check"></i><b>2.4.3</b> Les fonctions</a></li>
<li class="chapter" data-level="2.4.4" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#les-boucles"><i class="fa fa-check"></i><b>2.4.4</b> Les boucles</a></li>
<li class="chapter" data-level="2.4.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#conditions-if-else-if-else"><i class="fa fa-check"></i><b>2.4.5</b> Conditions: <code>if</code>, <code>else if</code>, <code>else</code></a></li>
<li class="chapter" data-level="2.4.6" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#installer-et-charger-un-module"><i class="fa fa-check"></i><b>2.4.6</b> Installer et charger un module</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#enfin"><i class="fa fa-check"></i><b>2.5</b> Enfin…</a></li>
<li class="chapter" data-level="2.6" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#petit-truc"><i class="fa fa-check"></i><b>2.6</b> Petit truc!</a></li>
<li class="chapter" data-level="2.7" data-path="chapitre-intro-a-R.html"><a href="chapitre-intro-a-R.html#extra-jupyter"><i class="fa fa-check"></i><b>2.7</b> Extra: Utiliser R avec Jupyter</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html"><i class="fa fa-check"></i><b>3</b> Organisation des données et opérations sur des tableaux</a><ul>
<li class="chapter" data-level="3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#les-collections-de-données-1"><i class="fa fa-check"></i><b>3.1</b> Les collections de données</a></li>
<li class="chapter" data-level="3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#organiser-un-tableau-de-données"><i class="fa fa-check"></i><b>3.2</b> Organiser un tableau de données</a></li>
<li class="chapter" data-level="3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#formats-de-tableau"><i class="fa fa-check"></i><b>3.3</b> Formats de tableau</a><ul>
<li class="chapter" data-level="3.3.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#xls-ou-xlsx"><i class="fa fa-check"></i><b>3.3.1</b> <em>xls</em> ou <em>xlsx</em></a></li>
<li class="chapter" data-level="3.3.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#csv"><i class="fa fa-check"></i><b>3.3.2</b> <em>csv</em></a></li>
<li class="chapter" data-level="3.3.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#json"><i class="fa fa-check"></i><b>3.3.3</b> <em>json</em></a></li>
<li class="chapter" data-level="3.3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#sqlite"><i class="fa fa-check"></i><b>3.3.4</b> SQLite</a></li>
<li class="chapter" data-level="3.3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#suggestion"><i class="fa fa-check"></i><b>3.3.5</b> Suggestion</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#entreposer-ses-données"><i class="fa fa-check"></i><b>3.4</b> Entreposer ses données</a></li>
<li class="chapter" data-level="3.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#manipuler-des-données-en-mode-tidyverse"><i class="fa fa-check"></i><b>3.5</b> Manipuler des données en mode tidyverse</a><ul>
<li class="chapter" data-level="3.5.1" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#importer-vos-données-dans-votre-session-de-travail"><i class="fa fa-check"></i><b>3.5.1</b> Importer vos données dans votre session de travail</a></li>
<li class="chapter" data-level="3.5.2" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#comment-sélectionner-et-filtrer-des-données"><i class="fa fa-check"></i><b>3.5.2</b> Comment sélectionner et filtrer des données ?</a></li>
<li class="chapter" data-level="3.5.3" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#le-format-long-et-le-format-large"><i class="fa fa-check"></i><b>3.5.3</b> Le format long et le format large</a></li>
<li class="chapter" data-level="3.5.4" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#combiner-des-tableaux"><i class="fa fa-check"></i><b>3.5.4</b> Combiner des tableaux</a></li>
<li class="chapter" data-level="3.5.5" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#opérations-sur-les-tableaux"><i class="fa fa-check"></i><b>3.5.5</b> Opérations sur les tableaux</a></li>
<li class="chapter" data-level="3.5.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exemple-difficile"><i class="fa fa-check"></i><b>3.5.6</b> Exemple (difficile)</a></li>
<li class="chapter" data-level="3.5.7" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#exporter-un-tableau"><i class="fa fa-check"></i><b>3.5.7</b> Exporter un tableau</a></li>
<li class="chapter" data-level="3.5.8" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#aller-plus-loin-dans-le-tidyverse"><i class="fa fa-check"></i><b>3.5.8</b> Aller plus loin dans le tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="chapitre-tableaux.html"><a href="chapitre-tableaux.html#références"><i class="fa fa-check"></i><b>3.6</b> Références</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html"><i class="fa fa-check"></i><b>4</b> Visualisation</a><ul>
<li class="chapter" data-level="4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#pourquoi-explorer-graphiquement"><i class="fa fa-check"></i><b>4.1</b> Pourquoi explorer graphiquement?</a></li>
<li class="chapter" data-level="4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publier-un-graphique"><i class="fa fa-check"></i><b>4.2</b> Publier un graphique</a><ul>
<li class="chapter" data-level="4.2.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#cinq-qualités-dun-bon-graphique"><i class="fa fa-check"></i><b>4.2.1</b> Cinq qualités d’un bon graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-le-type-de-graphique-le-plus-approprié"><i class="fa fa-check"></i><b>4.3</b> Choisir le type de graphique le plus approprié</a></li>
<li class="chapter" data-level="4.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#choisir-son-outil-de-visualisation"><i class="fa fa-check"></i><b>4.4</b> Choisir son outil de visualisation</a><ul>
<li class="chapter" data-level="4.4.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-impérative"><i class="fa fa-check"></i><b>4.4.1</b> Approche impérative</a></li>
<li class="chapter" data-level="4.4.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#approche-déclarative"><i class="fa fa-check"></i><b>4.4.2</b> Approche déclarative</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visualisation-en-r"><i class="fa fa-check"></i><b>4.5</b> Visualisation en R</a></li>
<li class="chapter" data-level="4.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#module-de-base-pour-les-graphiques"><i class="fa fa-check"></i><b>4.6</b> Module de base pour les graphiques</a></li>
<li class="chapter" data-level="4.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#la-grammaire-graphique-ggplot2"><i class="fa fa-check"></i><b>4.7</b> La grammaire graphique <strong><code>ggplot2</code></strong></a></li>
<li class="chapter" data-level="4.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#mon-premier-ggplot"><i class="fa fa-check"></i><b>4.8</b> Mon premier ggplot</a><ul>
<li class="chapter" data-level="4.8.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#plusieurs-sources-de-données"><i class="fa fa-check"></i><b>4.8.1</b> Plusieurs sources de données</a></li>
<li class="chapter" data-level="4.8.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-avec-style"><i class="fa fa-check"></i><b>4.8.2</b> Exporter avec style</a></li>
<li class="chapter" data-level="4.8.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#nuages-de-points"><i class="fa fa-check"></i><b>4.8.3</b> Nuages de points</a></li>
<li class="chapter" data-level="4.8.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#diagrammes-en-lignes"><i class="fa fa-check"></i><b>4.8.4</b> Diagrammes en lignes</a></li>
<li class="chapter" data-level="4.8.5" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-histogrammes"><i class="fa fa-check"></i><b>4.8.5</b> Les histogrammes</a></li>
<li class="chapter" data-level="4.8.6" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#boxplots"><i class="fa fa-check"></i><b>4.8.6</b> Boxplots</a></li>
<li class="chapter" data-level="4.8.7" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-diagrammes-en-barre"><i class="fa fa-check"></i><b>4.8.7</b> Les diagrammes en barre</a></li>
<li class="chapter" data-level="4.8.8" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#exporter-un-graphique"><i class="fa fa-check"></i><b>4.8.8</b> Exporter un graphique</a></li>
</ul></li>
<li class="chapter" data-level="4.9" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#les-graphiques-comme-outil-dexploration-des-données"><i class="fa fa-check"></i><b>4.9</b> Les graphiques comme outil d’exploration des données</a><ul>
<li class="chapter" data-level="4.9.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-graphiques-interactifs"><i class="fa fa-check"></i><b>4.9.1</b> Des graphiques interactifs!</a></li>
<li class="chapter" data-level="4.9.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#des-extensions-de-ggplot2"><i class="fa fa-check"></i><b>4.9.2</b> Des extensions de <strong><code>ggplot2</code></strong></a></li>
<li class="chapter" data-level="4.9.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#aller-plus-loin-avec-ggplot2"><i class="fa fa-check"></i><b>4.9.3</b> Aller plus loin avec <strong><code>ggplot2</code></strong></a></li>
</ul></li>
<li class="chapter" data-level="4.10" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#extra-règles-particulières"><i class="fa fa-check"></i><b>4.10</b> Extra: Règles particulières</a><ul>
<li class="chapter" data-level="4.10.1" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#ne-tronquez-pas-inutilement-laxe-des-y"><i class="fa fa-check"></i><b>4.10.1</b> Ne tronquez pas inutilement l’axe des <span class="math inline">\(y\)</span></a></li>
<li class="chapter" data-level="4.10.2" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#utilisez-un-encrage-proportionnel"><i class="fa fa-check"></i><b>4.10.2</b> Utilisez un encrage proportionnel</a></li>
<li class="chapter" data-level="4.10.3" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#publiez-vos-données"><i class="fa fa-check"></i><b>4.10.3</b> Publiez vos données</a></li>
<li class="chapter" data-level="4.10.4" data-path="chapitre-visualisation.html"><a href="chapitre-visualisation.html#visitez-www.junkcharts.typepad.com-de-temps-à-autre"><i class="fa fa-check"></i><b>4.10.4</b> Visitez www.junkcharts.typepad.com de temps à autre</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chapitre-git.html"><a href="chapitre-git.html"><i class="fa fa-check"></i><b>5</b> Science ouverte et reproductibilité</a><ul>
<li class="chapter" data-level="5.1" data-path="chapitre-git.html"><a href="chapitre-git.html#un-code-reproductible"><i class="fa fa-check"></i><b>5.1</b> Un code reproductible</a><ul>
<li class="chapter" data-level="5.1.1" data-path="chapitre-git.html"><a href="chapitre-git.html#structure-dun-projet"><i class="fa fa-check"></i><b>5.1.1</b> Structure d’un projet</a></li>
<li class="chapter" data-level="5.1.2" data-path="chapitre-git.html"><a href="chapitre-git.html#le-format-r-markdown"><i class="fa fa-check"></i><b>5.1.2</b> Le format <span>R markdown</span></a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="chapitre-git.html"><a href="chapitre-git.html#introduction-à-github"><i class="fa fa-check"></i><b>5.2</b> Introduction à GitHub</a></li>
<li class="chapter" data-level="5.3" data-path="chapitre-git.html"><a href="chapitre-git.html#introduction-à-pakrat"><i class="fa fa-check"></i><b>5.3</b> Introduction à Pakrat 📦🐀</a></li>
<li class="chapter" data-level="5.4" data-path="chapitre-git.html"><a href="chapitre-git.html#pour-terminer-le-reprex"><i class="fa fa-check"></i><b>5.4</b> Pour terminer, le <strong>reprex</strong></a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html"><i class="fa fa-check"></i><b>6</b> Biostatistiques</a><ul>
<li class="chapter" data-level="6.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#populations-et-échantillons"><i class="fa fa-check"></i><b>6.1</b> Populations et échantillons</a></li>
<li class="chapter" data-level="6.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-variables"><i class="fa fa-check"></i><b>6.2</b> Les variables</a><ul>
<li class="chapter" data-level="6.2.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-quantitatives"><i class="fa fa-check"></i><b>6.2.1</b> Variables quantitatives</a></li>
<li class="chapter" data-level="6.2.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#variables-qualitatives"><i class="fa fa-check"></i><b>6.2.2</b> Variables qualitatives</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-probabilités"><i class="fa fa-check"></i><b>6.3</b> Les probabilités</a></li>
<li class="chapter" data-level="6.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-distributions"><i class="fa fa-check"></i><b>6.4</b> Les distributions</a><ul>
<li class="chapter" data-level="6.4.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-binomiale"><i class="fa fa-check"></i><b>6.4.1</b> Distribution binomiale</a></li>
<li class="chapter" data-level="6.4.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-de-poisson"><i class="fa fa-check"></i><b>6.4.2</b> Distribution de Poisson</a></li>
<li class="chapter" data-level="6.4.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-uniforme"><i class="fa fa-check"></i><b>6.4.3</b> Distribution uniforme</a></li>
<li class="chapter" data-level="6.4.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#distribution-normale"><i class="fa fa-check"></i><b>6.4.4</b> Distribution normale</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#statistiques-descriptives"><i class="fa fa-check"></i><b>6.5</b> Statistiques descriptives</a></li>
<li class="chapter" data-level="6.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-dhypothèses-à-un-et-deux-échantillons"><i class="fa fa-check"></i><b>6.6</b> Tests d’hypothèses à un et deux échantillons</a><ul>
<li class="chapter" data-level="6.6.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-t-à-un-seul-échantillon"><i class="fa fa-check"></i><b>6.6.1</b> Test de t à un seul échantillon</a></li>
<li class="chapter" data-level="6.6.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#attention-mauvaises-interprétations-des-p-values"><i class="fa fa-check"></i><b>6.6.2</b> Attention: mauvaises interprétations des <em>p-values</em></a></li>
<li class="chapter" data-level="6.6.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#test-de-wilcoxon-à-un-seul-échantillon"><i class="fa fa-check"></i><b>6.6.3</b> Test de Wilcoxon à un seul échantillon</a></li>
<li class="chapter" data-level="6.6.4" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-t-à-deux-échantillons"><i class="fa fa-check"></i><b>6.6.4</b> Tests de t à deux échantillons</a></li>
<li class="chapter" data-level="6.6.5" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#comparaison-des-variances"><i class="fa fa-check"></i><b>6.6.5</b> Comparaison des variances</a></li>
<li class="chapter" data-level="6.6.6" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#tests-de-wilcoxon-à-deux-échantillons"><i class="fa fa-check"></i><b>6.6.6</b> Tests de Wilcoxon à deux échantillons</a></li>
<li class="chapter" data-level="6.6.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-tests-pairés"><i class="fa fa-check"></i><b>6.6.7</b> Les tests pairés</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#lanalyse-de-variance"><i class="fa fa-check"></i><b>6.7</b> L’analyse de variance</a></li>
<li class="chapter" data-level="6.8" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#les-modèles-statistiques"><i class="fa fa-check"></i><b>6.8</b> Les modèles statistiques</a><ul>
<li class="chapter" data-level="6.8.1" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modèles-à-effets-fixes"><i class="fa fa-check"></i><b>6.8.1</b> Modèles à effets fixes</a></li>
<li class="chapter" data-level="6.8.2" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#modèles-à-effets-mixtes"><i class="fa fa-check"></i><b>6.8.2</b> Modèles à effets mixtes</a></li>
<li class="chapter" data-level="6.8.3" data-path="chapitre-biostats.html"><a href="chapitre-biostats.html#aller-plus-loin"><i class="fa fa-check"></i><b>6.8.3</b> Aller plus loin</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html"><i class="fa fa-check"></i><b>7</b> Introduction à l’analyse bayésienne en écologie</a><ul>
<li class="chapter" data-level="7.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#quest-ce-que-cest"><i class="fa fa-check"></i><b>7.1</b> Qu’est-ce que c’est?</a></li>
<li class="chapter" data-level="7.2" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pourquoi-lutiliser"><i class="fa fa-check"></i><b>7.2</b> Pourquoi l’utiliser?</a></li>
<li class="chapter" data-level="7.3" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#comment-lutiliser"><i class="fa fa-check"></i><b>7.3</b> Comment l’utiliser?</a></li>
<li class="chapter" data-level="7.4" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#faucons-pélerins"><i class="fa fa-check"></i><b>7.4</b> Faucons pélerins</a></li>
<li class="chapter" data-level="7.5" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#statistiques-dune-population"><i class="fa fa-check"></i><b>7.5</b> Statistiques d’une population</a><ul>
<li class="chapter" data-level="7.5.1" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#calcul-analytique"><i class="fa fa-check"></i><b>7.5.1</b> Calcul analytique</a></li>
<li class="chapter" data-level="7.5.2" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#greta"><i class="fa fa-check"></i><b>7.5.2</b> greta</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#test-de-t-différence-entre-des-groupes"><i class="fa fa-check"></i><b>7.6</b> Test de t: Différence entre des groupes</a></li>
<li class="chapter" data-level="7.7" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#modélisation-multiniveau"><i class="fa fa-check"></i><b>7.7</b> Modélisation multiniveau</a></li>
<li class="chapter" data-level="7.8" data-path="chapitre-biostats-bayes.html"><a href="chapitre-biostats-bayes.html#pour-aller-plus-loin"><i class="fa fa-check"></i><b>7.8</b> Pour aller plus loin</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html"><i class="fa fa-check"></i><b>8</b> Explorer R</a><ul>
<li class="chapter" data-level="8.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-sur-le-web"><i class="fa fa-check"></i><b>8.1</b> R sur le web</a><ul>
<li class="chapter" data-level="8.1.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#github"><i class="fa fa-check"></i><b>8.1.1</b> GitHub</a></li>
<li class="chapter" data-level="8.1.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#twitter"><i class="fa fa-check"></i><b>8.1.2</b> Twitter</a></li>
<li class="chapter" data-level="8.1.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#nouvelles"><i class="fa fa-check"></i><b>8.1.3</b> Nouvelles</a></li>
<li class="chapter" data-level="8.1.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#des-questions"><i class="fa fa-check"></i><b>8.1.4</b> Des questions?</a></li>
<li class="chapter" data-level="8.1.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#participer"><i class="fa fa-check"></i><b>8.1.5</b> Participer</a></li>
<li class="chapter" data-level="8.1.6" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#mise-en-garde"><i class="fa fa-check"></i><b>8.1.6</b> Mise en garde</a></li>
<li class="chapter" data-level="8.1.7" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#prendre-tout-ça-en-note"><i class="fa fa-check"></i><b>8.1.7</b> Prendre tout ça en note</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#r-en-chaire-et-en-os"><i class="fa fa-check"></i><b>8.2</b> R en chaire et en os</a></li>
<li class="chapter" data-level="8.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#quelques-outils-en-écologie-mathématique-avec-r"><i class="fa fa-check"></i><b>8.3</b> Quelques outils en écologie mathématique avec R</a><ul>
<li class="chapter" data-level="8.3.1" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#prétraitement-des-données"><i class="fa fa-check"></i><b>8.3.1</b> Prétraitement des données</a></li>
<li class="chapter" data-level="8.3.2" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#acquérir-des-données-météo"><i class="fa fa-check"></i><b>8.3.2</b> Acquérir des données météo</a></li>
<li class="chapter" data-level="8.3.3" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#pédométrie-avec-r"><i class="fa fa-check"></i><b>8.3.3</b> Pédométrie avec R</a></li>
<li class="chapter" data-level="8.3.4" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#méta-analyses-en-r"><i class="fa fa-check"></i><b>8.3.4</b> Méta-analyses en R</a></li>
<li class="chapter" data-level="8.3.5" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#créer-des-applications-avec-r"><i class="fa fa-check"></i><b>8.3.5</b> Créer des applications avec R</a></li>
<li class="chapter" data-level="8.3.6" data-path="chapitre-explorer.html"><a href="chapitre-explorer.html#travailler-en-python"><i class="fa fa-check"></i><b>8.3.6</b> Travailler en Python</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html"><i class="fa fa-check"></i><b>9</b> Association, partitionnement et ordination</a><ul>
<li class="chapter" data-level="9.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#espaces-danalyse"><i class="fa fa-check"></i><b>9.1</b> Espaces d’analyse</a><ul>
<li class="chapter" data-level="9.1.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#abondance-et-occurence"><i class="fa fa-check"></i><b>9.1.1</b> Abondance et occurence</a></li>
<li class="chapter" data-level="9.1.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#environnement"><i class="fa fa-check"></i><b>9.1.2</b> Environnement</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#analyse-dassociation"><i class="fa fa-check"></i><b>9.2</b> Analyse d’association</a><ul>
<li class="chapter" data-level="9.2.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#association-entre-objets-mode-q"><i class="fa fa-check"></i><b>9.2.1</b> Association entre objets (mode Q)</a></li>
<li class="chapter" data-level="9.2.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#associations-entre-variables-mode-r"><i class="fa fa-check"></i><b>9.2.2</b> Associations entre variables (mode R)</a></li>
<li class="chapter" data-level="9.2.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-les-associations"><i class="fa fa-check"></i><b>9.2.3</b> Conclusion sur les associations</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement"><i class="fa fa-check"></i><b>9.3</b> Partitionnement</a><ul>
<li class="chapter" data-level="9.3.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#évaluation-dun-partitionnement"><i class="fa fa-check"></i><b>9.3.1</b> Évaluation d’un partitionnement</a></li>
<li class="chapter" data-level="9.3.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-non-hiérarchique"><i class="fa fa-check"></i><b>9.3.2</b> Partitionnement non hiérarchique</a></li>
<li class="chapter" data-level="9.3.3" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hiérarchique"><i class="fa fa-check"></i><b>9.3.3</b> Partitionnement hiérarchique</a></li>
<li class="chapter" data-level="9.3.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#partitionnement-hiérarchique-basée-sur-la-densité-des-points"><i class="fa fa-check"></i><b>9.3.4</b> Partitionnement hiérarchique basée sur la densité des points</a></li>
<li class="chapter" data-level="9.3.5" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#conclusion-sur-le-partitionnement"><i class="fa fa-check"></i><b>9.3.5</b> Conclusion sur le partitionnement</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination"><i class="fa fa-check"></i><b>9.4</b> Ordination</a><ul>
<li class="chapter" data-level="9.4.1" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-non-contraignante"><i class="fa fa-check"></i><b>9.4.1</b> Ordination non contraignante</a></li>
<li class="chapter" data-level="9.4.2" data-path="chapitre-ordination.html"><a href="chapitre-ordination.html#ordination-contraignante"><i class="fa fa-check"></i><b>9.4.2</b> Ordination contraignante</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html"><i class="fa fa-check"></i><b>10</b> Détection de valeurs aberrantes et imputation de données manquantes</a><ul>
<li class="chapter" data-level="10.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#données-manquantes-définition-origine-typologie-et-traitement"><i class="fa fa-check"></i><b>10.1</b> Données manquantes: définition, origine, typologie et traitement</a><ul>
<li class="chapter" data-level="10.1.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#définition"><i class="fa fa-check"></i><b>10.1.1</b> Définition</a></li>
<li class="chapter" data-level="10.1.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#origines-des-données-manquantes"><i class="fa fa-check"></i><b>10.1.2</b> Origines des données manquantes</a></li>
<li class="chapter" data-level="10.1.3" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#profils-des-données-manquantes"><i class="fa fa-check"></i><b>10.1.3</b> Profils des données manquantes</a></li>
<li class="chapter" data-level="10.1.4" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#traitement-des-données-manquantes"><i class="fa fa-check"></i><b>10.1.4</b> Traitement des données manquantes</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#valeurs-et-échantillons-aberrants-définition-origines-méthodes-de-détection-et-traitement"><i class="fa fa-check"></i><b>10.2</b> Valeurs et échantillons aberrants: définition, origines, méthodes de détection et traitement</a><ul>
<li class="chapter" data-level="10.2.1" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#définitions-1"><i class="fa fa-check"></i><b>10.2.1</b> Définitions</a></li>
<li class="chapter" data-level="10.2.2" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#origines"><i class="fa fa-check"></i><b>10.2.2</b> Origines</a></li>
<li class="chapter" data-level="10.2.3" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#détection-et-traitement-des-valeurs-aberrantes-univariés"><i class="fa fa-check"></i><b>10.2.3</b> Détection et traitement des valeurs aberrantes univariés</a></li>
<li class="chapter" data-level="10.2.4" data-path="chapitre-outliers.html"><a href="chapitre-outliers.html#détection-et-traitement-des-échantillons-aberrants-multivariés"><i class="fa fa-check"></i><b>10.2.4</b> Détection et traitement des échantillons aberrants multivariés</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chapitre-ml.html"><a href="chapitre-ml.html"><i class="fa fa-check"></i><b>11</b> Introduction à l’autoapprentissage</a><ul>
<li class="chapter" data-level="11.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lexique"><i class="fa fa-check"></i><b>11.1</b> Lexique</a></li>
<li class="chapter" data-level="11.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#démarche"><i class="fa fa-check"></i><b>11.2</b> Démarche</a><ul>
<li class="chapter" data-level="11.2.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#prétraitement"><i class="fa fa-check"></i><b>11.2.1</b> Prétraitement</a></li>
<li class="chapter" data-level="11.2.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#entraînement-et-test"><i class="fa fa-check"></i><b>11.2.2</b> Entraînement et test</a></li>
<li class="chapter" data-level="11.2.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#sousapprentissage-et-surapprentissage"><i class="fa fa-check"></i><b>11.2.3</b> Sousapprentissage et surapprentissage</a></li>
<li class="chapter" data-level="11.2.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#validation-croisée"><i class="fa fa-check"></i><b>11.2.4</b> Validation croisée</a></li>
<li class="chapter" data-level="11.2.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#choix-de-lalgorithme-dapprentissage"><i class="fa fa-check"></i><b>11.2.5</b> Choix de l’algorithme d’apprentissage</a></li>
<li class="chapter" data-level="11.2.6" data-path="chapitre-ml.html"><a href="chapitre-ml.html#déploiement"><i class="fa fa-check"></i><b>11.2.6</b> Déploiement</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#lautoapprentissage-en-r"><i class="fa fa-check"></i><b>11.3</b> L’autoapprentissage en R</a></li>
<li class="chapter" data-level="11.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#algorithmes"><i class="fa fa-check"></i><b>11.4</b> Algorithmes</a><ul>
<li class="chapter" data-level="11.4.1" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-k-plus-proches-voisins"><i class="fa fa-check"></i><b>11.4.1</b> Les <em>k</em> plus proches voisins</a></li>
<li class="chapter" data-level="11.4.2" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-arbres-décisionnels"><i class="fa fa-check"></i><b>11.4.2</b> Les arbres décisionnels</a></li>
<li class="chapter" data-level="11.4.3" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-réseaux-neuronaux"><i class="fa fa-check"></i><b>11.4.3</b> Les réseaux neuronaux</a></li>
<li class="chapter" data-level="11.4.4" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens"><i class="fa fa-check"></i><b>11.4.4</b> Les processus gaussiens</a></li>
<li class="chapter" data-level="11.4.5" data-path="chapitre-ml.html"><a href="chapitre-ml.html#les-processus-gaussiens-en-r"><i class="fa fa-check"></i><b>11.4.5</b> Les processus gaussiens en <code>R</code></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="chapitre-temps.html"><a href="chapitre-temps.html"><i class="fa fa-check"></i><b>12</b> Les séries temporelles</a><ul>
<li class="chapter" data-level="12.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#opérations-sur-les-données-temporelles"><i class="fa fa-check"></i><b>12.1</b> Opérations sur les données temporelles</a></li>
<li class="chapter" data-level="12.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#analyse-de-séries-temporelles"><i class="fa fa-check"></i><b>12.2</b> Analyse de séries temporelles</a><ul>
<li class="chapter" data-level="12.2.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#créer-et-visualiser-des-séries-temporelles"><i class="fa fa-check"></i><b>12.2.1</b> Créer et visualiser des séries temporelles</a></li>
<li class="chapter" data-level="12.2.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#structures-dans-les-séries-temporelles"><i class="fa fa-check"></i><b>12.2.2</b> Structures dans les séries temporelles</a></li>
<li class="chapter" data-level="12.2.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#lautocorrélation"><i class="fa fa-check"></i><b>12.2.3</b> L’autocorrélation</a></li>
<li class="chapter" data-level="12.2.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#signification-statistique-dune-série-temporelle"><i class="fa fa-check"></i><b>12.2.4</b> Signification statistique d’une série temporelle</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#modélisation-de-séries-temporelles"><i class="fa fa-check"></i><b>12.3</b> Modélisation de séries temporelles</a><ul>
<li class="chapter" data-level="12.3.1" data-path="chapitre-temps.html"><a href="chapitre-temps.html#méthode-naïve"><i class="fa fa-check"></i><b>12.3.1</b> Méthode naïve</a></li>
<li class="chapter" data-level="12.3.2" data-path="chapitre-temps.html"><a href="chapitre-temps.html#méthode-ses"><i class="fa fa-check"></i><b>12.3.2</b> Méthode SES</a></li>
<li class="chapter" data-level="12.3.3" data-path="chapitre-temps.html"><a href="chapitre-temps.html#la-méthode-arima"><i class="fa fa-check"></i><b>12.3.3</b> La méthode ARIMA</a></li>
<li class="chapter" data-level="12.3.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#les-modèles-dynamiques"><i class="fa fa-check"></i><b>12.3.4</b> Les modèles dynamiques</a></li>
<li class="chapter" data-level="12.3.5" data-path="chapitre-temps.html"><a href="chapitre-temps.html#les-modèles-tbats"><i class="fa fa-check"></i><b>12.3.5</b> Les modèles TBATS</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="chapitre-temps.html"><a href="chapitre-temps.html#pour-terminer"><i class="fa fa-check"></i><b>12.4</b> Pour terminer…</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chapitre-geo.html"><a href="chapitre-geo.html"><i class="fa fa-check"></i><b>13</b> Les données géospatiales</a><ul>
<li class="chapter" data-level="13.1" data-path="chapitre-geo.html"><a href="chapitre-geo.html#les-données-spatiales"><i class="fa fa-check"></i><b>13.1</b> Les données spatiales</a></li>
<li class="chapter" data-level="13.2" data-path="chapitre-geo.html"><a href="chapitre-geo.html#cartographier-avec-le-module-ggmap"><i class="fa fa-check"></i><b>13.2</b> Cartographier avec le module <strong><code>ggmap</code></strong></a></li>
<li class="chapter" data-level="13.3" data-path="chapitre-geo.html"><a href="chapitre-geo.html#types-génériques-de-données-spatiales"><i class="fa fa-check"></i><b>13.3</b> Types génériques de données spatiales</a></li>
<li class="chapter" data-level="13.4" data-path="chapitre-geo.html"><a href="chapitre-geo.html#les-choroplèthe"><i class="fa fa-check"></i><b>13.4</b> Les choroplèthe</a></li>
<li class="chapter" data-level="13.5" data-path="chapitre-geo.html"><a href="chapitre-geo.html#les-rasters"><i class="fa fa-check"></i><b>13.5</b> Les rasters</a></li>
<li class="chapter" data-level="13.6" data-path="chapitre-geo.html"><a href="chapitre-geo.html#autoapprentissage-spatial"><i class="fa fa-check"></i><b>13.6</b> Autoapprentissage spatial</a></li>
<li class="chapter" data-level="13.7" data-path="chapitre-geo.html"><a href="chapitre-geo.html#les-objets-spatialisés-en-r"><i class="fa fa-check"></i><b>13.7</b> Les objets spatialisés en R</a><ul>
<li class="chapter" data-level="13.7.1" data-path="chapitre-geo.html"><a href="chapitre-geo.html#données-vectorielles-points-lignes-et-polygones"><i class="fa fa-check"></i><b>13.7.1</b> Données vectorielles (points, lignes et polygones)</a></li>
<li class="chapter" data-level="13.7.2" data-path="chapitre-geo.html"><a href="chapitre-geo.html#données-raster"><i class="fa fa-check"></i><b>13.7.2</b> Données raster</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="chapitre-geo.html"><a href="chapitre-geo.html#section-systeme-coord"><i class="fa fa-check"></i><b>13.8</b> Les systèmes de coordonnées</a></li>
<li class="chapter" data-level="13.9" data-path="chapitre-geo.html"><a href="chapitre-geo.html#manipuler-des-tableaux-sf"><i class="fa fa-check"></i><b>13.9</b> Manipuler des tableaux <code>sf</code></a></li>
<li class="chapter" data-level="13.10" data-path="chapitre-geo.html"><a href="chapitre-geo.html#manipuler-des-objets-raster"><i class="fa fa-check"></i><b>13.10</b> Manipuler des objets raster</a></li>
<li class="chapter" data-level="13.11" data-path="chapitre-geo.html"><a href="chapitre-geo.html#graphiques-dobjets-spatialisés"><i class="fa fa-check"></i><b>13.11</b> Graphiques d’objets spatialisés</a></li>
<li class="chapter" data-level="13.12" data-path="chapitre-geo.html"><a href="chapitre-geo.html#ressources-complémentaires"><i class="fa fa-check"></i><b>13.12</b> Ressources complémentaires</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="chapitre-ode.html"><a href="chapitre-ode.html"><i class="fa fa-check"></i><b>14</b> Modélisation de mécanismes écologiques</a><ul>
<li class="chapter" data-level="14.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#équations-différentielles"><i class="fa fa-check"></i><b>14.1</b> Équations différentielles</a></li>
<li class="chapter" data-level="14.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#les-équations-différentielles-ordinaires-en-modélisation-écologique"><i class="fa fa-check"></i><b>14.2</b> Les équations différentielles ordinaires en modélisation écologique</a><ul>
<li class="chapter" data-level="14.2.1" data-path="chapitre-ode.html"><a href="chapitre-ode.html#évolution-dune-seule-population-en-fonction-du-temps"><i class="fa fa-check"></i><b>14.2.1</b> Évolution d’une seule population en fonction du temps</a></li>
<li class="chapter" data-level="14.2.2" data-path="chapitre-ode.html"><a href="chapitre-ode.html#population-exploitée"><i class="fa fa-check"></i><b>14.2.2</b> Population exploitée</a></li>
<li class="chapter" data-level="14.2.3" data-path="chapitre-ode.html"><a href="chapitre-ode.html#interactions-biologiques"><i class="fa fa-check"></i><b>14.2.3</b> Interactions biologiques</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse et modélisation d’agroécosystèmes</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="chapitre-ml" class="section level1">
<h1><span class="header-section-number">11</span> Introduction à l’autoapprentissage</h1>
<hr />
<p>️ <strong>Objectifs spécifiques</strong>:</p>
<p>À la fin de ce chapitre, vous</p>
<ul>
<li>saurez établir un plan de modélisation par autoapprentissage</li>
<li>saurez définir le sous-apprentissage et le surapprentissage</li>
<li>serez en mesure d’effectuer un autoapprentissage avec les techniques des <em>k</em>-proches voisins, les arbres de décision, les forêts aléatoires, les réseaux neuronnaux et les processus gaussiens</li>
</ul>
<hr />
<p>Plusieurs cas d’espèces en sciences et génies peuvent être approchés en liant un variable avec une ou plusieurs autres à l’aide de régressions linéaires, polynomiales, sinusoïdales, exponentielle, sigmoïdales, <a href="https://dl.sciencesocieties.org/publications/aj/pdfs/107/2/786">etc</a>. Encore faut-il s’assurer que ces formes préétablies représentent le phénomène de manière fiable.</p>
<p>Lorsque la forme de la réponse est difficile à envisager, en particulier dans des cas non-linéaires ou impliquant plusieurs variables, on pourra faire appel à des modèles dont la structure n’est pas contrôlée par une équation rigide gouvernée par des paramètres (comme la pente ou l’intercept).</p>
<p>L’<strong>autoapprentissage</strong>, apprentissage automatique, ou <em>machine learning</em>, vise à détecter des structures complexes émergeant d’ensembles de données à l’aide des mathématiques et de processus automatisés afin de prédire l’émergence de futures occurrences. Comme ensemble de techniques empiriques, l’autoapprentissage est un cas particulier de l’<strong>intelligence artificielle</strong>, qui elle inclut aussi les mécanismes déterministes et des ensembles d’opérations logiques. Par exemple, les premiers ordinateurs à compétitionner aux échecs se basaient sur des règles de logique (si la reine noire est positionnée en c3 et qu’un le fou blanc est en position f6 et que … alors bouge la tour en g5 - j’écris n’importe quoi). Un jeu simple d’intelligence artificielle consiste à lancer une marche aléatoire, par exemple bouger à chaque pas d’une distance au hasard en x et y, puis de recalculer le pas s’il arrive dans une boîte définie (figure <a href="#fig:random-walk"><strong>??</strong></a>). Dans les deux cas, il s’agit d’intelligence artificielle, mais pas d’autoapprentissage.</p>
<div class="figure" style="text-align: center"><span id="fig:ml-random-walk"></span>
<img src="_main_files/figure-html/ml-random-walk-1.png" alt="Petite tortue, n'entre pas dans la boîte!" width="100%" />
<p class="caption">
Figure 11.1: Petite tortue, n’entre pas dans la boîte!
</p>
</div>
<p>L’autoapprentissage passera davantage par la simulation de nombreuses parties et dégagera la structure optimale pour l’emporter considérant les positions des pièces sur l’échiquier.</p>
<div id="lexique" class="section level2">
<h2><span class="header-section-number">11.1</span> Lexique</h2>
<p>L’autoapprentissage possède son jargon particulier. Puisque certains termes peuvent porter à confusion, voici quelques définitions de termes que j’utiliserai dans ce chapitre.</p>
<ul>
<li><strong>Réponse</strong>. La variable que l’on cherche à obtenir. Il peut s’agir d’une variable continue comme d’une variable catégorielle. On la nomme aussi la <em>cible</em>.</li>
<li><strong>Prédicteur</strong>. Une variable utilisée pour prédire une réponse. Les prédicteurs sont des variables continues. Les prédicteurs de type catégoriel doivent préalablement être dummifiés (voir chapitre 5). On nomme les prédicteurs les <em>entrées</em>.</li>
<li><strong>Apprentissage supervisé</strong> et <strong>non-supervisé</strong>. Si vous avez suivi le cours jusqu’ici, vous avez déjà utilisé des outils entrant dans la grande famille de l’apprentissage automatique. La régression linéaire, par exemple, vise à minimiser l’erreur sur la réponse en optimisant les coefficients de pente et l’intercept. Un apprentissage supervisé a une cible, comme c’est le cas de la régression linéaire. En revanche, un apprentissage non supervisé n’en a pas: on laisse l’algorithme le soin de détecter des structures intéressantes. Nous avons déjà utilisé cette approche. Pensez-y un peu… l’analyse en composante principale ou en coordonnées principales, ainsi que le partitionnement hiérarchique ou non, couverts au chapitre <a href="chapitre-ordination.html#chapitre-ordination">9</a>, sont des exemples d’apprentissage non supervisé. En revanche, l’analyse de redondance a une réponse. L’analyse discriminante aussi, bien que sa réponse soit catégorielle. L’apprentissage non supervisé ayant déjà été couvert (sans le nommer) au chapitre <a href="chapitre-ordination.html#chapitre-ordination">9</a>, ce chapitre ne s’intéresse qu’à l’apprentissage supervisé.</li>
<li><strong>Régression</strong> et <strong>Classification</strong>. Alors que la régression est un type d’apprentissage automatique pour les réponses continues, la classification vise à prédire une réponse catégorielle. Il existe des algorithmes uniquement application à la régression, uniquement applicables à la classification, et plusieurs autres adaptable aux deux situations.</li>
<li><strong>Données d’entraînement</strong> et <strong>données de test</strong>. Lorsque l’on génère un modèle, on désire qu’il sache comment réagir à ses prédicteurs. Cela se fait avec des données d’entraînement, sur lesquelles on <strong>calibre</strong> et <strong>valide</strong> le modèle. Les données de test servent à vérifier si le modèle est en mesure de prédire des réponses sur lesquelles il n’a pas été entraîné.</li>
<li><strong>Fonction de perte</strong>. Une fonction qui mesure l’erreur d’un modèle.</li>
</ul>
</div>
<div id="démarche" class="section level2">
<h2><span class="header-section-number">11.2</span> Démarche</h2>
<p>La première tâche est d’explorer les données, ce que nous avons couvert au chapitres <a href="chapitre-tableaux.html#chapitre-tableaux">3</a> et <a href="chapitre-visualisation.html#chapitre-visualisation">4</a>.</p>
<div id="prétraitement" class="section level3">
<h3><span class="header-section-number">11.2.1</span> Prétraitement</h3>
<p>Pour la plupart des techniques d’autoapprentissage, le choix de l’échelle de mesure est déterminant sur la modélisation subséquente. Par exemple, un algorithme basé sur la distance comme les <em>k</em> plus proches voisins ne mesurera pas les mêmes distances entre deux observations si l’on change l’unité de mesure d’une variable du mètre au kilomètre. Il est donc important d’effectuer, ou d’envisager la possibilité d’effectuer un prétraitement sur les données. Je vous réfère au chapitre <a href="chapitre-explorer.html#chapitre-explorer">8</a> pour plus de détails sur le prétraitement.</p>
</div>
<div id="entraînement-et-test" class="section level3">
<h3><span class="header-section-number">11.2.2</span> Entraînement et test</h3>
<p>Vous connaissez peut-être l’expression sportive “avoir l’avantage du terrain”. Il s’agit d’un principe prétendant que les athlètes performent mieux en terrain connu. Idem pour les modèles phénoménologiques. Il est possible qu’un modèle fonctionne très bien sur les données avec lesquelles il a été entraîné, mais très mal sur des données externes. De mauvaises prédictions effectuées à partir d’un modèle qui semblait bien se comporter peut mener à des décisions qui, pourtant prises de manière confiante, se révèlent fallacieuses au point d’aboutir à de graves conséquences. C’est pourquoi, <strong>en mode prédictif, on doit évaluer la précision et l’exactitude d’un modèle sur des données qui n’ont pas été utilisés dans son entraînement</strong>.</p>
<p>En pratique, il convient de séparer un tableau de données en deux: un tableau d’entraînement et un tableau de test. Il n’existe pas de standards sur la proportion à utiliser dans l’un et l’autre. Cela dépend de la prudence de l’analyse et de l’ampleur de son tableau de données. Dans certains cas, nous préférerons couper le tableau à 50%. Dand d’autres, nous préférerons réserver le deux-tiers des données pour l’entraînement, ou 70%, 75%. Rarement, toutefois, réservera-t-on moins plus de 50% et moins de 20% à la phase de test.</p>
<p>Si les données sont peu équilibrées (par exemple, on retrouve peu de données de l’espèce <span class="math inline">\(A\)</span>, que l’on retrouve peu de données à un pH inférieur à 5 ou que l’on a peu de données croisées de l’espèce <span class="math inline">\(A\)</span> à pH inférieur à 5), il y a un danger qu’une trop grande part, voire toute les données, se retrouvent dans le tableau d’entraînement (certaines situations ne seront ainsi pas testées) ou dans le tableau de test (certaines situations ne seront pas couvertes par le modèle). L’analyste doit s’assurer de séparer le tableau au hasard, mais de manière consciencieuse.</p>
</div>
<div id="sousapprentissage-et-surapprentissage" class="section level3">
<h3><span class="header-section-number">11.2.3</span> Sousapprentissage et surapprentissage</h3>
<p>Une difficulté en modélisation phénoménologique est de discerner ce qui tient de la structure de ce qui tient du bruit. Lorsque l’on considère une structure comme du bruit, on est dans un cas de sousapprentissage. Lorsque, au contraire, on interprète du bruit comme une structure, on est en cas de surapprentissage. Les graphiques de la figure <a href="#fig:mesapprentissage"><strong>??</strong></a> présentent ces deux cas, avec au centre un cas d’apprentissage conforme.</p>
<div class="figure" style="text-align: center"><span id="fig:ml-mesapprentissage"></span>
<img src="_main_files/figure-html/ml-mesapprentissage-1.png" alt="Cas de figure de mésapprentissage. À gauche, sous-apprentissage. Au centre, apprentissage valide. À droite, surapprentissage." width="672" />
<p class="caption">
Figure 11.2: Cas de figure de mésapprentissage. À gauche, sous-apprentissage. Au centre, apprentissage valide. À droite, surapprentissage.
</p>
</div>
<p>Il est néanmoins difficile d’inspecter un modèle comprenant plusieurs entrées. On détectera le mésapprentissage lorsque la précision d’un modèle est lourdement altérée en phase de test. Une manière de limiter le <em>mésapprentissage</em> est d’avoir recours à la validation croisée.</p>
</div>
<div id="validation-croisée" class="section level3">
<h3><span class="header-section-number">11.2.4</span> Validation croisée</h3>
<p>Souvent confondue avec le fait de séparer le tableau en phases d’entraînement et de test, la validation croisée est un principe incluant plusieurs algorithmes qui consistent à entraîner le modèle sur un échantillonnage aléatoire des données d’entraînement. La technique la plus utilisée est le <em>k-fold</em>, où l’on sépare aléatoirement le tableau d’entraînement en un nombre <em>k</em> de tableaux. À chaque étape de la validation croisée, on calibre le modèle sur tous les tableaux sauf un, puis on valide le modèle sur le tableau exclu. La performance du modèle en entraînement est jugée sur les validations.</p>
</div>
<div id="choix-de-lalgorithme-dapprentissage" class="section level3">
<h3><span class="header-section-number">11.2.5</span> Choix de l’algorithme d’apprentissage</h3>
<p>Face aux <a href="https://topepo.github.io/caret/available-models.html">centaines d’algorithmes d’apprentissages qui vous sont offertes</a>, choisir l’algorithme (ou les algorithmes) adéquats pour votre problème n’est pas une tâche facile. Ce choix sera motivé par les tenants et aboutissants des algorithmes, votre expérience, l’expérience de la littérature, l’expérience de vos collègues, etc. À moins d’être particulièrement surdoué.e, il vous sera pratiquement impossible de maîtriser la mathématique de chacun d’eux. Une approche raisonnable est de tester plusieurs modèles, de retenir les modèles qui semblent les plus pertinents, et d’approfondir si ce n’est déjà fait la mathématique des options retenues. Ajoutons qu’il existe des algorithmes génétiques, qui ne sont pas couverts ici, qui permettent de sélectionner des modèles d’autoapprentissages optimaux. Un de ces algorithmes est offert par le module Python <a href="https://epistasislab.github.io/tpot/"><code>tpot</code></a>.</p>
</div>
<div id="déploiement" class="section level3">
<h3><span class="header-section-number">11.2.6</span> Déploiement</h3>
<p>Nous ne couvrirons pas la phase de déploiement d’un modèle. Notons seulement qu’il est possible, en R, d’exporter un modèle dans un fichier <code>.Rdata</code>, qui pourra être chargé dans un autre environnement R. Cet environnement peut être une feuille de calcul comme une interface visuelle montée, par exemple, avec <a href="https://shiny.rstudio.com/">Shiny</a> (chapitre <a href="chapitre-explorer.html#chapitre-explorer">8</a>).</p>
<hr />
<p>En résumé,</p>
<ol style="list-style-type: decimal">
<li>Explorer les données</li>
<li>Sélectionner des algorithmes</li>
<li>Effectuer un prétraitement</li>
<li>Créer un ensemble d’entraînement et un ensemble de test</li>
<li>Lisser les données sur les données d’entraînement avec validation croisée</li>
<li>Tester le modèle</li>
<li>Déployer le modèle</li>
</ol>
</div>
</div>
<div id="lautoapprentissage-en-r" class="section level2">
<h2><span class="header-section-number">11.3</span> L’autoapprentissage en R</h2>
<p>Plusieurs options sont disponibles.</p>
<ol style="list-style-type: decimal">
<li>Les modules que l’on retrouve en R pour l’autoapprentissage sont nombreux, et parfois spécialisés. Il est possible de les utiliser individuellement.</li>
<li>Chacun de ces modules fonctionne à sa façon. Le module <strong><code>caret</code></strong> de R a été conçu pour donner accès à des centaines de fonctions d’autoapprentissage via une interface commune. <strong><code>caret</code></strong> est très efficace, mais prend de l’âge. Une refonte complète, nommée <a href="https://tidymodels.github.io/parsnip/"><strong><code>parsnip</code></strong></a> (panais en français) est en cours sous l’ombrelle du méta-module de modélisation <a href="https://github.com/tidymodels/tidymodels"><strong><code>tidymodels</code></strong></a>, mais n’est à ce jour pas encore aboutie.</li>
<li>Le module <strong><code>mlr</code></strong> occupe sensiblement le même créneau que <strong><code>caret</code></strong>, mais utilise plutôt une approche par objets connectés. Au moment d’écrire ces lignes, <strong><code>mlr</code></strong> est peu documenté, donc <em>a priori</em> plus complexe à prendre en main.</li>
<li>En Python, le module <strong><code>scikit-learn</code></strong> offre un interface unique pour l’utilisation de nombreuses techniques d’autoapprentissage. Il est possible d’appeler des fonctions de Python à partir de R grâce au module <strong><code>reticulate</code></strong>.</li>
</ol>
<p>Dans ce chapitre, nous verrons comment fonctionnent certains algorithmes sélectionnés, puis nous les appliquerons avec le module respectif qui m’a semblé le plus approprié. Nous utiliserons <strong><code>caret</code></strong> ainsi que quelques outils de <strong><code>tidymodels</code></strong>, dont les recettes pour le prétraitement (module <strong><code>recipes</code></strong>).</p>
<div class="sourceCode" id="cb842"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb842-1" title="1"><span class="kw">library</span>(<span class="st">&quot;tidyverse&quot;</span>) <span class="co"># évidemment</span></a>
<a class="sourceLine" id="cb842-2" title="2"><span class="kw">library</span>(<span class="st">&quot;tidymodels&quot;</span>)</a>
<a class="sourceLine" id="cb842-3" title="3"><span class="kw">library</span>(<span class="st">&quot;caret&quot;</span>)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;caret&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:compositions&#39;:
## 
##     R2</code></pre>
<pre><code>## The following objects are masked from &#39;package:yardstick&#39;:
## 
##     precision, recall, sensitivity, specificity</code></pre>
<pre><code>## The following object is masked from &#39;package:pls&#39;:
## 
##     R2</code></pre>
<pre><code>## The following object is masked from &#39;package:vegan&#39;:
## 
##     tolerance</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     lift</code></pre>
</div>
<div id="algorithmes" class="section level2">
<h2><span class="header-section-number">11.4</span> Algorithmes</h2>
<p>Il existe des centaines d’algorithmes d’autoapprentissage. Je n’en couvrirai que quatre, qui me semblent être appropriés pour la modélisation phénoménologique en agroécologie, et utilisables autant pour la régression et la classification.</p>
<ul>
<li>Les <em>k</em> plus proches voisins</li>
<li>Les arbres de décision</li>
<li>Les réseaux neuronaux</li>
<li>Les processus gaussiens</li>
</ul>
<div id="les-k-plus-proches-voisins" class="section level3">
<h3><span class="header-section-number">11.4.1</span> Les <em>k</em> plus proches voisins</h3>
<div class="figure" style="text-align: center"><span id="fig:ml-les-voisons"></span>
<img src="images/11_les-voisins.jpg" alt="&lt;&lt; Le... l'idée en arrière pour être... euh... simpliste, là c'est que c'est un peu de... euhmm... de la vitamine de vinyle.&gt;&gt; - Georges ([Les voisins](https://youtu.be/-RpYi_Vuviw?t=6m40s), une pièce de Claude Meunier)." width="100%" />
<p class="caption">
Figure 11.3: &lt;&lt; Le… l’idée en arrière pour être… euh… simpliste, là c’est que c’est un peu de… euhmm… de la vitamine de vinyle.&gt;&gt; - Georges (<a href="https://youtu.be/-RpYi_Vuviw?t=6m40s">Les voisins</a>, une pièce de Claude Meunier).
</p>
</div>
<p>Pour dire comme Georges, le… l’idée en arrière des KNN pour être… euh… <em>simpliste</em>, c’est qu’un objet va ressembler à ce qui se trouve dans son voisinage. Les KNN se basent en effet sur une métrique de distance pour rechercher un nombre <em>k</em> de points situés à proximité de la mesure. Les <em>k</em> points les plus proches sont retenus, <em>k</em> étant un entier non nul à optimiser. Un autre paramètre parfois utilisé est la distance maximale des voisins à considérer: un voisin trop éloigné pourra être discarté. La réponse attribuée à la mesure est calculée à partir de la réponse des <em>k</em> voisins retenus. Dans le cas d’une régression, on utiliser généralement la moyenne. Dans le cas de la classification, la mesure prendra la catégorie qui sera la plus présente chez les <em>k</em> plus proches voisins.</p>
<p>L’algorithme des <em>k</em> plus proches voisins est relativement simple à comprendre. Certains pièges sont, de même, peuvent être contournés facilement. Imaginez que vous rechercher les points les plus rapprochés dans un système de coordonnées géographiques où les coordonnées <span class="math inline">\(x\)</span> sont exprimées en mètres et les coordonnées <span class="math inline">\(y\)</span>, en centimètres. Vous y projetez trois points (figure <a href="#fig:knn1"><strong>??</strong></a>).</p>
<div class="figure" style="text-align: center"><span id="fig:ml-knn1"></span>
<img src="_main_files/figure-html/ml-knn1-1.png" alt="Distances entre les points pour utilisation avec les KNN" width="672" />
<p class="caption">
Figure 11.4: Distances entre les points pour utilisation avec les KNN
</p>
</div>
<p>Techniquement la distance A-B est 100 plus élevée que la distance A-C, mais l’algorithme ne se soucie pas de la métrique que vous utilisez (figure <a href="#fig:knn1"><strong>??</strong></a>). Il est primordial dans ce cas d’utiliser la même métrique. Cette stratégie est évidente lorsque les variables sont comparables. C’est rarement le cas, que ce soit lorsque l’on compare des dimensions physionomiques (la longueur d’une phalange ou celle d’un fémur) mais lorsque les variables incluent des mélanges de longueurs, des pH, des décomptes, etc., il est important de bien identifier la métrique et le type de distance qu’il convient le mieux d’utiliser. En outre, la standardisation des données à une moyenne de zéro et à un écart-type de 1 est une approche courrament utilisée.</p>
<div id="exemple-dapplication-1" class="section level4">
<h4><span class="header-section-number">11.4.1.1</span> Exemple d’application</h4>
<p>Pour ce premier exemple, je présenterai un cheminement d’autoapprentissage, du prétraitement au test. Nous allons essayer de classer les espèces de dragon selon leurs dimensions.</p>
<div class="figure" style="text-align: center"><span id="fig:ml-dragons"></span>
<img src="images/11_dragon.png" alt="Dimensions mesurés sur les dragons capturés." width="50%" />
<p class="caption">
Figure 11.5: Dimensions mesurés sur les dragons capturés.
</p>
</div>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb849-1" title="1">dragons &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/11_dragons.csv&quot;</span>)</a></code></pre></div>
<pre><code>## Parsed with column specification:
## cols(
##   V1 = col_double(),
##   V2 = col_double(),
##   V3 = col_double(),
##   V4 = col_double(),
##   V5 = col_double(),
##   V6 = col_double(),
##   V7 = col_double(),
##   V8 = col_double(),
##   V9 = col_double(),
##   V10 = col_double(),
##   V11 = col_double(),
##   ID = col_double(),
##   Species = col_character()
## )</code></pre>
<p>Assurons-nous que les données sont toutes à l’échelle. Nous pourrions utiliser la fonction <code>scale()</code>. Toutefois, si je capture un nouveau dragon, je n’aurai pas l’information pour convertir mes nouvelles dimensions dans la même métrique que celle utilisée pour lisser mon modèle. Prenez donc soin de conserver la moyenne et l’écart-type pour subséquemment calculer des mises à l’échelle.</p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb851-1" title="1">dim_means &lt;-<span class="st"> </span>dragons <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-2" title="2"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;V&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-3" title="3"><span class="st">  </span><span class="kw">summarise_all</span>(mean, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb851-4" title="4"></a>
<a class="sourceLine" id="cb851-5" title="5">dim_sds &lt;-<span class="st"> </span>dragons <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-6" title="6"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;V&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-7" title="7"><span class="st">  </span><span class="kw">summarise_all</span>(sd, <span class="dt">na.rm =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb851-8" title="8"></a>
<a class="sourceLine" id="cb851-9" title="9">dragons_sc &lt;-<span class="st"> </span>dragons <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-10" title="10"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(<span class="kw">starts_with</span>(<span class="st">&quot;V&quot;</span>)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb851-11" title="11"><span class="st">  </span><span class="kw">scale</span>(.) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-12" title="12"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb851-13" title="13"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Species =</span> dragons<span class="op">$</span>Species)</a></code></pre></div>
<p>Séparons les données en entraînement (<code>_tr</code>) et en test (<code>_te</code>) avec une proportion 70/30 (<code>p = 0.7</code>). Il est essentiel d’utiliser <code>set.seed()</code> pour s’assurer que la partition soit la même à chaque session de code (pour la reproductibilité) - j’ai l’habitude de taper n’importe quel numéro à environ 6 chiffres, mais lors de publications, je vais sur <a href="https://www.random.org/">random.org</a> et je génère un numéro au hasard, sans biais.</p>
<div class="sourceCode" id="cb852"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb852-1" title="1"><span class="kw">set.seed</span>(<span class="dv">68017</span>)</a>
<a class="sourceLine" id="cb852-2" title="2">id_tr &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(dragons_sc<span class="op">$</span>Species, <span class="dt">p =</span> <span class="fl">0.7</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)[, <span class="dv">1</span>]</a>
<a class="sourceLine" id="cb852-3" title="3">dragons_tr &lt;-<span class="st"> </span>dragons_sc[id_tr, ]</a>
<a class="sourceLine" id="cb852-4" title="4">dragons_te &lt;-<span class="st"> </span>dragons_sc[<span class="op">-</span>id_tr, ]</a></code></pre></div>
<p>Avant de lancer nos calculs, allons vois sur la <a href="https://topepo.github.io/caret/available-models.html">page de caret</a> les modules qui effectuent des KNN pour la classification. Nous trouvons <strong><code>knn</code></strong> et <strong><code>kknn</code></strong>. Si les modules nécessaires aux calculs ne sont pas installés sur votre ordinateur, <strong><code>caret</code></strong> vous demandera de les installer. Prenons le module <strong><code>kknn</code></strong>, qui demande le paramètre <code>kmax</code>, soit le nombre de voisins à considérer, ainsi qu’un paramètre de <code>distance</code> (spécifiez 1 pour la distance de Mahattan et 2 pour la distance euclidienne), et un <code>kernel</code>, qui est une fonction pour mesurer la distance. Comment choisir les bons paramètres? Une manière de procéder est de créer une grille de paramètres.</p>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb853-1" title="1">kknn_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">kmax =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">6</span>,</a>
<a class="sourceLine" id="cb853-2" title="2">                         <span class="dt">distance =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,</a>
<a class="sourceLine" id="cb853-3" title="3">                         <span class="dt">kernel =</span> <span class="kw">c</span>(<span class="st">&quot;rectangular&quot;</span>, <span class="st">&quot;gaussian&quot;</span>, <span class="st">&quot;optimal&quot;</span>))</a></code></pre></div>
<p>Les noms des colonnes de la grille doivent correspondre aux noms des paramètres du modèle. Nous allons modéliser avec une validation croisée à 5 plis.</p>
<div class="sourceCode" id="cb854"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb854-1" title="1">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)</a></code></pre></div>
<p>Pour finalement lisser le modèle.</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb855-1" title="1"><span class="kw">set.seed</span>(<span class="dv">8961704</span>)</a>
<a class="sourceLine" id="cb855-2" title="2">clf &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb855-3" title="3">             <span class="dt">data =</span> dragons_tr,</a>
<a class="sourceLine" id="cb855-4" title="4">             <span class="dt">method =</span> <span class="st">&quot;kknn&quot;</span>,</a>
<a class="sourceLine" id="cb855-5" title="5">             <span class="dt">tuneGrid =</span> kknn_grid,</a>
<a class="sourceLine" id="cb855-6" title="6">             <span class="dt">trainControl =</span> ctrl)</a>
<a class="sourceLine" id="cb855-7" title="7">clf</a></code></pre></div>
<pre><code>## k-Nearest Neighbors 
## 
## 34 samples
## 11 predictors
##  5 classes: &#39;Dragon de caverne&#39;, &#39;Dragon de feu&#39;, &#39;Dragon de mer&#39;, &#39;Dragon de pierre&#39;, &#39;Dragon de saturne&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 34, 34, 34, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   kmax  distance  kernel       Accuracy   Kappa    
##   3     1         rectangular  0.8914566  0.8572135
##   3     1         gaussian     0.8914566  0.8572135
##   3     1         optimal      0.8914566  0.8572135
##   3     2         rectangular  0.8601133  0.8164023
##   3     2         gaussian     0.8601133  0.8164023
##   3     2         optimal      0.8601133  0.8164023
##   4     1         rectangular  0.8914566  0.8572135
##   4     1         gaussian     0.8914566  0.8572135
##   4     1         optimal      0.8914566  0.8572135
##   4     2         rectangular  0.8528406  0.8070909
##   4     2         gaussian     0.8601133  0.8164023
##   4     2         optimal      0.8601133  0.8164023
##   5     1         rectangular  0.8881233  0.8533711
##   5     1         gaussian     0.8881233  0.8533711
##   5     1         optimal      0.8914566  0.8572135
##   5     2         rectangular  0.8528406  0.8071905
##   5     2         gaussian     0.8601133  0.8165018
##   5     2         optimal      0.8601133  0.8164023
##   6     1         rectangular  0.8881233  0.8533711
##   6     1         gaussian     0.8881233  0.8533711
##   6     1         optimal      0.8914566  0.8572135
##   6     2         rectangular  0.8528406  0.8071905
##   6     2         gaussian     0.8601133  0.8165018
##   6     2         optimal      0.8601133  0.8164023
## 
## Accuracy was used to select the optimal model using the largest value.
## The final values used for the model were kmax = 6, distance = 1 and kernel = optimal.</code></pre>
<p>Nous obtenons les paramètres du modèle optimal. Prédisons l’espèce de dragons selon ses dimensions pour chacun des tableaux.</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb857-1" title="1">pred_tr &lt;-<span class="st"> </span><span class="kw">predict</span>(clf)</a>
<a class="sourceLine" id="cb857-2" title="2">pred_te &lt;-<span class="st"> </span><span class="kw">predict</span>(clf, <span class="dt">newdata =</span> dragons_te)</a></code></pre></div>
<p>Une manière d’évaluer la prédiction est d’afficher un tableau de contingence.</p>
<div class="sourceCode" id="cb858"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb858-1" title="1"><span class="kw">table</span>(dragons_tr<span class="op">$</span>Species, pred_tr)</a></code></pre></div>
<pre><code>##                    pred_tr
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 6             0             0                0
##   Dragon de feu                     0             7             0                0
##   Dragon de mer                     0             0             7                0
##   Dragon de pierre                  0             0             0                7
##   Dragon de saturne                 0             0             0                0
##                    pred_tr
##                     Dragon de saturne
##   Dragon de caverne                 0
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 7</code></pre>
<div class="sourceCode" id="cb860"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb860-1" title="1"><span class="kw">table</span>(dragons_te<span class="op">$</span>Species, pred_te)</a></code></pre></div>
<pre><code>##                    pred_te
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 2             0             0                0
##   Dragon de feu                     0             2             0                0
##   Dragon de mer                     0             0             3                0
##   Dragon de pierre                  0             0             0                3
##   Dragon de saturne                 0             0             0                1
##                    pred_te
##                     Dragon de saturne
##   Dragon de caverne                 0
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 2</code></pre>
<p>Les espèces de dragon sont toutes bien classées tant entraînement qu’en test (c’est rarement le cas dans les situations réelles).</p>
</div>
</div>
<div id="les-arbres-décisionnels" class="section level3">
<h3><span class="header-section-number">11.4.2</span> Les arbres décisionnels</h3>
<div class="figure" style="text-align: center"><span id="fig:ml-ents"></span>
<img src="images/11_Entmoot.jpg" alt="Les Ents, tiré du film le Seigneur des anneaux, qui prennent trop de temps avant de se décider - paradoxalement, les abrbres de décisions sont dotés d'algorithmes rapides." width="100%" />
<p class="caption">
Figure 11.6: Les Ents, tiré du film le Seigneur des anneaux, qui prennent trop de temps avant de se décider - paradoxalement, les abrbres de décisions sont dotés d’algorithmes rapides.
</p>
</div>
<p>Un arbre décisionnel est une collection hiérarchisée de décisions, le plus souvent binaires. Chaque embranchement est un test à vrai ou faux sur une variable. La réponse, que ce soit une catégorie ou une valeur numérique, se trouve au bout de la dernière branche. Les suites de décisions sont organisées de manière à ce que la précision de la réponse soit optimisée. Ils ont l’avantage de pouvoir être exprimés en un schéma simple et imprimable.</p>
<div class="figure" style="text-align: center"><span id="fig:ml-jj-dt"></span>
<img src="https://www.jeremyjordan.me/content/images/2017/03/Screen-Shot-2017-03-11-at-10.15.37-PM.png" alt="Exemple d'arbre de décision, tiré du [blogue de Jeremy Jordon](https://www.jeremyjordan.me/decision-trees/)." width="50%" />
<p class="caption">
Figure 11.7: Exemple d’arbre de décision, tiré du <a href="https://www.jeremyjordan.me/decision-trees/">blogue de Jeremy Jordon</a>.
</p>
</div>
<p>Les arbres sont notamment paramétrés par le nombre maximum d’embranchements, qui s’il est trop élevé peut mener à du surapprentissage. <a href="https://topepo.github.io/caret/available-models.html">Il existe de nombreux algorithmes d’arbres de décision</a>.</p>
<p>Une collection d’arbres devient une forêt. Les forêts aléatoires (<em>random forest</em>) sont une catégorie d’algorithmes composés de plusieurs arbres de décision optimisés sur des données répliquées aléatoirement par <em>bagging</em>. Allons-y par étape. À partir des données existantes composées de <em>n</em> observations (donc <em>n</em> lignes) sélectionnées pour l’entraînement, échantillonnons au hasard <em>avec remplacement</em> un nombre <em>n</em> de nouvelles observations. Le remplacement implique qu’on retrouvera fort probablement dans notre nouveau tableau des lignes identiques. Lissons un arbre sur notre tableau aléatoire. Effectuons un nouveau tirage, puis un autre arbre. Puis encore, et encore, disons 10 fois. Nous obtiendrons une forêt de 10 arbres. Pour une nouvelle observation à prédire, nous obtenons donc 10 prédictions, sur lesquelles nous pouvons effectuer un moyenne s’il s’agit d’une variable numérique, ou bien prenons la catégorie la plus souvent prédite dans le cas d’une classification. Les forêts aléatoires peuvent être constitués de 10, 100, 1000 arbres: autant qu’il en est nécessaire.</p>
<div id="exemple-dapplication-2" class="section level4">
<h4><span class="header-section-number">11.4.2.1</span> Exemple d’application</h4>
<p>Utilisons toujours nos données de dimensions de dragons. Bien qu’il en existe plusieurs, le module conventionnel pour effectuer un arbre de décision est <strong><code>rpart2</code></strong>. <a href="https://topepo.github.io/caret/available-models.html">Sur la page de <strong><code>caret</code></strong></a>, nous trouvons <strong><code>rpart2</code></strong>, apte pour les classifications et les régressions, <a href="https://topepo.github.io/caret/train-models-by-tag.html#random-forest">qui n’a besoin que du paramètre <code>maxdepth</code></a>.</p>
<div class="sourceCode" id="cb862"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb862-1" title="1">rpart2_grid &lt;-<span class="st"> </span><span class="kw">expand.grid</span>(<span class="dt">maxdepth =</span> <span class="dv">3</span><span class="op">:</span><span class="dv">10</span>) <span class="co"># expand_grid n&#39;est pas nécessaire ici</span></a></code></pre></div>
<p>Prenons 5 plis encore une fois.</p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb863-1" title="1">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)</a></code></pre></div>
<p>Pour finalement lisser le modèle.</p>
<div class="sourceCode" id="cb864"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb864-1" title="1"><span class="kw">set.seed</span>(<span class="dv">3468973</span>)</a>
<a class="sourceLine" id="cb864-2" title="2">clf &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb864-3" title="3">             <span class="dt">data =</span> dragons_tr,</a>
<a class="sourceLine" id="cb864-4" title="4">             <span class="dt">method =</span> <span class="st">&quot;rpart2&quot;</span>,</a>
<a class="sourceLine" id="cb864-5" title="5">             <span class="dt">tuneGrid =</span> rpart2_grid)</a>
<a class="sourceLine" id="cb864-6" title="6">clf</a></code></pre></div>
<pre><code>## CART 
## 
## 34 samples
## 11 predictors
##  5 classes: &#39;Dragon de caverne&#39;, &#39;Dragon de feu&#39;, &#39;Dragon de mer&#39;, &#39;Dragon de pierre&#39;, &#39;Dragon de saturne&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 34, 34, 34, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   maxdepth  Accuracy   Kappa    
##    3        0.4162868  0.2872798
##    4        0.4162868  0.2872798
##    5        0.4162868  0.2872798
##    6        0.4162868  0.2872798
##    7        0.4162868  0.2872798
##    8        0.4162868  0.2872798
##    9        0.4162868  0.2872798
##   10        0.4162868  0.2872798
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was maxdepth = 3.</code></pre>
<p>Nous obtenons les paramètres du modèle optimal: <code>maxdepth = 3</code> - puisque c’est à la limite inférieure de la grille, mieux vaudrait étendre la grille, mais passons pour l’exemple. Comme je l’ai mentionné, un arbre de décision est un outil convivial à visualiser.</p>
<div class="sourceCode" id="cb866"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb866-1" title="1"><span class="kw">plot</span>(clf<span class="op">$</span>finalModel)</a>
<a class="sourceLine" id="cb866-2" title="2"><span class="kw">text</span>(clf<span class="op">$</span>finalModel)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-tree-plot-1.png" width="672" /></p>
<p>Ou en plus beau, je vous laisse essayer.</p>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb867-1" title="1"><span class="kw">library</span>(<span class="st">&quot;rattle&quot;</span>)</a>
<a class="sourceLine" id="cb867-2" title="2"><span class="kw">fancyRpartPlot</span>(clf<span class="op">$</span>finalModel)</a></code></pre></div>
<p>Tout comme pour les KNN, prédisons l’espèce de dragons selon ses dimensions pour chacun des tableaux.</p>
<div class="sourceCode" id="cb868"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb868-1" title="1">pred_tr &lt;-<span class="st"> </span><span class="kw">predict</span>(clf)</a>
<a class="sourceLine" id="cb868-2" title="2">pred_te &lt;-<span class="st"> </span><span class="kw">predict</span>(clf, <span class="dt">newdata =</span> dragons_te)</a></code></pre></div>
<p>En ce qui a trait aux tableaux de contigence…</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb869-1" title="1"><span class="kw">table</span>(dragons_tr<span class="op">$</span>Species, pred_tr)</a></code></pre></div>
<pre><code>##                    pred_tr
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 0             0             0                0
##   Dragon de feu                     0             7             0                0
##   Dragon de mer                     0             0             7                0
##   Dragon de pierre                  0             0             0                7
##   Dragon de saturne                 0             0             0                0
##                    pred_tr
##                     Dragon de saturne
##   Dragon de caverne                 6
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 7</code></pre>
<div class="sourceCode" id="cb871"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb871-1" title="1"><span class="kw">table</span>(dragons_te<span class="op">$</span>Species, pred_te)</a></code></pre></div>
<pre><code>##                    pred_te
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 0             1             0                0
##   Dragon de feu                     0             2             0                0
##   Dragon de mer                     0             0             3                0
##   Dragon de pierre                  0             0             0                3
##   Dragon de saturne                 0             0             0                0
##                    pred_te
##                     Dragon de saturne
##   Dragon de caverne                 1
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 3</code></pre>
<p>Les espèces de dragon sont toutes bien classées en entraînement et en test… sauf pour les dragons de caverne, qui (l’avez-vous remarquez?) n’apparaissent pas dans l’arbre de décision!</p>
<p>Le module <strong><code>caret</code></strong> vient avec la fonction <code>varImp()</code> qui offre une appréciation de l’importance des variables dans le modèle final. La notion d’importance varie d’un modèle à l’autre, et reste à ce jour mal documenté. Mieux vaut en examiner les tenants et aboutissants avant d’interpréter exessivement la sortie de cette fonction.</p>
<div class="sourceCode" id="cb873"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb873-1" title="1"><span class="kw">varImp</span>(clf) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">plot</span>(.)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-tree-varimp-1.png" width="672" /></p>
<p>On pourra effectuer de la même manière une forêt aléatoire, mais cette fois-ci avec le module <strong><code>rf</code></strong>.</p>
<div class="sourceCode" id="cb874"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb874-1" title="1"><span class="kw">set.seed</span>(<span class="dv">3468973</span>)</a>
<a class="sourceLine" id="cb874-2" title="2">ctrl &lt;-<span class="st"> </span><span class="kw">trainControl</span>(<span class="dt">method=</span><span class="st">&quot;repeatedcv&quot;</span>, <span class="dt">repeats =</span> <span class="dv">5</span>)</a>
<a class="sourceLine" id="cb874-3" title="3">clf &lt;-<span class="st"> </span><span class="kw">train</span>(Species <span class="op">~</span><span class="st"> </span>.,</a>
<a class="sourceLine" id="cb874-4" title="4">             <span class="dt">data =</span> dragons_tr,</a>
<a class="sourceLine" id="cb874-5" title="5">             <span class="dt">method =</span> <span class="st">&quot;rf&quot;</span>)</a>
<a class="sourceLine" id="cb874-6" title="6">clf</a></code></pre></div>
<pre><code>## Random Forest 
## 
## 34 samples
## 11 predictors
##  5 classes: &#39;Dragon de caverne&#39;, &#39;Dragon de feu&#39;, &#39;Dragon de mer&#39;, &#39;Dragon de pierre&#39;, &#39;Dragon de saturne&#39; 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 34, 34, 34, 34, 34, 34, ... 
## Resampling results across tuning parameters:
## 
##   mtry  Accuracy   Kappa    
##    2    0.9018266  0.8776655
##    6    0.9555287  0.9441745
##   11    0.9524518  0.9401765
## 
## Accuracy was used to select the optimal model using the largest value.
## The final value used for the model was mtry = 6.</code></pre>
<p>Et les résultats.</p>
<div class="sourceCode" id="cb876"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb876-1" title="1">pred_tr &lt;-<span class="st"> </span><span class="kw">predict</span>(clf)</a>
<a class="sourceLine" id="cb876-2" title="2">pred_te &lt;-<span class="st"> </span><span class="kw">predict</span>(clf, <span class="dt">newdata =</span> dragons_te)</a>
<a class="sourceLine" id="cb876-3" title="3"><span class="kw">table</span>(dragons_te<span class="op">$</span>Species, pred_te)</a></code></pre></div>
<pre><code>##                    pred_te
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 2             0             0                0
##   Dragon de feu                     0             2             0                0
##   Dragon de mer                     0             0             3                0
##   Dragon de pierre                  0             0             0                3
##   Dragon de saturne                 0             0             0                0
##                    pred_te
##                     Dragon de saturne
##   Dragon de caverne                 0
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 3</code></pre>
<div class="sourceCode" id="cb878"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb878-1" title="1"><span class="kw">table</span>(dragons_tr<span class="op">$</span>Species, pred_tr)</a></code></pre></div>
<pre><code>##                    pred_tr
##                     Dragon de caverne Dragon de feu Dragon de mer Dragon de pierre
##   Dragon de caverne                 6             0             0                0
##   Dragon de feu                     0             7             0                0
##   Dragon de mer                     0             0             7                0
##   Dragon de pierre                  0             0             0                7
##   Dragon de saturne                 0             0             0                0
##                    pred_tr
##                     Dragon de saturne
##   Dragon de caverne                 0
##   Dragon de feu                     0
##   Dragon de mer                     0
##   Dragon de pierre                  0
##   Dragon de saturne                 7</code></pre>
<p>Notez que les forêts aléatoires ne génère par de visuel.</p>
</div>
</div>
<div id="les-réseaux-neuronaux" class="section level3">
<h3><span class="header-section-number">11.4.3</span> Les réseaux neuronaux</h3>
<p>Après les KNN et les <em>random forests</em>, nous passons au domaine plus complexe des réseaux neuronaux. Le terme <em>réseau neuronal</em> est une métaphore liée à une perception que l’on avait du fonctionnement du cerveau humain lorsque la technique des réseaux neuronaux a été développée dans les années 1950. Un réseau neuronal comprend une série de boîtes d’entrées liée à des fonctions qui transforment et acheminent successivement l’information jusqu’à la sortie d’une ou plusieurs réponse. Il existe plusieurs formes de réseaux neuronnaux, dont la plus simple manifestation est le <em>perceptron multicouche</em>. Dans l’exemple de la figure <a href="#fig:nn1"><strong>??</strong></a>, on retrouve 4 variables d’entrée et trois variables de sortie entre lesquelles on retrouve 5 couches dont le nombre de neurones varient entre 3 et 6.</p>
<div class="figure" style="text-align: center"><span id="fig:ml-nn1"></span>
<img src="images/11_deep_neural_network.png" alt="Réseau neuronal schématisé, Source: [Neural designer](https://www.neuraldesigner.com/)." width="50%" />
<p class="caption">
Figure 11.8: Réseau neuronal schématisé, Source: <a href="https://www.neuraldesigner.com/">Neural designer</a>.
</p>
</div>
<p>Entre la première couche de neurones (les variables prédictives) et la dernière couche (les variables réponse), on retrouve des <em>couches cachées</em>. Chaque neurone est relié à tous les neurones de la couche suivante.</p>
<p>Les liens sont des poids, qui peuvent prendre des valeurs dans l’ensemble des nombres réels. À chaque neurone suivant la première couche, on fait la somme des poids multipliés par la sortie du neurone. Le nombre obtenu entre dans chaque neurone de la couche. Le neurone est une fonction, souvent très simple, qui transforme le nombre. La fonction plus utilisée est probablement la fonction ReLU, pour <em>rectified linear unit</em>, qui expulse le même nombre aux neurones de la prochaine couche s’il est positif: sinon, il expulse un zéro.</p>
<p><strong>Exercice</strong>. Si tous les neurones sont des fonctions ReLU, calculez la sortie de ce petit réseau neuronal.</p>
<p><img src="images/11_nn_ex1_Q.jpg" width="600px"></p>
<p>Vous trouverez la réponse sur l’image <code>images/11_nn_ex1_R.jpg</code>.</p>
<p>Il est aussi possible d’ajouter un <em>biais</em> à chaque neurone, qui est un nombre réel additionné à la somme des neurones pondérée par les poids.</p>
<p>L’optimisation les poids pour chaque lien et les biais pour chaque neurone (grâce à des algorithmes dont le fonctionnement sort du cadre de ce cours) constitue le processus d’apprentissage. Avec l’aide de logiciels et de modules spécialisés, la construction de réseaux de centaines de neurones organisés en centaines de couches vous permettra de capter des patrons complexes dans des ensembles de données.</p>
<p>Vous avez peut-être déjà entendu parler d’apprentissage profond (ou <em>deep learning</em>). Il s’agit simplement d’une appellation des réseaux neuronaux modernisé pour insister sur la présence de nombreuses couches de neurones. C’est un terme à la mode.</p>
<div id="les-réseaux-neuronaux-sur-r-avec-neuralnet" class="section level4">
<h4><span class="header-section-number">11.4.3.1</span> Les réseaux neuronaux sur R avec <strong><code>neuralnet</code></strong></h4>
<p>Plusieurs modules sont disponibles sur R pour l’apprentissage profond. Certains utilisent le module <a href="https://github.com/h2oai/h2o-3">H2O.ia</a>, propulsé en Java, d’autres utilisent plutôt <a href="https://keras.rstudio.com/">Keras</a>, propulsé en Python par l’intermédiaire de <a href="https://www.tensorflow.org/">Tensorflow</a>. J’ai une préférence pour Keras, puisqu’il supporte les réseaux neuronaux classiques (perceptrons multicouche) autant que convolutifs ou récurrents. Keras pourrait néanmoins être difficile à installer sur Windows, où Python ne vient pas par défaut. Sur Windows, Keras ne fonctionne qu’avec Anaconda: vous devez donc installez <a href="https://www.anaconda.com/download/#windows">Anaconda ou Miniconda</a> (Miniconda offre une installation minimaliste).</p>
<p>Donc, pour ce cours, nous utiliserons le module <strong><code>neuralnet</code></strong>. Il est possible de l’utilser grâce à l’interface de <strong><code>caret</code></strong>, mais son utilisation directe permet davantage de flexibilité. Chargeons les données d’iris.</p>
<div class="sourceCode" id="cb880"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb880-1" title="1"><span class="kw">library</span>(<span class="st">&quot;neuralnet&quot;</span>)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;neuralnet&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:dplyr&#39;:
## 
##     compute</code></pre>
<div class="sourceCode" id="cb883"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb883-1" title="1"><span class="kw">data</span>(<span class="st">&quot;iris&quot;</span>)</a></code></pre></div>
<p>Prenons soin de segmenter nos données en entraînement et en test.</p>
<div class="sourceCode" id="cb884"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb884-1" title="1"><span class="kw">set.seed</span>(<span class="dv">8453668</span>)</a>
<a class="sourceLine" id="cb884-2" title="2">iris_tr_index &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y=</span>iris<span class="op">$</span>Species, <span class="dt">p =</span> <span class="fl">0.75</span>, <span class="dt">list =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Nous pouvons ainsi créer nos tableaux d’entraînement et de test pour les variables prédictives.</p>
<p>Les réseaux neuronnaux sont aptes à générer des sorties multiples. Nous désirons prédire une catégorie, et <strong><code>neuralnet</code></strong> ne s’occupe pas de les transformer de facto. Lors de la prédiction d’une catégorie, nous devons générée des sorties multiples qui permettront de décider de l’appartenance exclusive à une catégorie ou une autre. Nous avons abordé l’encodage catégoriel aux chapitres <a href="chapitre-biostats.html#chapitre-biostats">6</a> et <a href="chapitre-explorer.html#chapitre-explorer">8</a>. C’est ce que nous ferons ici.</p>
<div class="sourceCode" id="cb885"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb885-1" title="1">species_oh &lt;-<span class="st"> </span><span class="kw">model.matrix</span>(<span class="op">~</span><span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span>Species, iris)</a>
<a class="sourceLine" id="cb885-2" title="2"><span class="kw">colnames</span>(species_oh) &lt;-<span class="st"> </span><span class="kw">levels</span>(iris<span class="op">$</span>Species)</a>
<a class="sourceLine" id="cb885-3" title="3">iris_oh &lt;-<span class="st"> </span>iris <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb885-4" title="4"><span class="st">  </span><span class="kw">cbind</span>(species_oh)</a>
<a class="sourceLine" id="cb885-5" title="5">iris_tr &lt;-<span class="st"> </span>iris_oh[iris_tr_index, ]</a>
<a class="sourceLine" id="cb885-6" title="6">iris_te &lt;-<span class="st"> </span>iris_oh[<span class="op">-</span>iris_tr_index, ]</a></code></pre></div>
<p>Lançons le réseau neuronnal avec l’interface-formule de R (neuralnet n’accepte pas le <code>.</code> pour indiquer <em>prend toutes les variables à l’exeption de celles utilisées en y</em>): nous allons les inclure à la main. L’argument <code>hidden</code> est un vecteur qui indique le nombre de neuronnes pour chaque couche. L’argument <code>linear.input</code> indique si l’on désire travailler en régression (<code>linear.output = TRUE</code>) ou en classification (<code>linear.output = FALSE</code>). Lorsque les données sont nombreuses, patience, le calcul prend pas mal de temps. Dans ce cas-ci, nous avons un tout petit tableau.</p>
<div class="sourceCode" id="cb886"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb886-1" title="1">nn &lt;-<span class="st"> </span><span class="kw">neuralnet</span>(setosa <span class="op">+</span><span class="st"> </span>versicolor <span class="op">+</span><span class="st"> </span>virginica <span class="op">~</span><span class="st"> </span>Sepal.Length <span class="op">+</span><span class="st"> </span>Sepal.Width <span class="op">+</span><span class="st"> </span>Petal.Length <span class="op">+</span><span class="st"> </span>Petal.Width,</a>
<a class="sourceLine" id="cb886-2" title="2">                <span class="dt">data =</span> iris_tr, </a>
<a class="sourceLine" id="cb886-3" title="3">                <span class="dt">hidden =</span> <span class="kw">c</span>(<span class="dv">5</span>, <span class="dv">5</span>),</a>
<a class="sourceLine" id="cb886-4" title="4">                <span class="dt">act.fct =</span> <span class="st">&quot;tanh&quot;</span>,</a>
<a class="sourceLine" id="cb886-5" title="5">                <span class="dt">linear.output =</span> <span class="ot">FALSE</span>)</a></code></pre></div>
<p>Un réseau neuronnal peu complexe peut être lisible.</p>
<div class="sourceCode" id="cb887"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb887-1" title="1"><span class="kw">plot</span>(nn)</a></code></pre></div>
<p>Il n’existe pas de règle stricte sur le nombre de couche et le nombre de noeud par couche. Il est néanmoins conseillé de générer d’abord un modèle simple, puis au besoin de le complexifier graduellement en terme de nombre de noeuds, puis de nombre de couches. Si vous désirez aller plus loin et utiliser keras, le module <a href="https://autokeras.com/"><code>autokeras</code></a>, disponible seulement en Python, est conçu pour optimiser un modèle Keras.</p>
<p>La sortie du réseau neuronal est une valeur près de 1 ou une valeur près de 0. Voici une manière de générer un vecteur catégoriel.</p>
<div class="sourceCode" id="cb888"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb888-1" title="1">compute_te &lt;-<span class="st"> </span><span class="kw">compute</span>(nn, iris_te)</a>
<a class="sourceLine" id="cb888-2" title="2">pred_te &lt;-<span class="st"> </span>compute_te<span class="op">$</span>net.result <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb888-3" title="3"><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb888-4" title="4"><span class="st">  </span><span class="kw">apply</span>(., <span class="dv">1</span>, which.max) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb888-5" title="5"><span class="st">  </span><span class="kw">levels</span>(iris<span class="op">$</span>Species)[.] <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb888-6" title="6"><span class="st">  </span><span class="kw">as.factor</span>()</a></code></pre></div>
<pre><code>## Warning: The `x` argument of `as_tibble.matrix()` must have column names if `.name_repair` is omitted as of tibble 2.0.0.
## Using compatibility `.name_repair`.
## This warning is displayed once every 8 hours.
## Call `lifecycle::last_warnings()` to see where this warning was generated.</code></pre>
<p>La fonction <code>caret::confusionMatrix()</code> permet de générer les statistiques du modèle.</p>
<div class="sourceCode" id="cb890"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb890-1" title="1"><span class="kw">confusionMatrix</span>(iris_te<span class="op">$</span>Species, pred_te)</a></code></pre></div>
<pre><code>## Confusion Matrix and Statistics
## 
##             Reference
## Prediction   setosa versicolor virginica
##   setosa         12          0         0
##   versicolor      1         10         1
##   virginica       0          0        12
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9444          
##                  95% CI : (0.8134, 0.9932)
##     No Information Rate : 0.3611          
##     P-Value [Acc &gt; NIR] : 2.421e-13       
##                                           
##                   Kappa : 0.9167          
##                                           
##  Mcnemar&#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: setosa Class: versicolor Class: virginica
## Sensitivity                 0.9231            1.0000           0.9231
## Specificity                 1.0000            0.9231           1.0000
## Pos Pred Value              1.0000            0.8333           1.0000
## Neg Pred Value              0.9583            1.0000           0.9583
## Prevalence                  0.3611            0.2778           0.3611
## Detection Rate              0.3333            0.2778           0.3333
## Detection Prevalence        0.3333            0.3333           0.3333
## Balanced Accuracy           0.9615            0.9615           0.9615</code></pre>
<p>Encore une fois, c’est rarement le cas mais nous obtenons une classification parfaite.</p>
</div>
<div id="pour-aller-plus-loin-1" class="section level4">
<h4><span class="header-section-number">11.4.3.2</span> Pour aller plus loin</h4>
<p>En une heure divisée en <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi">4 vidéos</a>, Grant Sanderson explique les réseaux neuronaux de manière intuitive. En ce qui a trait à Keras, je recommande le livre <a href="https://www.safaribooksonline.com/library/view/deep-learning-with/9781617295546/?ar">Deep learning with R, de François Allaire</a>, auquel vous avez accès avec un IDUL de l’Université Laval. Si vous vous sentez à l’aise à utiliser Keras avec le langage Python, je vous recommande le cours gratuit en ligne <a href="https://www.youtube.com/watch?v=sRy26qWejOI&amp;list=PLjy4p-07OYzulelvJ5KVaT2pDlxivl_BN"><em>Applications of deep neural networks</em>, de Jeff Heaton</a>.</p>
<p>Des types de réseaux neuronaux spécialisés ont été développés. Je les présente sans aller dans les détails.</p>
<ul>
<li><strong>Réseaux neuronaux convolutif</strong>. Ce type de réseau neuronal est surtout utilisé en reconnaissance d’image. Les couches de neurones convolutifs possèdent, en plus des fonctions des perceptrons classiques, des filtres permettant d’intégrer les variables descriptives connexes à l’observation: dans le cas d’une image, il s’agit de scanner les pixels au pourtour du pixel traité. <a href="https://www.youtube.com/watch?v=YRhxdVk_sIs">Une brève introduction sur Youtube</a>.</li>
<li><strong>Réseaux neuronaux récurrents</strong>. Prédire des occurrences futures à partir de séries temporelles implique que la réponse au temps t dépend non seulement de conditions externes, mais aussi le la réponse au temps t-1. Les réseaux neuronaux récurrents. Vous devrez ajouter des neurones particuliers pour cette tâche, qui pourra être pris en charge par Keras grâce aux couches de type <a href="https://www.youtube.com/watch?v=UnclHXZszpw"><em>Long Short-Term Memory network</em>, ou LSTM</a>.</li>
<li><strong>Réseaux neuronaux probabilistes</strong>. Les réseaux neuronaux non-probabilistes offre une estimation de la variable réponse. Mais quelle est la crédibilité de la réponse selon les variables descriptives? Question qui pourrait se révéler cruciale en médecine ou en ingénierie, à la laquelle on pourra répondre en mode probabiliste. Pour ce faire, on pose des distributions <em>a priori</em> sur les poids du réseau neuronal. Le module <a href="http://edwardlib.org/"><code>edward</code></a>, programmé et distribué en Python, offre cette possibilité. Vous pourrez accéder à <code>edward</code> grâce au module <code>reticulate</code>, mais à ce stade mieux vaudra basculer en Python. Pour en savoir davantage, considérez <a href="https://www.youtube.com/watch?v=I09QVNrUS3Q">cette conférence de Andrew Rowan</a>.</li>
</ul>
</div>
</div>
<div id="les-processus-gaussiens" class="section level3">
<h3><span class="header-section-number">11.4.4</span> Les processus gaussiens</h3>
<p>Les sorties des techniques que sont les KNN, les arbres ou les forêts ainsi que les réseaux neuronaux sont (classiquement) des nombres réels ou des catégories. Dans les cas où la crédibilité de la réponse est importante, il devient pertinent que la sortie soit probabiliste: les prédictions seront alors présentées sous forme de distributions de probabilité. Dans le cas d’une classification, la sortie du modèle sera un vecteur de probabilité qu’une observation appartienne à une classe ou à une autre. Dans celui d’une régression, on obtiendra une distribution continue.</p>
<p>Les <strong>processus gaussiens</strong> tirent profit des statistiques bayésiennes pour effectuer des prédictions probabilistes. D’autres techniques peuvent être utilisées pour effectuer des prédictions probabilistes, comme les <a href="http://edwardlib.org/iclr2017">réseaux neuronaux probabilistes</a>, que j’ai introduits précédemment.</p>
<p>Bien que les processus gaussiens peuvent être utilisés pour la classification, son fonctionnement s’explique favorablement, de manière intuitive, pas la régression.</p>
<div id="un-approche-intuitive" class="section level4">
<h4><span class="header-section-number">11.4.4.1</span> Un approche intuitive</h4>
<p>Ayant acquis de l’expérience en enseignement des processus gaussiens, <a href="http://stat.columbia.edu/~cunningham/">John Cunningham</a> a développé une approche intuitive permettant de saisir les mécanismes des processus gaussiens. lors de conférences disponible sur YouTube (<a href="https://youtu.be/BS4Wd5rwNwE">1</a>, <a href="https://www.youtube.com/watch?v=Jv25sg-IYHU">2</a>), il aborde le sujet par la nécessité d’effectuer une régression non-linéaire.</p>
<p>Générons d’abord une variable prédictive <code>x</code>, l’heure, et une variable réponse <code>y</code>, le rythme cardiaque d’un individu en battements par minute (bpm).</p>
<div class="sourceCode" id="cb892"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb892-1" title="1">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">17</span>)</a>
<a class="sourceLine" id="cb892-2" title="2">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>, <span class="dv">69</span>, <span class="dv">67</span>, <span class="dv">78</span>)</a>
<a class="sourceLine" id="cb892-3" title="3"></a>
<a class="sourceLine" id="cb892-4" title="4"><span class="kw">plot</span>(x, y, <span class="dt">xlab=</span><span class="st">&quot;Heure&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>)</a>
<a class="sourceLine" id="cb892-5" title="5"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">12</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">12</span>, <span class="dv">67</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb892-6" title="6"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">16</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">16</span>, <span class="dv">72</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-data-1.png" width="672" /></p>
<p>Poser un problème par un processus gaussien, c’est se demander les valeurs crédibles qui pourraient être obtenues hors du domaine d’observations (par exemple, dans la figure ci-dessus, à <code>x=12</code> et <code>x=16</code>)? Ou bien, de manière plus générale, <em>quelles fonctions ont pu générer les variables réponse à partir d’une structure dans les variables prédictives?</em></p>
<p>Les distributions normales, que nous appellerons <em>gaussiennes</em> dans cette section par concordance avec le terme <em>processus gaussien</em>, sont particulièrement utiles pour répondre à cette question.</p>
<p>Nous avons vu précédemment ce que sont les distributions de probabilité: des outils mathématiques permettant d’appréhender la structure des processus aléatoires. Une distribution gaussienne représente une situation où l’on tire au hasard des valeurs continues. Une distribution gaussienne de la variable aléatoire <span class="math inline">\(X\)</span> de moyenne <span class="math inline">\(0\)</span> et de variance de <span class="math inline">\(1\)</span> est notée ainsi:</p>
<p><span class="math display">\[ X \sim \mathcal{N} \left( 0, 1\right)\]</span></p>
<p>Par exemple, une courbe de distribution gaussienne du rythme cardiaque à 7:00 pourrait prendre la forme suivante.</p>
<p><span class="math display">\[ bpm \sim \mathcal{N} \left( 65, 5\right)\]</span></p>
<p>En <code>R</code>:</p>
<div class="sourceCode" id="cb893"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb893-1" title="1">x_sequence &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">50</span>, <span class="dv">80</span>, <span class="dt">length=</span><span class="dv">100</span>)</a>
<a class="sourceLine" id="cb893-2" title="2"><span class="kw">plot</span>(x_sequence,</a>
<a class="sourceLine" id="cb893-3" title="3">     <span class="kw">dnorm</span>(x_sequence, <span class="dt">mean=</span><span class="dv">65</span>, <span class="dt">sd=</span><span class="dv">5</span>),</a>
<a class="sourceLine" id="cb893-4" title="4">     <span class="dt">type=</span><span class="st">&quot;l&quot;</span>,</a>
<a class="sourceLine" id="cb893-5" title="5">     <span class="dt">xlab=</span><span class="st">&quot;Rythme cardiaque (bpm)&quot;</span>,</a>
<a class="sourceLine" id="cb893-6" title="6">     <span class="dt">ylab=</span><span class="st">&quot;Densité&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-xseq-1.png" width="672" /></p>
<p>Une distribution <strong>bi</strong>normale, un cas particulier de la distribution <strong>multi</strong>normale, comprendra deux vecteurs, <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_2\)</span>. Elle aura donc deux moyennes. Puisqu’il s’agit d’une distribution binormale, et non pas deux distributions normales, les deux variables ne sont pas indépendantes et l’on utilisera une matrice de covariance au lieu de deux variances indépendantes.</p>
<p><span class="math display">\[
\binom{x_1}{x_2} \sim \mathcal{N}
\Bigg( 
\binom{\mu_1}{\mu_2},
\left[ {\begin{array}{cc}
\Sigma_{x_1} &amp; \Sigma_{x_1,x_2} \\
\Sigma_{x_1,x_2}^T &amp; \Sigma_{x_2} \\
\end{array} } \right]
\Bigg)
\]</span></p>
<p>La matrice <span class="math inline">\(\Sigma\)</span>, dite de <em>variance-covariance</em>, indique sur sa diagonale les variances des variables (<span class="math inline">\(\Sigma_{x_1}\)</span> et <span class="math inline">\(\Sigma_{x_2}\)</span>). Les covariances <span class="math inline">\(\Sigma_{x_1,x_2}\)</span> et <span class="math inline">\(\Sigma_{x_1,x_2}^T\)</span> sont symétriques et indiquent le lien entre les variables.</p>
<p>On pourrait supposer que le rythme cardiaque à 8:00 soit corrélé avec celui à 7:00. Mises ensembles, les distributions gaussiennes à 7:00 et à 8:00 formeraient une distribution gaussienne binormale.</p>
<p><span class="math display">\[
\binom{bpm_7}{bpm_8} \sim \mathcal{N}
\Bigg( 
\binom{65}{75},
\left[ {\begin{array}{cc}
10 &amp; 6 \\
6 &amp; 15 \\
\end{array} } \right]
\Bigg)
\]</span></p>
<p>En <code>R</code>:</p>
<div class="sourceCode" id="cb894"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb894-1" title="1"><span class="kw">library</span>(<span class="st">&quot;ellipse&quot;</span>)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;ellipse&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:car&#39;:
## 
##     ellipse</code></pre>
<pre><code>## The following object is masked from &#39;package:graphics&#39;:
## 
##     pairs</code></pre>
<div class="sourceCode" id="cb898"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb898-1" title="1">means_vec &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">65</span>, <span class="dv">75</span>)</a>
<a class="sourceLine" id="cb898-2" title="2">covariance_mat &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">c</span>(<span class="dv">10</span>, <span class="dv">6</span>, <span class="dv">6</span>, <span class="dv">15</span>), <span class="dt">ncol=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb898-3" title="3"><span class="kw">par</span>(<span class="dt">pty=</span><span class="st">&#39;s&#39;</span>)</a>
<a class="sourceLine" id="cb898-4" title="4"><span class="kw">plot</span>(<span class="kw">ellipse</span>(<span class="dt">x=</span>covariance_mat, <span class="dt">centre=</span>means_vec, <span class="dt">levels=</span><span class="fl">0.95</span>), </a>
<a class="sourceLine" id="cb898-5" title="5">     <span class="dt">type=</span><span class="st">&#39;l&#39;</span>,</a>
<a class="sourceLine" id="cb898-6" title="6">     <span class="dt">xlab=</span><span class="st">&quot;Rythme cardiaque à 7:00 (bpm)&quot;</span>,</a>
<a class="sourceLine" id="cb898-7" title="7">     <span class="dt">ylab=</span><span class="st">&quot;Rythme cardiaque à 8:00 (bpm)&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-ellipse-1.png" width="672" /></p>
<div class="sourceCode" id="cb899"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb899-1" title="1"><span class="co">#lines(ellipse(x=covariance_mat, centre=means_vec, level=0.8))</span></a></code></pre></div>
<p>On peut se poser la question: étant donnée que <span class="math inline">\(x_1 = 68\)</span>, quelle serait la distribution de <span class="math inline">\(x_2\)</span>? Dans ce cas bivariée, la distribution marginale serait univariée, mais dans le cas multivarié en <span class="math inline">\(D\)</span> dimensions, la distribution marginale où l’on spécifie <span class="math inline">\(m\)</span> variables serait de <span class="math inline">\(D-m\)</span>. de Une propriété fondamentale d’une distribution gaussienne est que peu importe l’endroit où l’angle selon lequel on la tranche, la distribution marginale sera aussi gaussienne. Lorsque l’on retranche une ou plusieurs variables en spécifiant la valeur qu’elles prennent, on applique un <em>conditionnement</em> à la distribution.</p>
<p><img src="_main_files/figure-html/ml-gp-multnorm-1.png" width="672" /></p>
<p>Les points sur l’axe (symbole x) conditionnés sont des échantillons tirés au hasard dans la distribution conditionnée.</p>
<p>Une autre manière de visualiser la distribution gaussienne binormale est de placer <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_2\)</span> côte à côte en abscisse, avec leur valeur en ordonnée. Le bloc de code suivant peut sembler lourd au premier coup d’œil: pas de panique, il s’agit surtout d’instructions graphiques. Vous pouvez vous amuser à changer les paramètres de la distribution binormale (section 1) ainsi que la valeur de <span class="math inline">\(x_1\)</span> à laquelle est conditionnée la distribution de <span class="math inline">\(x_2\)</span> (section 2).</p>
<p><img src="_main_files/figure-html/ml-gp-distr1-1.png" width="672" /></p>
<p>Les valeurs que peuvent prendre le rythme cardiaque en <span class="math inline">\(x_2\)</span> sont tirées aléatoirement d’une distribution conditionnée. Sautons maintenant au cas multinormal, incluant 6 variables (<em>hexanormal</em>!). Afin d’éviter de composer une matrice de covariance à la mitaine, je me permets de la générer avec une fonction. Cette fonction particulière est nommée <em>fonction de base radiale</em> ou <em>exponentiel de la racine</em>.</p>
<p><span class="math display">\[K_{RBF} \left( x_i, x_j \right) = \sigma^2 exp \left( -\frac{\left( x_i - x_j \right)^2}{2 l^2}  \right) \]</span></p>
<div class="sourceCode" id="cb900"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb900-1" title="1">RBF_kernel &lt;-<span class="st"> </span><span class="cf">function</span>(x, sigma, l) {</a>
<a class="sourceLine" id="cb900-2" title="2">  n &lt;-<span class="st"> </span><span class="kw">length</span>(x)</a>
<a class="sourceLine" id="cb900-3" title="3">  k &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">ncol =</span> n, <span class="dt">nrow =</span> n)</a>
<a class="sourceLine" id="cb900-4" title="4">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb900-5" title="5">    <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {</a>
<a class="sourceLine" id="cb900-6" title="6">      k[i, j] =<span class="st"> </span>sigma<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span><span class="op">/</span>(<span class="dv">2</span><span class="op">*</span>l<span class="op">^</span><span class="dv">2</span>) <span class="op">*</span><span class="st"> </span>(x[i] <span class="op">-</span><span class="st"> </span>x[j])<span class="op">^</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb900-7" title="7">    }</a>
<a class="sourceLine" id="cb900-8" title="8">  }</a>
<a class="sourceLine" id="cb900-9" title="9">  <span class="kw">colnames</span>(k) &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">&#39;x&#39;</span>, <span class="dv">1</span><span class="op">:</span>n)</a>
<a class="sourceLine" id="cb900-10" title="10">  <span class="kw">rownames</span>(k) &lt;-<span class="st"> </span><span class="kw">colnames</span>(k)</a>
<a class="sourceLine" id="cb900-11" title="11">  <span class="kw">return</span>(k)</a>
<a class="sourceLine" id="cb900-12" title="12">}</a></code></pre></div>
<p>Dans la fonction <code>RBF_kernel</code>, <code>x</code> désigne les dimensions, <code>sigma</code> désigne un écart-type commun à chacune des dimensions et <code>l</code> est la longueur désignant l’amplification de la covariance entre des dimensions éloignées (dans le sens que la première dimension est éloignée de la dernière). Pour 6 dimensions, avec un écart-type de 4 et une longueur de 2.</p>
<div class="sourceCode" id="cb901"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb901-1" title="1">covariance_<span class="dv">6</span> &lt;-<span class="st"> </span><span class="kw">RBF_kernel</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">sigma=</span><span class="dv">4</span>, <span class="dt">l=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb901-2" title="2"><span class="kw">round</span>(covariance_<span class="dv">6</span>, <span class="dv">2</span>)</a></code></pre></div>
<pre><code>##       x1    x2    x3    x4    x5    x6
## x1 16.00 14.12  9.70  5.19  2.17  0.70
## x2 14.12 16.00 14.12  9.70  5.19  2.17
## x3  9.70 14.12 16.00 14.12  9.70  5.19
## x4  5.19  9.70 14.12 16.00 14.12  9.70
## x5  2.17  5.19  9.70 14.12 16.00 14.12
## x6  0.70  2.17  5.19  9.70 14.12 16.00</code></pre>
<p>Changez la valeur de <code>l</code> permet de bien saisir son influence sur la matrice de covariance. Avec un <code>l</code> de 1, la covariance entre <span class="math inline">\(x_1\)</span> et <span class="math inline">\(x_6\)</span> est pratiquement nulle: elle est un peut plus élevée avec <code>l=2</code>. Pour reprendre l’exemple du rythme cardiaque, on devrait en effet s’attendre à retrouver une plus grande corrélation entre celles mesurées aux temps 4 et 5 qu’entre les temps 1 et 6.</p>
<p>De même que dans la situation où nous avions une distribution binormale, nous pouvons conditionner une distribution multinormale. Dans l’exemple suivant, je conditionne la distribution multinormale de 6 dimensions en spécifiant les valeurs prises par les deux premières dimensions. Le résultat du conditionnement est une distribution en 4 dimensions. Puisqu’il est difficile de présenter une distribution en 6D, le graphique en haut à gauche ne comprend que les dimensions 1 et 6. Remarquez que la corrélation entre les dimensions 1 et 6 est faible, en concordance avec la matrice de covariance générée par la fonction <code>RBF_kernel</code>. Lancez plusieurs fois le code et voyez ce qui advient des échantillonnages dans les dimensions 3 à 6 selon le conditionnement en 1 et 2.</p>
<p><img src="_main_files/figure-html/ml-gp-cond-6d-1.png" width="672" /></p>
<p>La structure de la covariance assure que les dimensions proches prennent des valeurs similaires, assurant une courbe lisse et non en dents de scie. Pourquoi s’arrêter à 6 dimensions? Prenons-en plusieurs, puis générons plus d’un échantillon. Ensuite, utilisons ces simulations pour de calculer la moyenne et l’écart-type de chacune des dimensions.</p>
<p><img src="_main_files/figure-html/ml-gp-cond-65-1.png" width="672" /></p>
<p>Revenons au rythme cardiaque. On pourra utiliser le conditionnement aux temps observés, soit 7:00, 8:00, 10:00, 14:00 et 17:00 pour estimer la distribution à 12:00 et 16:00, où à des dimensions artificielles quelconques ici fixées aux demi-heures.</p>
<p><img src="_main_files/figure-html/ml-gp-cond-bpm-1.png" width="672" /></p>
<p>Comme on devrait s’y attendre, la régression résultant de la mise en indices de la distribution est précise aux mesures, et imprécise aux indices peu garnis en mesures. Nous avions utilisé 21 dimensions. <strong>Lorsque l’on généralise la procédure à une quantité infinie de dimensions, on obtient un <em>processus gaussien</em>.</strong></p>
<p><img src="https://media.giphy.com/media/12R2bKfxceemNq/giphy.gif" /></p>
<p>L’indice de la variable devient ainsi une valeur réelle. Un processus gaussien, <span class="math inline">\(\mathcal{GP}\)</span>, est défini par une fonction de la moyenne, <span class="math inline">\(m \left( x \right)\)</span>, et une autre de la covariance que l’on nomme <em>noyau</em> (ou <em>kernel</em>), <span class="math inline">\(K \left( x, x&#39; \right)\)</span>. Un processus gaussien est noté de la manière suivante:</p>
<p><span class="math display">\[\mathcal{GP} \sim \left( m \left( x \right), K \left( x, x&#39; \right) \right)\]</span></p>
<p>La fonction définissant la moyenne peut être facilement écartée en s’assurant de centrer la variable réponse à zéro (<span class="math inline">\(y_{centré} = y - \hat{y}\)</span>). Ainsi, par convention, on spécifie une fonction de moyenne comme retournant toujours un zéro. Quant au noyau, il peut prendre différentes fonctions de covariance ou combinaisons de fonctions de covariance. Règle générale, on utilisera un noyau permettant de définir deux paramètres: la hauteur (<span class="math inline">\(\sigma\)</span>) et la longueur de l’ondulation (<span class="math inline">\(l\)</span>) (figure <a href="#fig:gp-hyperp"><strong>??</strong></a>).</p>
<div class="figure" style="text-align: center"><span id="fig:ml-gp-hyperp"></span>
<img src="_main_files/figure-html/ml-gp-hyperp-1.png" alt="Hyperparamètres d'un noyau RBF." width="100%" />
<p class="caption">
Figure 11.9: Hyperparamètres d’un noyau RBF.
</p>
</div>
<p>On pourra ajouter à ce noyau un bruit blanc, c’est-à-dire une variation purement aléatoire, sans covariance (noyau générant une matrice diagonale).</p>
<p>Le noyau devient ainsi un <em>a priori</em>, et le processus gaussien conditionné aux données devient un <em>a posteriori</em> probabiliste.</p>
<p>Finalement, les processus gaussiens peuvent être extrapolés à plusieurs variables descriptives.</p>
</div>
</div>
<div id="les-processus-gaussiens-en-r" class="section level3">
<h3><span class="header-section-number">11.4.5</span> Les processus gaussiens en <code>R</code></h3>
<p>Pas de souci, vous n’aurez pas à programmer vos propres fonctions pour lancer des processus gaussiens. Vous pourrez <a href="https://topepo.github.io/caret/train-models-by-tag.html#gaussian-process">passer par <code>caret</code></a>. Vous pourriez, comme c’est le cas avec les réseaux neuronnaux, obtenir davantage de contrôle sur l’autoapprentissage en utilisant directement la fonction <code>gausspr()</code> du package <strong><code>kernlab</code></strong>.</p>
<div class="sourceCode" id="cb903"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb903-1" title="1"><span class="kw">library</span>(<span class="st">&quot;kernlab&quot;</span>)</a></code></pre></div>
<pre><code>## 
## Attaching package: &#39;kernlab&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:scales&#39;:
## 
##     alpha</code></pre>
<pre><code>## The following object is masked from &#39;package:permute&#39;:
## 
##     how</code></pre>
<pre><code>## The following object is masked from &#39;package:purrr&#39;:
## 
##     cross</code></pre>
<pre><code>## The following object is masked from &#39;package:ggplot2&#39;:
## 
##     alpha</code></pre>
<div class="sourceCode" id="cb909"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb909-1" title="1">x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">7</span>, <span class="dv">8</span>, <span class="dv">10</span>, <span class="dv">14</span>, <span class="dv">17</span>)</a>
<a class="sourceLine" id="cb909-2" title="2">y &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">61</span>, <span class="dv">74</span>, <span class="dv">69</span>, <span class="dv">67</span>, <span class="dv">78</span>)</a>
<a class="sourceLine" id="cb909-3" title="3">y_sc &lt;-<span class="st"> </span>(y <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(y)</a>
<a class="sourceLine" id="cb909-4" title="4"></a>
<a class="sourceLine" id="cb909-5" title="5">m &lt;-<span class="st"> </span><span class="kw">gausspr</span>(x, y_sc, </a>
<a class="sourceLine" id="cb909-6" title="6">             <span class="dt">kernel =</span> <span class="st">&#39;rbfdot&#39;</span>, <span class="co"># le noyau: différents types disponibles (?gausspr)</span></a>
<a class="sourceLine" id="cb909-7" title="7">             <span class="dt">kpar =</span> <span class="kw">list</span>(<span class="dt">sigma =</span> <span class="dv">4</span>), <span class="co"># hyperparamètre du noyau (l est optimisé)</span></a>
<a class="sourceLine" id="cb909-8" title="8">             <span class="dt">variance.model =</span> <span class="ot">TRUE</span>, <span class="co"># pour pouvoir générer les écarts-type</span></a>
<a class="sourceLine" id="cb909-9" title="9">             <span class="dt">scaled =</span> <span class="ot">TRUE</span>, <span class="co"># mettre à l&#39;échelle des variables</span></a>
<a class="sourceLine" id="cb909-10" title="10">             <span class="dt">var =</span> <span class="fl">0.01</span>, <span class="co"># bruit blanc</span></a>
<a class="sourceLine" id="cb909-11" title="11">             <span class="dt">cross =</span> <span class="dv">2</span>) <span class="co"># nombre de plis de la validation croisée</span></a>
<a class="sourceLine" id="cb909-12" title="12"></a>
<a class="sourceLine" id="cb909-13" title="13">xtest &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">6</span>, <span class="dv">18</span>, <span class="dt">by =</span> <span class="fl">0.1</span>)</a>
<a class="sourceLine" id="cb909-14" title="14">y_sc_pred_mean &lt;-<span class="st"> </span><span class="kw">predict</span>(m, xtest, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb909-15" title="15">y_pred_mean &lt;-<span class="st"> </span>y_sc_pred_mean <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(y)</a>
<a class="sourceLine" id="cb909-16" title="16">y_sc_pred_sd &lt;-<span class="st"> </span><span class="kw">predict</span>(m, xtest, <span class="dt">type=</span><span class="st">&quot;sdeviation&quot;</span>) <span class="co"># &quot;sdeviation&quot; en régression et &quot;probabilities&quot; pour la classification</span></a>
<a class="sourceLine" id="cb909-17" title="17">y_pred_sd &lt;-<span class="st"> </span>y_sc_pred_sd <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(y)</a>
<a class="sourceLine" id="cb909-18" title="18"></a>
<a class="sourceLine" id="cb909-19" title="19"><span class="kw">plot</span>(x, y, <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="dv">6</span>, <span class="dv">18</span>), <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">45</span>, <span class="dv">90</span>))</a>
<a class="sourceLine" id="cb909-20" title="20"><span class="kw">lines</span>(xtest, y_pred_mean)</a>
<a class="sourceLine" id="cb909-21" title="21"><span class="kw">lines</span>(xtest, y_pred_mean <span class="op">+</span><span class="st"> </span>y_pred_sd, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb909-22" title="22"><span class="kw">lines</span>(xtest, y_pred_mean <span class="op">-</span><span class="st"> </span>y_pred_sd, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb909-23" title="23"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">12</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">12</span>, <span class="dv">67</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a>
<a class="sourceLine" id="cb909-24" title="24"><span class="kw">abline</span>(<span class="dt">v=</span><span class="dv">16</span>, <span class="dt">lty=</span><span class="dv">3</span>, <span class="dt">col=</span><span class="st">&#39;gray50&#39;</span>);<span class="kw">text</span>(<span class="dv">16</span>, <span class="dv">72</span>, <span class="st">&#39;?&#39;</span>, <span class="dt">cex=</span><span class="dv">2</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-kernlab-1.png" width="672" /></p>
<div id="application-pratique" class="section level4">
<h4><span class="header-section-number">11.4.5.1</span> Application pratique</h4>
<p>Les processus gaussiens sont utiles pour effectuer des prédictions sur des phénomène sur lesquels on désire éviter de se commettre sur la structure. Les séries temporelles ou les signaux spectraux en sont des exemples. Aussi, j’ai utilisé les processus gaussiens pour modéliser des courbes de réponse aux fertilisants. Prenons ces données générées au hasard, comprenant l’identifiant de la mesure, le bloc du test, la dose de fertilisant, trois variables environnementales ainsi que la performance de la culture en terme de rendement.</p>
<div class="sourceCode" id="cb910"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb910-1" title="1">fert &lt;-<span class="st"> </span><span class="kw">read_csv</span>(<span class="st">&quot;data/11_response_fert.csv&quot;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb911"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb911-1" title="1">fert <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb911-2" title="2"><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Dose, <span class="dt">y =</span> Yield)) <span class="op">+</span></a>
<a class="sourceLine" id="cb911-3" title="3"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">group =</span> Block), <span class="dt">colour =</span> <span class="kw">rgb</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="fl">0.5</span>))</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-pratique2-1.png" width="672" /></p>
<p>Les blocs 1 à 30 serviront d’entraînement, les autres de test. Le rendement est mis à l’échelle pour la modélisation.</p>
<div class="sourceCode" id="cb912"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb912-1" title="1">environment &lt;-<span class="st"> </span>fert <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb912-2" title="2"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(Dose, var1, var2, var3)</a>
<a class="sourceLine" id="cb912-3" title="3">yield_sc &lt;-<span class="st"> </span>(fert<span class="op">$</span>Yield <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)) <span class="op">/</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb912-4" title="4"></a>
<a class="sourceLine" id="cb912-5" title="5">environment_tr &lt;-<span class="st"> </span>environment[fert<span class="op">$</span>Block <span class="op">&lt;=</span><span class="st"> </span><span class="dv">30</span>, ]</a>
<a class="sourceLine" id="cb912-6" title="6">environment_te &lt;-<span class="st"> </span>environment[fert<span class="op">$</span>Block <span class="op">&gt;</span><span class="st"> </span><span class="dv">30</span>, ]</a>
<a class="sourceLine" id="cb912-7" title="7">yield_tr &lt;-<span class="st"> </span>yield_sc[fert<span class="op">$</span>Block <span class="op">&lt;=</span><span class="st"> </span><span class="dv">30</span>]</a>
<a class="sourceLine" id="cb912-8" title="8">yield_te &lt;-<span class="st"> </span>yield_sc[fert<span class="op">$</span>Block <span class="op">&gt;</span><span class="st"> </span><span class="dv">30</span>]</a></code></pre></div>
<p>Je pourrais optimiser les hyperparamètres en créant une grille puis en lançant plusieurs processus gaussiens en boucle. Mais pour l’exemple j’utilise des hyperparamètres quelconque.</p>
<div class="sourceCode" id="cb913"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb913-1" title="1">yield_gp &lt;-<span class="st"> </span><span class="kw">gausspr</span>(environment_tr, yield_tr, <span class="dt">kernel =</span> <span class="st">&#39;rbfdot&#39;</span>,</a>
<a class="sourceLine" id="cb913-2" title="2">                    <span class="dt">kpar =</span> <span class="kw">list</span>(<span class="dt">sigma =</span> <span class="fl">0.1</span>),</a>
<a class="sourceLine" id="cb913-3" title="3">                    <span class="dt">variance.model =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb913-4" title="4">                    <span class="dt">scaled =</span> <span class="ot">TRUE</span>,</a>
<a class="sourceLine" id="cb913-5" title="5">                    <span class="dt">var =</span> <span class="fl">0.1</span>,</a>
<a class="sourceLine" id="cb913-6" title="6">                    <span class="dt">cross =</span> <span class="dv">10</span>)</a>
<a class="sourceLine" id="cb913-7" title="7"></a>
<a class="sourceLine" id="cb913-8" title="8"><span class="co"># rendements prédits dans l&#39;échelle originale</span></a>
<a class="sourceLine" id="cb913-9" title="9">gp_pred_tr &lt;-<span class="st"> </span><span class="kw">predict</span>(yield_gp, environment_tr, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb913-10" title="10">gp_pred_te &lt;-<span class="st"> </span><span class="kw">predict</span>(yield_gp, environment_te, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>) <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb913-11" title="11"></a>
<a class="sourceLine" id="cb913-12" title="12"><span class="co"># rendements réels dans l&#39;échelle originale</span></a>
<a class="sourceLine" id="cb913-13" title="13">yield_tr_os &lt;-<span class="st"> </span>yield_tr <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb913-14" title="14">yield_te_os &lt;-<span class="st"> </span>yield_te <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb913-15" title="15"></a>
<a class="sourceLine" id="cb913-16" title="16"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</a>
<a class="sourceLine" id="cb913-17" title="17"><span class="kw">plot</span>(yield_tr_os, gp_pred_tr, <span class="dt">main =</span> <span class="st">&quot;train&quot;</span>)</a>
<a class="sourceLine" id="cb913-18" title="18"><span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb913-19" title="19"><span class="kw">plot</span>(yield_te_os, gp_pred_te, <span class="dt">main =</span> <span class="st">&quot;test&quot;</span>)</a>
<a class="sourceLine" id="cb913-20" title="20"><span class="kw">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-pratique4-fit-1.png" width="672" /></p>
<p>La prédiction semble bien fonctionner en entraînement comme en test. Pour une application à un cas d’étude, disons que pour mon site j’ai des variables environnementales de valeurs du bloc 50, et que je cherche la dose optmale.</p>
<div class="sourceCode" id="cb914"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb914-1" title="1">fert <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb914-2" title="2"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">filter</span>(Block <span class="op">==</span><span class="st"> </span><span class="dv">50</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb914-3" title="3"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">select</span>(var1, var2, var3) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb914-4" title="4"><span class="st">  </span>dplyr<span class="op">::</span><span class="kw">slice</span>(<span class="dv">1</span>)</a></code></pre></div>
<pre><code>## # A tibble: 1 x 3
##    var1  var2  var3
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  1.57  101. -10.7</code></pre>
<p>Je peux créer un tableau comprenant des environnements égaux pour chaque ligne, mais comprenant des incréments de dose, puis prédire la courbe de réponse ainsi que son incertitude. Et puisque c’est un cas documenté, je peux afficher les résultats de l’essai pour vérifier si le modèle est crédible.</p>
<div class="sourceCode" id="cb916"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb916-1" title="1">environment_appl &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Dose =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">200</span>, <span class="dv">5</span>), <span class="dt">var1 =</span> <span class="fl">1.57</span>, <span class="dt">var2 =</span> <span class="fl">101.5</span>, <span class="dt">var3 =</span> <span class="fl">-10.7</span>)</a>
<a class="sourceLine" id="cb916-2" title="2">yield_appl_sc &lt;-<span class="st"> </span><span class="kw">predict</span>(yield_gp, environment_appl, <span class="dt">type=</span><span class="st">&quot;response&quot;</span>)</a>
<a class="sourceLine" id="cb916-3" title="3">y_sc_pred_sd_sc &lt;-<span class="st"> </span><span class="kw">predict</span>(yield_gp, environment_appl, <span class="dt">type=</span><span class="st">&quot;sdeviation&quot;</span>)</a>
<a class="sourceLine" id="cb916-4" title="4"></a>
<a class="sourceLine" id="cb916-5" title="5">yield_appl &lt;-<span class="st"> </span>yield_appl_sc <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield) <span class="op">+</span><span class="st"> </span><span class="kw">mean</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb916-6" title="6">yield_appl_sd &lt;-<span class="st"> </span>y_sc_pred_sd_sc <span class="op">*</span><span class="st"> </span><span class="kw">sd</span>(fert<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb916-7" title="7"></a>
<a class="sourceLine" id="cb916-8" title="8"><span class="kw">plot</span>(environment_appl<span class="op">$</span>Dose, yield_appl, <span class="dt">type =</span> <span class="st">&quot;l&quot;</span>, <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">35</span>))</a>
<a class="sourceLine" id="cb916-9" title="9"><span class="kw">points</span>(<span class="dt">x =</span> fert[fert<span class="op">$</span>Block <span class="op">==</span><span class="st"> </span><span class="dv">50</span>, ]<span class="op">$</span>Dose, <span class="dt">y =</span> fert[fert<span class="op">$</span>Block <span class="op">==</span><span class="st"> </span><span class="dv">50</span>, ]<span class="op">$</span>Yield)</a>
<a class="sourceLine" id="cb916-10" title="10"><span class="kw">lines</span>(environment_appl<span class="op">$</span>Dose, yield_appl <span class="op">+</span><span class="st"> </span>yield_appl_sd, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a>
<a class="sourceLine" id="cb916-11" title="11"><span class="kw">lines</span>(environment_appl<span class="op">$</span>Dose, yield_appl <span class="op">-</span><span class="st"> </span>yield_appl_sd, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>)</a></code></pre></div>
<p><img src="_main_files/figure-html/ml-gp-pratique-rep-table-1.png" width="672" /></p>
<p>&lt;our chaque incrément de dose de la courbe de rponse, il est possible de calculer un rendement économique et/ou écologique en fonction du prix de la dose pondéré par un coût environnemental, puis de soutirer une performance optimale en terme de fertilisation.</p>
<p><strong>Exercice</strong>. Changez les valeurs des variables environnementales pour générer le tableau <code>environment_appl</code> avec des valeurs qui sortent du lot (voir figure <a href="#fig:variables-env"><strong>??</strong></a>). Qu’observez-vous? Pourquoi?</p>
<div class="figure" style="text-align: center"><span id="fig:ml-variables-env"></span>
<img src="_main_files/figure-html/ml-variables-env-1.png" alt="Vairables environnementales du tableau fictif `fert`." width="100%" />
<p class="caption">
Figure 11.10: Vairables environnementales du tableau fictif <code>fert</code>.
</p>
</div>
<p><strong>Exercice</strong>. Effectuer la prédiction du rendement avec d’autres techniques, comme des réseaux neuronaux. Comment les modèles se comportent-ils?</p>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chapitre-outliers.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="chapitre-temps.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
