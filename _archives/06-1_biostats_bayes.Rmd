--- 
site: bookdown::bookdown_site
output: bookdown::gitbook
---

# Introduction à l'analyse bayésienne en écologie {#chapitre-biostats-bayes}

 ***
️\ **Objectifs spécifiques**:

**Ce chapitre est un extra. Il ne fait pas partie des objectifs du cours. Il ne sera pas évalué.**

À la fin de ce chapitre, vous

- serez en mesure de définir ce que sont les statistiques bayésiennes
- serez en mesure de calculer des statistiques descriptives de base en mode bayésien avec le module [**`greta`**](https://greta-stats.org/).

 ***

Les statistiques bayésiennes forment une trousse d'outils à garder dans votre *packsack*.

## Qu'est-ce que c'est?

En deux mots: modélisation probabiliste. Un approche de modélisation probabiliste se servant au mieux de l'information disponible. Pour calculer les probabilités d'une variable inconnu en mode bayésien, nous avons besoin:

* De données
* D'un modèle
* D'une idée plus ou moins précise du résultat avant d'avoir analysé les données

De manière plus formelle, le théorème de Bayes (qui forme la base de l'analyse bayéseienne), dit que la distribution de probabilité des paramètres d'un modèle (par exemple, la moyenne ou une pente) est proportionnelle à la mutliplication de la distribution de probabilité estimée des paramètres et la distribution de probabilité émergeant des données.

Plus formellement,

$$P\left(\theta | y \right) = \frac{P\left(y | \theta \right) \times P\left(\theta\right)}{P\left(y \right)}$$,

où $P\left(\theta | y \right)$ $-$ la probabilité d'obtenir des paramètres $\theta$ à partir des données $y$ $-$ est la distribution de probabilité *a posteriori*, calculée à partir de votre *a prioti* $P\left(\theta\right)$ $-$ la probabilité d'obtenir des paramètres $\theta$ sans égard aux données, selon votre connaissance du phénomène $-$ et vos données observées $P\left(y | \theta \right)$ $-$ la probabilité d'obtenir les données $y$ étant donnés les paramètres $\theta$ qui régissent le phénomène. $P\left(y\right)$, la probabilité d'observer les données, est appellée la *vraissemblance marginale*, et assure que la somme des probabilités est nulle.

## Pourquoi l'utiliser?

Avec la notion fréquentielle de probabilité, on teste la probabilité d'observer les données recueillies étant donnée l'absence d'effet réel (qui est l'hypothèse nulle généralement adoptée). La notion bayésienne de probabilité combine la connaissance que l'on a d'un phénomène et les données observées pour estimer la probabilité qu'il existe un effet réel. En d'autre mots, les stats fréquentielles testent si les données concordent avec un modèle du réel, tandis que les stats bayésiennes évaluent, selon les données, la probabilité que le modèle soit réel.

Le hic, c'est que lorsqu'on utilise les statistiques fréquentielles pour répondre à une question bayésienne, on s'expose à de mauvaises interprétations. Par exemple, lors d'un projet considérant la vie sur Mars, les stats fréquentielles évalueront si les données recueillies sont conformes ou non avec l'hypothèse de la vie sur Mars. Par contre, pour évaluer la *probabilité de l'existance de vie sur Mars*, on devra passer par les stats bayésiennes (exemple tirée du billet [Dynamic Ecology -- Frequentist vs. Bayesian statistics: resources to help you choose](https://dynamicecology.wordpress.com/2011/10/11/frequentist-vs-bayesian-statistics-resources-to-help-you-choose/)).

## Comment l'utiliser?

Bien que la formule du théorème de Bayes soit plutôt simple, calculer une fonction *a posteriori* demandera de passer par des algorithmes de simulation, ce qui pourrait demander une bonne puissance de calcul, et des outils appropriés. R comporte une panoplie d'outils pour le calcul bayésien générique ([**`rstan`**](https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started), [**`rjags`**](https://cran.r-project.org/web/packages/rjags/index.html), [**`MCMCpack`**](https://cran.r-project.org/web/packages/MCMCpack/index.html), etc.), et d'autres outils pour des besoins particuliers ([**`brms`**: R package for Bayesian generalized multivariate non-linear multilevel models using Stan](https://github.com/paul-buerkner/brms)). Nous utiliserons ici le module générique [**`greta`**](https://greta-stats.org/), qui permet de générer de manière conviviale plusieurs types de modèles bayésiens.

Pour installer **`greta`**, vous devez préalablement installer Python, gréé des modules Python **`tensorflow`** et **`tensorflow-probability`** en suivant [le guide](https://greta-stats.org/articles/get_started.html). En somme, vous devez d'abord installer **`greta`** (`install.packages("greta")`) et **`tensorflow`** (`install.packages("tensorflow")`). Puis vous devez installer une distribution de Python -- je vous suggère [Anaconda](https://www.anaconda.com/download) (~500 Mo) ou [Miniconda](https://conda.io/miniconda.html) pour une installation minimale (~60 Mo). Enfin, lancez les commandes suivantes (une connection internet est nécessaire pour télécharger les modules). Si vous avez installé la version complète d'Anaconda, vous avez accès à Anaconda-navigator, une interface pour la gestion de vos environnements de calcul: assurez-vous qu'il soit fermé pour éviter que la commande se butte à des fichiers verouillés.

```#{r}
 greta::install_tensorflow(
    method = "conda",
    envname = "r-greta",
    version = "1.14.0",
    extra_packages = "tensorflow-probability==0.7.0"
  )
```

## Faucons pélerins

Empruntons un exemple du livre [Introduction to WinBUGS for Ecologists: A Bayesian Approach to Regression, ANOVA and Related Analyses](https://www.elsevier.com/books/introduction-to-winbugs-for-ecologists/kery/978-0-12-378605-0), de Marc Kéry et examinons la masse de faucons pélerins. Mais alors que Marc Kéry utilise WinBUGS, un logiciel de résolution de problème en mode bayésien, nous utiliserons greta.

![](https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/Falco_peregrinus_-_01.jpg/1024px-Falco_peregrinus_-_01.jpg)
Source: [Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Falco_peregrinus_-_01.jpg)

Pour une première approche, nous allons estimer la masse moyenne d'une population de faucons pélerins.

À titre de données, générons des nombres aléatoires. Cette stratégie permet de valider les statistiques en les comparant aux paramètre que l'on impose. Ici, nous imposons une moyenne de 600 grammes et un écart-type de 30 grammes. Générons une séries de données avec 20 échantillons.

```{r bayes-falcon-data}
library("tidyverse")
set.seed(5682)
y20 <- rnorm(n = 20, mean=600, sd = 30)
y200 <- rnorm(n = 200, mean=600, sd = 30)
par(mfrow = c(1, 2))
hist(y20, breaks=5)
hist(y200, breaks=20)
```

Je crée une fonction qui retourne la moyenne et l'erreur sur la moyenne ou sur la distribution. Calculons les statistiques classiques.

```{r bayes-ci-function}
confidence_interval <- function(x, on="deviation", distribution="t", level=0.95) {
  m <- mean(x)
  se <- sd(x)
  n <- length(x)
  if (distribution == "t") {
    error <- se * qt((1+level)/2, n-1)
  } else if (distribution == "normal") {
    error <- se * qnorm((1+level)/2)
  }
  if (on == "error") {
    error <- error/sqrt(n)
  }
  return(c(ll = m-error, mean = m, ul = m+error))
}
```

```{r bayes-print-falcon-stats}
print("Déviation, 95%")
print(round(confidence_interval(y20, on='deviation', level=0.95), 2))

print("Erreur, 95%")
print(round(confidence_interval(y20, on='error', level=0.95), 2))

print("Écart-type")
print(round(sd(y20), 2))
```

En faisant cela, nous prenons pour acquis que les données sont distribuées normalement. En fait, nous savons qu'elles devraient l'être pour de grands échantillons, puisque nous avons nous-même généré les données. Par contre, comme observateur par exemple de la série de 20 données générées, la distribution est définitivement asymétrique. Sous cet angle, la moyenne, ainsi que l'écart-type, pourraient être des paramètres biaisés. Nous pouvons justifier le choix d'une loi normale par des connaissances a priori des distributions de masse parmi des espèces d'oiseau. Ou bien transformer les données pour rendre leur distribution normale (chapitre \@ref(chapitre-explorer)).

## Statistiques d'une population

### Calcul analytique

Supposer une distribution normale d'une population implique d'estimer deux paramètres: sa moyenne et son écart-type. Toutefois, pour cet exemple, nous supposons que l'écart-type est connu, ce qui n'est à toute fin pratique jamais le cas, mais vous découvrirez bientôt pourquoi nous laisse tomber l'écart-type à cette étape. Nous allons donc estimer la moyenne d'une population de faucons dont l'écart-type est de 30: $X \sim \mathcal{N}(\mu, 30)$.

On sait qu'une distribution normale est définir par la fonction suivante.

$$f(x) = \frac{1}{\sigma \sqrt{2\pi} } e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}$$

Ou, en R:
  
```{r bayes-normal-distribution-function}
normdist <- function(x, mean, sd) {
  f <- 1 / (sd * sqrt(2*pi)) * exp(-0.5 * ((x-mean)/sd)^2)
  return(f)
}
```

Ce qui n'est utile que pour une petite démonstration, étant donnée cette opération peut être effectuée avec la fonction `dnorm()`, qui vient avec le module **`stats`** chargé en R par défaut.

```{r bayes-normal-distribution-plot}
x_ <- seq(0, 2000, 100)
plot(x_, dnorm(x = x_, mean = 750, sd = 300), "l", lwd = 4, col = "pink")
points(x_, normdist(x = x_, mean = 750, sd = 300))
```

Reprenons notre équation de Bayes.

$$P\left(\theta | y \right) = \frac{P\left(y | \theta \right) \times P\left(\theta\right)}{P\left(y \right)}$$,

En mode bayésien, nous devons définir la connaissance *a priori*, P\left(\theta\right), sous forme de variables aléatoires non-observées selon une distribution. Prenons l'exemple des faucons pélerins. Disons que nous ne savons pas à quoi ressemble la moyenne du groupe a priori. Nous pouvons utiliser un *a priori* peu informatif, où la masse moyenne peut prendre n'importe quelle valeur entre 0 et 2000 grammes, sans préférence: nous lui imposons donc un a priori selon une distribution uniforme. Idem pour l'écart-type. C'est ce qu'on appelle des *a priori* plats. Mais il est plutôt conseiller ([Gelman et al., 2013](http://www.stat.columbia.edu/~gelman/book/)) d'utiliser des *a priori* vagues plutôt que plats ou non-informatifs. En effet, des masses de 0 g ou 2000 g ne sont pas aussi probables qu'une masse de 750 g. Si vous étudiez les faucons pélerins (ce qui n'est pas mon cas), vous aurez une idée de sa masse, ne serait-ce qu'en arcourrant la littérature à son sujet. Mais disons que j'estime très vaguement qu'une masse moyenne échantillonale devrait être autour de 750 g, avec un large écart-type de 200 g sur la moyenne. Il s'agit de l'écart-type de la moyenne, pas de l'écart-type de l'échantillon que nous supposons être connu. Notez que l'*a priori* peu avoir la forme que l'on désire: il s'agit seulement de créer un vecteur. Toutefois, générer ce vecteur avec des distributions connues est aussi pratique qu'élégant.

```{r bayes-mass-prior-plot}
x_mean <- seq(400, 1200, 5)
prob <- tibble(mass = x_mean, 
               Prior = dnorm(x = x_mean, mean = 750, sd = 200))

prob$Prior <- prob$Prior / sum(prob$Prior)

prob %>% 
  ggplot(aes(mass, Prior))+
  geom_line() +
  expand_limits(y=0)
```

Note sur le jargon: étant donnée que cet *a priori* aura la même distribution que l'*a posteriori*, on dit que cet *a priori* est *conjugué*.

Nous allons également utiliser nos données pour créer une fonction de vraissemblance (likelihood), $P\left(y | \theta \right)$, qui est la distribution de probabilité issue des données: une distribution normale avec une moyenne calculée et une variance connue.

```{r bayes-mass-likelihood-plot}
prob$Likelihood <- dnorm(x = x_mean, mean = mean(y20), sd = 30)
prob$Likelihood <- prob$Likelihood / sum(prob$Likelihood)

prob %>% 
  pivot_longer(-mass, names_to = "type", values_to = "probability") %>% 
  ggplot(aes(mass, probability, colour = type)) +
  geom_line() +
  expand_limits(y=0)
```

Noter distribution *a posteriori* est proportionnelle à la multiplication de l'*a priori* et de la vraissemblance. Puis nous allons normaliser l'*a posteriori* pour faire en sorte que la somme des probabilités soit de 1.

```{r bayes-mass-posterior-plot}
prob$Posterior <- prob$Likelihood * prob$Prior
prob$Posterior <- prob$Posterior / sum(prob$Posterior)

prob %>% 
  pivot_longer(-mass, names_to = "type", values_to = "probability") %>% 
  ggplot(aes(mass, probability, colour = type)) +
  geom_line() +
  expand_limits(y=0)
```

La distribution *a posteriori* est presque callée sur les données. Pas étonnant, étant donnée que l'*a priori* est très vague. En revanche, un *a priori* plus affirmé, avec un écart-type plus faible, aurait davantage de poids sur l'*a posteriori*.

> **Exercice**. Changez l'*a priori* et visualisez l'effet sur l'*a posteriori*.

Maintenant, imaginez ajouter l'écart-type. Cela reste faisable en calcul analytique, mais ça complique le calcul pour normaliser les proabilité. Ajoutez encore une variable et le calcul bayésien devient un véritable casse-tête. En fait, en bayésien, la difficulté de mettre à l'échelle de plus d'un paramètre rend rare la multiplication distributions de probabilité. C'est pourquoi l'on préfère les simuler et échantillonnant, à l'aide de différents algorithmes, la distribution *a posteriori*. En R, le module **`greta`** est conçu pour cela.

### greta

Chargeons d'abord les modules nécessaires. Avant de charger **`greta`**, il faut sélectionner l'environnement conda (Python) auquel se connecter. Lors de l'installation, nous avions spécifié que l'installation se fasse dans l'environnement nommé `r-greta`.

```{r bayes-load-greta-packages}
# se connecter à l'environnement Python
library("reticulate")
use_condaenv("r-greta", required = TRUE) 

# charger les modules pour l'analyse bayésienne
library("greta")
library("DiagrammeR")
library ("bayesplot")
library("tidybayes")
```

Reprenons l'*a piori* utilisé précédemment. Dans **`greta`**, nous définissons notre *a priori* ainsi.

```{r bayes-greta-prior}
param_mean <- normal(mean = 750, 200)
```

L'écart-type d'un échantillon ne peut pas être négatif. Il est commun pour les écarts-types d'utiliser une distribution en tronquée à 0. On pourrait utiliser une normale tronquée, mais la cauchy tronquée est souvent recommandée (e.g. [Gelman, 2006](http://www.stat.columbia.edu/~gelman/research/published/taumain.pdf)) puisque la queue, plus épaisse que la distribution normale, permet davantage de flexibilité. Disons que nous supposons un écart-type d'une moyenne de 50, et d'un écart-type de 100, tronqué à 0.

```{r bayes-greta-sd-prior}
x_ <- seq(0, 500, 10)
plot(x_, dcauchy(x = x_, location = 50, scale = 100), "l")
param_sd <- cauchy(location = 50, scale = 100, dim = NULL, truncation = c(0, Inf))
```

La fonction *a porteriori* inclue la fonction de vraissemblance ainsi que la connaissance *a priori*.

```{r bayes-greta-distribution}
distribution(y20) <- normal(param_mean, param_sd)
```

Le tout forme un modèle pour apprécier la masse des faucons pélerins.

```{r bayes-greta-model-plot}
m <- model(param_mean, param_sd)
plot(m)
```

**Légende**:

![](images/5-1_legende.png)

Le graphique du modèle montre que deux paramètres, `praram_sd` et `param_mean` sont attachés à leur distribution respective pour générer une distribution de sortie.

Lançons le modèle avec 2000 échantillons suivant une phase d'initiation (*warmup*) de 1000 échantillons. La phase d'initiation donne à l'échantillonnage l'occasion de converger avant d'être considérée la la distribution *a posteriori*. Ces nombres, 2000 et 1000, pourraient être plus élevés. Je les garde bas pour accélérer les calculs.

Le taux d'amincissement, *thin*, spécifie qu'e l'on ne retient qu'un échantillon sur la valeur indiquée, ce qui permet de contrôler l'autocorrélation dans la chaîne de Markov. Dans ce cas, nous allons utiliser 2. La valeur par défaut est de 1.

L'échantillonnage peut utiliser autant de chaînes de Markov qu'il y a de processeurs sur l'ordinateur.

```{r bayes-draw-mcmc-simple}
draws <- mcmc(m, n_samples = 2000, warmup = 1000, thin = 2, chains = 4)
```

L'inspection de l'échantillonnage peut être effectuée grâce au module bayesplot.

```{r bayes-greta-plot-simple}
mcmc_combo(draws, combo = c("hist", "trace")) # "dens" pour les courbes de densité
```

À gauche, nous obtenons la distribution des paramètres. À droite, nous pouvons observer que l'échantillonnage semble stable: la *"chenille"* est droite avec un bruit constant. Dans le cas où il ne le serait pas, il faudrait revoir le modèle, peut-être en changeatn sa structure ou en changeant les paramètres de convergence. Nous pouvons calculer des intervales de crédibilté.

```{r bayes-greta-simple-statistics}
draws_tidy <- draws %>%
  spread_draws(param_mean, param_sd)

draws_mean <- confidence_interval(x = draws_tidy$param_mean, on = "deviation", distribution = "normal", level = 0.95)
print("Moyenne:")
draws_mean

draws_sd <- confidence_interval(x = draws_tidy$param_sd, on = "deviation", distribution = "normal", level = 0.95)
print("Écart-type:")
draws_sd
```

L'*a priori* étant vague, les résultats de l'analyse bayésienne sont comparables aux statistiques fréquentielles.

```{r bayes-greta-simple-compare-freq}
print("Erreur, 95%")
print(round(confidence_interval(y20, on='error', level=0.95), 2))
```

Les résultats des deux approches doivent néanmoins être interprétés de manière différente. En ce qui a trait à la moyenne:

- **Fréquentiel**. Il y a une probabilité de 95% que mes données aient été générées à partir d'une moyenne se situant entre 584 et 614 grammes.

- **Bayésien**. Étant donnée mes connaissances (vagues) de la moyenne et de l'écart-type avant de procéder à l'analyse (*a priori*), il y a une probabilité de 95% que la moyenne de la masse de la population se situe entre `r round(draws_mean[1], 1)` et `r round(draws_mean[3], 1)` grammes.

Nous avons une idée de la distribution des paramètres... mais pas de la masse dans la population. Pas de problème: nous avons des échantillons de moyennes et d'écart-type. Nous pouvons les échantilonnés avec remplacement pour générer des possibilités de distrbution, puis échantillonné une masse selon ces distributions échantillonnées. Disons... 10000?

```{r starwars10000, out.width="100%", fig.align="center", fig.cap="Source: Star Wars, a new hope", echo = FALSE}
knitr::include_graphics("https://media.giphy.com/media/ZEaHzwGBp2qC0LN9Ye/giphy.gif")
```

Yep, 10 000.

```{r bayes-sample-distribution}
n_mass <- 10000
sim_mass <- rep(0, n_mass)
for (i in 1:n_mass) {
  sim_mean <- sample(draws_tidy$param_mean)
  sim_sd <- sample(draws_tidy$param_sd)
  sim_mass[i] <- rnorm(1, sim_mean, sim_sd)
}
```

La distribution avec laquelle j'ai créé les données `y20` plus haut avait une moyenne de 600 et un écart-type de 30. Je la superpose ici avec La distribution modélisée avec notre petit modèle bayésien.

```{r bayes-greta-posterior-mass-density}
x_ <- seq(450, 750, 5)
plot(x_, dnorm(x_, 600, 30), lty = 3, col = "red", type = "l", xlab = "Mass (g)", ylab = "Density")
lines(density(sim_mass), col = "blue")

sim_mass_limits <- confidence_interval(x = sim_mass, on = "deviation", distribution = "normal", level = 0.95)
abline(v = sim_mass_limits[1], lty = 2, col = "blue")
abline(v = sim_mass_limits[3], lty = 2, col = "blue")
text(x = sim_mass_limits[1], y = 0.01, labels = round(sim_mass_limits[1]), pos = 2, col = "blue")
text(x = sim_mass_limits[3], y = 0.01, labels = round(sim_mass_limits[3]), pos = 4, col = "blue")
```

Raisonnement bayésien: Étant donnée mes connaissances vagues de la moyenne et de l'écart-type avant de procéder à l'analyse, il y a une probabilité de 95% que la masse de la population se situe entre `r round(sim_mass_limits[1], 1)` et `r round(sim_mass_limits[3], 1)` grammes.

Nous avons maintenant une idée de la distribution de moyenne de la population. Mais, rarement, une analyse s'arrêtera à ce stade. Il arrive souvent que l'on doive comparer les paramètres de deux, voire plusieurs groupes. Par exemple, comparer des populations vivants dans des écosystèmes différents, ou comparer un traitement à un placébo. Ou bien, comparer, dans une même population de faucons pélerins, l'envergure des ailes des mâles et celle des femelles.

## Test de t: Différence entre des groupes

Pour comparer des groupes, on exprime généralement une hypothèse nulle, qui typiquement pose qu'il n'y a pas de différence entre les groupes. Puis, on choisit un test statistique **pour déterminer si les distributions des données observées sont plausibles dans si l'hypothèse nulle est vraie**.

En d'autres mots, le test statistique exprime la probabilité que l'on obtienne les données obtenues s'il n'y avait pas de différence entre les groupes. 

Par exemple, si 

1. vous obtenez une *p-value* de moins de 0.05 après un test de comparaison et
2. l'hypothèse nulle pose qu'il n'y a pas de différence entre les groupes,

cela signifie qu'il y a une probabilité de 5% que vous ayiez obtenu ces données s'il n'y avait en fait pas de différence entre les groupe. Il serait donc peu probable que vos données euent été générées comme telles s'il n'y avait en fait pas de différence.

```{r bayes-greta-model-t-data}
n_f <- 30
moy_f <- 105
n_m <- 20
moy_m <- 77.5
sd_fm <- 2.75

set.seed(21526)
envergure_f <- rnorm(mean=moy_f, sd=sd_fm, n=n_f)
envergure_m <- rnorm(mean=moy_m, sd=sd_fm, n=n_m)

envergure_f_df <- data.frame(Sex = "Female", Wingspan = envergure_f)
envergure_m_df <- data.frame(Sex = "Male", Wingspan = envergure_m)
envergure_df <- rbind(envergure_f_df, envergure_m_df)

envergure_df %>%
  ggplot(aes(x=Wingspan)) +
  geom_histogram(aes(y=..density.., fill=Sex)) +
  geom_density(aes(value=Sex, y=..density..))
```

Et les statistiques des deux groupes.

```{r bayes-greta-model-t-stats}
envergure_df %>%
  group_by(Sex) %>%
  summarise(mean = mean(Wingspan),
            sd = sd(Wingspan),
            n = n())
```

Évaluer s'il y a une différence significative peut se faire avec un test de t (ou de Student).

```{r bayes-greta-model-t-ttest}
t.test(envergure_f, envergure_m)
```

La probabilité que les données ait été générées de la sorte si les deux groupes n'était semblables est très faible (`p-value < 2.2e-16`). On obtiendrait sensiblement les mêmes résultats avec une régression linéaire.

```{r bayes-greta-model-t-lm}
linmod <- lm(Wingspan ~ Sex, envergure_df)
summary(linmod)
```

Le modèle linéaire est plus informatif. Il nous apprend que l'envergure des ailes des mâles est en moyenne plus faible de 28.0 cm que celle des femelles...

```{r bayes-greta-model-t-confint}
confint(linmod, level = 0.95)
```

... avec un intervalle de confiance entre -29.6 cm à -26.4 cm.

Utilisons l'information dérivée de statistiques classiques dans nos a priori. Oui-oui, on peut faire ça. Mais attention, un a priori trop précis ou trop collé sur nos données orientera le modèle vers une solution préalablement établie: ce qui constituerait aucune avancée par rapport à l'*a priori*. Nous allons utiliser a priori pour les deux groupes la moyenne des deux groupes, et comme dispersion la moyenne le double de l'écart-type. Rappelons que cet écart-type est l'a priori de écart-type sur la moyenne, non pas de la population.

Procédons à la création d'un modèle greta. Nous utiliserons la régression linéaire préférablement au test de t.

```{r bayes-greta-model-t-modmat}
is_female <- model.matrix(~envergure_df$Sex)[, 2]
```


```{r bayes-greta-model-t-create-model}
int <- normal(600, 30)
coef <- normal(30, 10)
sd <- cauchy(0, 10, truncation = c(0, Inf))

mu <- int + coef * is_female

distribution(envergure_df$Wingspan) <- normal(mu, sd)

m <- model(int, coef, sd, mu)
plot(m)
```

Utilisons 1000 échatillons, un warmup de 1000 (par défaut) et un thin de 1 (par défaut), et go!

```{r bayes-greta-model-t-draws}
draws <- mcmc(m, n_samples = 1000)
```

Et les résultats.

```{r bayes-greta-model-t-results}
mcmc_combo(draws, combo = c("dens", "trace"), pars = c("int", "coef", "sd"))
```


```{r bayes-greta-model-t-spread}
draws_tidy <- draws %>%
  spread_draws(int, coef, sd)
draws_tidy
```

```{r bayes-greta-model-t-stats2}
print("Intercept:")
confidence_interval(x = draws_tidy$int, on = "deviation", distribution = "normal", level = 0.95)

print("Pente:")
confidence_interval(x = draws_tidy$coef, on = "deviation", distribution = "normal", level = 0.95)
```

## Modélisation multiniveau

Vous souvenez-vous en quoi consiste un effet aléatoire? Pour rappel, il s'agit d'un effet global nul mais variable d'un groupe à l'autre, alors qu'un effet fixe ne subit pas la contrainte d'effet nul. En modélisation linéaire, l'effet aléatoire peut se trouver sur l'intercept ou sur une pente (ou plusieurs pentes). Ce concept peut être porté naturellement en modélisation bayésienne en ajoutant à l'intercept ou à une pente un effet dont l'*a priori* est une distribution étalée autour de zéro (effet global nul, mais variable).

Reprenons le modèle considéré à la section \@ref(chapitre-biostats). 

```{r bayes-greta-mm-freq}
data(lasrosas.corn, package = "agridat")
lasrosas.corn$year_rep <- paste0(lasrosas.corn$year, "_", lasrosas.corn$rep)

lasrosas.corn_sc <- lasrosas.corn %>%
  select(lat, long, nitro, bv) %>% 
  mutate_all(scale) %>% 
  bind_cols(lasrosas.corn %>% select(-lat, -long, -nitro, -bv)) %>% 
  mutate(year = as.factor(year))

mmodlin_1 <- nlme::lme(fixed = yield ~ lat + long + nitro + topo + bv,
                 random = ~ 1|year/rep,
                 data = lasrosas.corn_sc)
summary(mmodlin_1)$tTable
```

En **`greta`**, nous travaillerons avec une matrice modèle des effets fixes.

```{r bayes-greta-mm-modmat}
corn_modmat <- model.matrix(~lat + long + nitro + topo + bv, data = lasrosas.corn_sc)
head(corn_modmat)
```

Nous devons définir nos *a priori* sur les paramètres du modèle. Nous avons l'intercept, ainsi que les pentes des effets fixes et des effets aléatoires. Nous pourrions créer un *a priori* par paramètre, ou bien créer un seul jeu d'*a priori* pour les pentes et l'intercept. Je préfère le séparer.

```{r bayes-greta-mm-fixef}
intercept <- normal(0, 10)
b_fixed <- normal(0, 10, dim = 7) # pentes effet fixes
```

Les effets aléatoires fonctionnent en donnant une valeur de décalage par identifiant. 

```{r bayes-greta-mm-ranef}
year_id <- lasrosas.corn_sc$year
year_sd <- lognormal(0, 1)
year_offset <- normal(0, year_sd, dim = length(unique(year_id))-1 )
year_effect <- rbind(0, year_offset)

rep_id <- as.numeric(as.factor(lasrosas.corn_sc$year_rep))
rep_sd <- lognormal(0, 1)
rep_offset <- normal(0, rep_sd, dim = length(unique(rep_id))-1 )
rep_effect <- rbind(0, rep_offset)
```

Le modèle est monté en ajoutant aux effets fixes des valeurs dépendantes de l'année et de la répétition. Dans ce cas, ce sont bien des effets aléatoires sur l'intercept.

```{r bayes-greta-mm-create-model}
mu <- intercept + # intercept du modèle (effet fixe)
  corn_modmat[, 2:8] %*% b_fixed + # pentes du modèle (effet fixe)
  year_effect[year_id] + # décalage par année sur l'intercept du modèle (effet aléatoire)
  rep_effect[rep_id] # décalage par répétition par année sur l'intercept du modèle (effet aléatoire)
sd <- cauchy(0, 3, truncation = c(0, Inf)) # a priori sur l'erreur du modèle
distribution(lasrosas.corn_sc$yield) <- normal(mu, sd)
m <- model(intercept, b_fixed, year_effect, rep_effect, sd, mu)
plot(m)

```

Le modèle peut prendre une minute ou deux à échantillonner.

```{r bayes-greta-mm-draws}
draws <- greta::mcmc(m, n_samples = 5000, warmup = 1000, thin = 10)
```

Nous pouvons soutirer l'intercept.

```{r bayes-greta-mm-intercept}
mcmc_combo(draws, combo = c("hist", "trace"), regex_pars = "intercept")
```

Et les coefficients des effets fixes.

```{r bayes-greta-mm-b_fixed, fig.height=20}
mcmc_combo(draws, combo = c("hist", "trace"), regex_pars = "b_fixed\\[[.[1234567]")
```

L'intercept et les coefficients semblent avoir été bien échantillonnés. Les intervalles de confiance peuvent être présenter ainsi.

```{r bayes-greta-mm-b-intervals}
mcmc_intervals(draws, pars = paste0("b_fixed[", 1:7, ",1]"))
```

Ou encore mieux, nous pouvons tirer profit des statistiques bayésiennes pour les représenter sous forme de distributions.

```{r bayes-greta-mm-b-distributions}
mcmc_areas(draws, pars = paste0("b_fixed[", 1:7, ",1]"))
```

Il y a des manières plus élégantes d'extraire les valeurs, mais j'y vais de manière plus brutale. J'extrais les échantillonnages des coefficients `b_fixed` avec la fonction `calculate()`.

```{r bayes-greta-mm-b-calculate}
b_calc <- b_fixed %>% 
  calculate(draws)
```

Le résultat, `b_calc`, est une liste des échantillons par chaîne de Markov. La première ligne du prochain bloc de code permet d'effectuer une moyenne des matrices élément par élément. Ensuite, j'effectue des opérations en chaîne pour en soutirer moyennes et intervalles (en utilisant une fonction définie peécédemment dans ce chapitre).

```{r bayes-greta-mm-b-stats}
b_calc_chainmean <- apply(simplify2array(b_calc), 1:2, mean) %>% as_tibble()

b_calc_chainmean %>%
  pivot_longer(cols = everything()) %>% 
  group_by(name) %>% 
  summarise(mean = mean(value),
            ll = confidence_interval(value)[1],
            ul = confidence_interval(value)[3])

```

Visualisons maintenant les effets aléatoires par année.

```{r bayes-greta-mm-plot-ranef-year}
mcmc_combo(draws, combo = c("hist", "trace"), regex_pars = "year_effect.")
```

Et par répétition.

```{r bayes-greta-mm-plot-ranef-rep, fig.height=20}
mcmc_combo(draws, combo = c("hist", "trace"), regex_pars = "rep_effect.")
```


## Pour aller plus loin

Le module **`greta`** est conçu et maintenu par [Nick Golding](https://github.com/goldingn), du Quantitative & Applied Ecology Group de l'University of Melbourne, Australie. La [documentation de greta](https://greta-stats.org/) offre des [recettes](https://greta-stats.org/articles/example_models.html) pour toutes sortes d'analyses en écologie.

Les livres de Mark Kéry, bien que rédigés pour les calculs en langage R et WinBUGS, offre une approche bien structurée et traduisible en **`greta`**, qui est plus moderne que WinBUGS.

- [Introduction to WinBUGS for Ecologists (2010)](https://www.amazon.com/Introduction-WinBUGS-Ecologists-Bayesian-regression/dp/0123786053)
- [Bayesian Population Analysis using WinBUGS: A Hierarchical Perspective (2011)](https://www.amazon.com/Bayesian-Population-Analysis-using-WinBUGS/dp/0123870208)
- [Applied Hierarchical Modeling in Ecology: Analysis of distribution, abundance and species richness in R and BUGS (2015)](https://www.amazon.com/Applied-Hierarchical-Modeling-Ecology-distribution/dp/0128013788)

Enfin, si comme moi vous aimez vous dérouiller en Python, le module PyMC3 est très bien documenté, en particulier dans le livre gratuit [*Probabilistic Programming & Bayesian Methods for Hackers*](http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/), de Cam Davidson-Pilon.

```{r, bayes-rm-all, include=FALSE}
rm(list = ls())
```