[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analyse et modélisation d’agroécosystèmes sur R",
    "section": "",
    "text": "Préface\nCe cours a pour objectif de former les étudiants gradués en génie agroenvironnemental, génie civil, génie écologique, agronomie, biologie, foresterie et écologie en analyse et modélisation de systèmes vivants. Les sujets traités sont l’introduction au langage de programmation R, l’analyse statistique descriptive, la visualisation, la modélisation inférentielle, prédictive et déterministe.\nCe manuel est basé sur le cours Analyse et modélisation d’agroécosystèmes de Essi Parent (voir licence au bas de la page). La version proposée ici tient compte des mises à jour des différents outils présentés dans le manuel original. Elle est construite au format Quarto par Charles Frenette-Vallières et Andrés Felipe Silva Dimaté\nVoici la liste des modifications principales apportées jusqu’à présent par rapport à la version originale :"
  },
  {
    "objectID": "index.html#table-des-matières",
    "href": "index.html#table-des-matières",
    "title": "Analyse et modélisation d’agroécosystèmes sur R",
    "section": "Table des matières",
    "text": "Table des matières\n\nIntroduction\nLa science des données avec R\nOrganisation des données et opérations sur des tableaux\nVisualisation\nScience ouverte et reproductibilité\nIntroduction à Python\nBiostatistiques\nIntroduction à l’analyse bayésienne en écologie\nRégression\nExplorer R\nAssociation, partitionnement et ordination\nDétection de valeurs aberrantes et imputation de données manquantes\nLes séries temporelles\nIntroduction à l’autoapprentissage\nLes données géospatiales\nModélisation de mécanismes écologiques\n\n\nAnalyse et modélisation d’agroécosystèmes de Essi Parent est mis à disposition selon les termes de la licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International\n\nFondé(e) sur une œuvre à https://github.com/essicolo/ecologie-mathematique-R/."
  },
  {
    "objectID": "01-intro.html#définitions",
    "href": "01-intro.html#définitions",
    "title": "1  Introduction",
    "section": "1.1 Définitions",
    "text": "1.1 Définitions\nLes mathématiques confèrent aux humains une capacité d’abstraction suffisamment complexe pour leur permettre de toucher les étoiles et les atomes, de comprendre le passé et de prédire le futur, de toucher l’infini et de goûter à l’éternité. À partir des maths, on a pu créer des outils de calcul qui permettent de projeter des images de l’univers, bien au-delà de la Voie lactée. Mais appréhender le vivant, tout près de nous, demeure une tâche complexe.\n\n\n\n\n\nFigure 1.2: Domaines scientifiques de l’écologie mathématique.\n\n\n\n\nL’écologie mathématique couvre un large spectre de domaines (Figure 1.2), mais peut être divisée en deux branches: l’écologie théorique et l’écologie quantitative (Legendre et Legendre, 2012). Alors que l’écologie théorique s’intéresse à l’expression mathématique des mécanismes écologiques, l’écologie quantitative, plus empirique, en étudie principalement les phénomènes. La modélisation écologique vise à prévoir une situation selon des conditions données. Faisant partie à la fois de l’écologie théorique et de l’écologie quantitative, elle superpose souvent des mécanismes de l’écologie théorique et des phénomènes empiriques de l’écologie quantitative. L’écologie numérique comprend la branche descriptive de l’écologie quantitative, c’est-à-dire qu’elle s’intéresse à évaluer des effets à partir de données empiriques. L’exploration des données dans le but d’y découvrir des structures passe souvent par des techniques multivariées comme la classification hiérarchique ou la réduction d’axe (par exemple, l’analyse en composantes principales), qui sont davantage heuristiques (dans notre cas, bioheuristique) que statistiques. Les tests d’hypothèses et l’analyse des probabilités, quant à eux, relèvent de la biostatistique.\nLe génie écologique, une discipline intimement liée à l’écologie mathématique, est voué à l’analyse, la modélisation, la conception et la construction de systèmes vivants dans le but de résoudre de manière efficace des problèmes liés à l’écologie et à une panoplie de domaines qui lui sont raccordés. L’agriculture est l’un de ces domaines. C’est d’emblée la discipline qui sera prisée dans ce manuel. Néanmoins, les principes qui seront discutés sont transférables à l’écologie générale."
  },
  {
    "objectID": "01-intro.html#à-qui-sadresse-ce-manuel",
    "href": "01-intro.html#à-qui-sadresse-ce-manuel",
    "title": "1  Introduction",
    "section": "1.2 À qui s’adresse ce manuel?",
    "text": "1.2 À qui s’adresse ce manuel?\nLe cours vise à introduire des étudiant.e.s gradué.e.s en agronomie, biologie, écologie, sols, génie agroenvironnemental, génie civil et génie écologique à l’analyse et la modélisation dans leur domaine, tant pour les appuyer pour leurs travaux de recherche que pour leur fournir une trousse d’outils émancipatrice pour leur cheminement professionnel. Plus spécifiquement, vous serez accompagné à découvrir différents outils numériques qui vous permettront d’appréhender vos données, d’en faire émerger l’information et de construire des modèles. L’objectif de ce cours n’est pas de vous former en mathématiques, mais de vous aider à les utiliser. En ce sens, c’est un cours de pilotage, pas un cours de mécanique. Vous ferez tout de même un peu de mécanique pour mieux comprendre les réactions de notre machine.\nBien que des connaissances en programmation et en statistiques aideront grandement les étudiant.e.s à appréhender ce document, une littératie informatique n’est pas requise. Dans tous les cas, quiconque voudra tirer profit de ce manuel devra faire preuve d’autonomie. Vous serez guidés vers des ressources et des références, mais je vous suggère vivement de développer votre propre bibliothèque adaptée à vos besoins et à votre manière de comprendre."
  },
  {
    "objectID": "01-intro.html#les-logiciels-libres",
    "href": "01-intro.html#les-logiciels-libres",
    "title": "1  Introduction",
    "section": "1.3 Les logiciels libres",
    "text": "1.3 Les logiciels libres\nTous les outils numériques qui sont proposés dans ce cours sont des logiciels libres:\n\n« Logiciel libre » [free software] désigne des logiciels qui respectent la liberté des utilisateurs. En gros, cela veut dire que les utilisateurs ont la liberté d’exécuter, copier, distribuer, étudier, modifier et améliorer ces logiciels. Ainsi, « logiciel libre » fait référence à la liberté, pas au prix1 (pour comprendre ce concept, vous devez penser à « liberté d’expression », pas à « entrée libre »). - Projet GNU\n\nDonc: codes sources ouverts, développement souvent communautaire, gratuité. Plusieurs raisons éthiques, principalement liées au contrôle de l’environnement virtuel par les utilisateurs et les communautés, peuvent justifier l’utilisation de logiciels libres. Plusieurs raisons pratiques justifient aussi cette orientation. Les logiciels libres vous permettent de transporter vos outils avec vous, d’une entreprise à l’autre, au bureau, ou à la maison, et ce, sans vous soucier d’acheter de coûteuses licences.\nIl existe tout de même des risques liés aux possibles erreurs dans les codes des logiciels communautaires. Ces risques sont d’ailleurs les mêmes que ceux liés aux logiciels propriétaires. Pour les scientifiques, une erreur peut mener à une étude retirée de la littérature et même, potentiellement, des politiques publiques mal avisées. Pour les ingénieurs, les conséquences pourraient être dramatiques. Mais retenez qu’en toute circonstance, comme professionnel.le, vous êtes responsable des outils que vous utilisez: vous devez vous assurer de la bonne qualité d’un logiciel, qu’il soit propriétaire ou communautaire.\nAlors que la qualité des logiciels propriétaires est généralement suivie par audits, celle des logiciels libres est plutôt soumise à la vigilance communautaire. Chaque approche a ses avantages et inconvénients, mais elles ne sont pas exclusives. Ainsi, les logiciels libres peuvent être audités à l’externe par quiconque décide de le faire. Différentes entreprises, souvent concurrentes, participent tant à cette vigilance qu’au développement des logiciels libres: elles en sont même souvent les instigatrices (comme RStudio, Anaconda et Enthought).\nPar ailleurs, ce manuel est distribué librement sous licence Creative commons, selon les termes suivants.\n\nAnalyse et modélisation d’agroécosystèmes de Essi Parent est mis à disposition selon les termes de la licence Creative Commons Attribution - Pas d’Utilisation Commerciale - Partage dans les Mêmes Conditions 4.0 International\n\nFondé(e) sur une œuvre à https://github.com/essicolo/ecologie-mathematique-R/."
  },
  {
    "objectID": "01-intro.html#langage-de-programmation",
    "href": "01-intro.html#langage-de-programmation",
    "title": "1  Introduction",
    "section": "1.4 Langage de programmation",
    "text": "1.4 Langage de programmation\n\n1.4.1 R\nCe cours est basé sur le langage R. En plus d’être libre, R est un langage de programmation dynamique largement utilisé dans le monde universitaire, et dont l’utilisation s’étend de manière soutenue hors des tours d’ivoire.\n\nR is also the name of a popular programming language used by a growing number of data analysts inside corporations and academia. It is becoming their lingua franca partly because data mining has entered a golden age, whether being used to set ad prices, find new drugs more quickly or fine-tune financial models. New York Times, janvier 2009\n\nSon développement est supporté par la R Foundation for Statistical Computing, basée à l’Université de Vienne. Également, l’équipe de RStudio contribue largement au développement de modules génériques. R est principalement utilisé pour le calcul statistique, mais les récents développements le rendent un outil de choix pour tout ce qui entoure la science des données, de l’interaction avec les bases de données au déploiement d’outils d’intelligence artificielle en passant par la visualisation. Une fois implémenté avec des modules de calcul scientifique spécialisés en biologie, en écologie et en agronomie (que nous couvrirons au long du cours), R devient un outil de calcul convivial, rapide et fiable.\n\n\n1.4.2 Pourquoi pas Python?\nLa première mouture de ce cours se fondait sur le langage Python. Tout comme R, Python est un langage de programmation dynamique prisé pour le calcul scientifique. Python est un langage générique apprécié pour sa polyvalence et sa simplicité. Python est utilisé autant pour créer des logiciels ou des sites web que pour le calcul scientifique. Ainsi, Python peut être utilisé en interopérabilité avec une panoplie de logiciels libres, comme QGIS pour la cartographie et FreeCAD pour le dessin technique. Il est particulièrement apprécié en ingénierie pour ses modules de calcul par éléments finis (e.g. FeNICS) et en bioinformatique pour ses outils liés au séquençage (scikit-bio), mais ses lacunes en analyse statistique, en particulier en statistiques multivariées m’ont amené à favoriser R.\nBien que leurs possibilités se superposent largement, ce serait une erreur d’aborder R et Python comme des langages rivaux. Les deux langages s’expriment de manière similaire et s’inspirent mutuellement: apprendre à travailler avec l’un revient à apprendre l’autre. Les spécialistes en calcul scientifique tendent à apprendre à travailler avec plus d’un langage de programmation. Par ailleurs, il existe de plus en plus des moyens de travailler en R et en Python dans un même flux de travail. L’interface de calcul RStudio, que nous utiliserons pendant le cours, permet d’inclure des blocs de code en Python.\nDans la version mise à jour du manuel, une courte introduction facultative à Python est proposée.\n\n\n1.4.3 Pourquoi pas Matlab?\nParce qu’on est en 2024.\n\n\n1.4.4 Et… SAS?\nParce qu’on est à l’université.\n\n\n1.4.5 Mais pourquoi pas ______ ?\nD’autres langages, comme Julia, Scala, Javascript et même Ruby sont utilisés en calcul scientifique. Ils sont néanmoins moins garnis et moins documentés que R. Des langages de plus bas niveau, comme Fortran et C++, viennent souvent appuyer les fonctions des autres langages: ces langages sont plus ardus à utiliser au jour le jour, mais leur rapidité de calcul est imbattable."
  },
  {
    "objectID": "01-intro.html#contenu-du-manuel",
    "href": "01-intro.html#contenu-du-manuel",
    "title": "1  Introduction",
    "section": "1.5 Contenu du manuel",
    "text": "1.5 Contenu du manuel\nJe favorise une approche intuitive aux développements mathématiques. Nous aborderons l’analyse et la modélisation inférentielle, prédictive et mécanistique appliquée aux agroécosystèmes.\nChapitre 2 - Introduction au langage de programmation R. Qu’est-ce que R? Comment l’aborder? Quelles sont les fonctionnalités de base et comment tirer profit de tout l’écosystème de programmation?\nChapitre 3 - Organisation des données et opérations sur des tableaux. Les tableaux permettent d’enchâsser l’information dans un format prêt-à-porter pour R. Comment les importer, les exporter, les filtrer, et en faire des sommaires?\nChapitre 4 - Visualisation. Comment présenter l’information contenue dans un long tableau en un seul coup d’oeil?\nChapitre 5 - Le travail collaboratif, le suivi de version et la science ouverte. Ce chapitre offre une introduction à l’utilisation des outils de calcul collaboratif, ainsi qu’un aperçu du système de suivi de version git et de son utilisation sur GitHub.\nChapitre 6 - Introduction à Python (section facultative). Une très brève introduction au langage de programmation Python. Ce contenu est externe au cours et est là pour vous fournir des références si vous souhaitez explorer ce langage dans le futur.\nChapitre 7 - Biostatistiques. Il est audacieux de ne consacrer qu’un seul chapitre sur ce vaste sujet. Nous irons à l’essentiel… pour vous donner les outils qui permettront d’approfondir le sujet.\nChapitre 8 - Biostatistiques bayésiennes (section facultative). Une très brève introduction pour qui est intéressé à l’analyse bayésienne.\nChapitre 9 - Régression. À venir.\nChapitre 10 - Explorer R. La science des données évolue rapidement. Vous gagnerez à vous tenir au courrant de son évolution, et immanquablement vous vous buterez sur des opérations qui vous sembleront insolubles. Ce chapitre vous accompagnera à rester à jour sur le développement de R, à poser de bonnes questions et proposera des modules intéressants en écologie mathématique.\nChapitre 11 - Association, partitionnement et ordination. Les écosystèmes diffèrent, mais en quoi sont-ils semblables, et en quoi dffèrent-ils? Ces questions importantes peuvent être abordés par l’écologie numérique, domaine d’étude au sein duquel l’association, le partitionnement et l’ordination sont des outils prédominants.\nChapitre 12 - Détection de valeurs aberrantes et imputation. Une donnée aberrante sortira du lot, pour une raison ou pour une autre. Comment les détecter de manière systématique? D’autre part, que faire lorsqu’une donnée est manquante? Peut-on l’imputer? Comment?\nChapitre 13 - Les séries temporelles. Les capteurs modernes permettent de générer des données en fonction du temps. Que ce soit des données météorologiques enregistrées quotidiennement ou des données de teneur en eau enregistrées au 5 secondes, les données en fonction du temps forment un signal. Comment analyser ces signaux?\nChapitre 14 - L’autoapprentissage. Les applications de l’intelligence artificielle ne sont limitées que par votre imagination. Encore faut-il l’utiliser… intelligemment.\nChapitre 15 - Les données spatiales. Ce chapitre porte sur l’utilisation de R comme système d’information géographique de base. Nous utiliserons aussi l’autoapprentissage et les modèles déterministes comme outils d’interpolation spatial.\nChapitre 16 - La modélisation mécanistique (section facultative). Les modèles sont des maquettes simplifiées. Comment utiliser les équations différentielles ordinaires pour créer ces maquettes?\nSi les chapitres 3 à 5 peuvent être considérés comme fondamentaux pour bien maîtriser R, les autres peuvent être feuilletés à la pièce, bien qu’ils forment une suite logique.\nChaque chapitre de ce manuel est rédigé en format Quarto, dans un environnement RStudio. Pour exécuter les commandes, vous pourrez soit les copier-coller dans R (ou RStudio), soit télécharger les fichiers-sources et exécuter les blocs de code.\nLe manuel original était rédigé au format R Markdown et est toujours disponible à l’adresse suivante."
  },
  {
    "objectID": "01-intro.html#objectifs-généraux",
    "href": "01-intro.html#objectifs-généraux",
    "title": "1  Introduction",
    "section": "1.6 Objectifs généraux",
    "text": "1.6 Objectifs généraux\nÀ la fin du cours, vous serez en mesure:\n\nde programmer en langage R\nd’importer, de manipuler (sélection des colonnes, filtres, sommaires statistiques) et d’exporter des tableaux\nde générer des graphiques d’utilisation commune\nde vous assurer que vos calculs soient auditables et reproductibles dans une perspective de science ouverte\nd’appréhender des données écologiques et agronomiques à l’aide de tests statistiques fréquentiels\nd’explorer par vous-même les possibilités offertes par la communauté de développement de modules R\nd’explorer les données à l’aide des outils de l’écologie numérique (association, partitionnement et ordination)\nd’imputer des données manquantes dans un tableau et de détecter des valeurs aberrantes\nde créer un modèle d’autoapprentissage\nd’effectuer une analyse de série temporelle\nd’interpoler des données spatiales\nde modéliser des équations différentielles ordinaires"
  },
  {
    "objectID": "01-intro.html#lectures-complémentaires",
    "href": "01-intro.html#lectures-complémentaires",
    "title": "1  Introduction",
    "section": "1.7 Lectures complémentaires",
    "text": "1.7 Lectures complémentaires\n\n1.7.1 Écologie mathématique\n\nHow to be a quantitative ecologist. Jason Mathipoulos vous prend par la main pour découvrir les notions de mathématiques fondamentales en écologie, appliquées avec le langage R.\n\nNumerical ecology. L’ouvrage hautement détaillé des frères Legendre est non seulement fondamental, mais aussi fondateur d’une science qui évolue encore aujourd’hui: l’analyse des données écologiques.\nA practical guide to ecological modelling. Soetaert et Herman portent une attention particulière à la présentation des principes de modélisation dans un langage accessible - ce qui est rarement le cas dans le domaine de la modélisation. Les modèles présentés concernent principalement les bilans de masse, en termes de systèmes de réactions chimiques et de relations biologiques.\nModélisation mathématique en écologie. Rare livre en modélisation écologique publié en français, la première partie s’attarde aux concepts mathématiques, alors que la deuxième planche à les appliquer. Si le haut niveau d’abstraction de la première partie vous rebute, n’hésitez pas débuter par la seconde partie et de vous référer à la première au besoin.\nA new ecology: systems perspective. Principalement grâce au soleil, la Terre forme un ensemble de gradients d’énergie qui se déclinent en des systèmes d’une étonnante complexité. C’est ainsi que le regretté Sven Erik Jørgensen (1934-2016, Figure 1.3)) et ses collaborateurs décrivent les écosystèmes dans cet ouvrage qui fait suite aux travaux fondateurs de Howard Thomas Odum.\nEcological engineering. Principle and Practice.\nEcological processes handbook.\nModeling complex ecological dynamics\n\n\n\n\n\n\nFigure 1.3: Sven Erik Jørgensen, Source: Elsevier.\n\n\n\n\n\n\n1.7.2 Programmation\n\nR for data science (2e). L’analyse de données est une branche importante de l’écologie mathématique. Ce manuel traite des matrices et la manipulation de données chapitre 3), de la visualisation (chapitre 4) ainsi que de l’apprentissage automatique (chapitre 14). R for data science (2e) repasse ces sujets plus en profondeur. En particulier, l’ouvrage de Garrett Grolemund, Hadley Wickham et Mine Çetinkaya-Rundel offre une introduction au module graphique ggplot2 et à tidyverse.\nNumerical ecology with R. Daniel Borcard enseigne l’écologie numérique à l’Université de Montréal. Son cours est condensé dans ce livre recettes voué à l’application des principes lourdement décrits dans Numerical ecology.\n\n\n\n1.7.3 Divers\n\nThe truthful art. Dans cet ouvrage, Alberto Cairo s’intéresse à l’utilisation des données et de leurs présentations pour fournir une information adéquate à différents publics."
  },
  {
    "objectID": "01-intro.html#besoin-daide",
    "href": "01-intro.html#besoin-daide",
    "title": "1  Introduction",
    "section": "1.8 Besoin d’aide?",
    "text": "1.8 Besoin d’aide?\nLes ouvrages de référence reconnus vous offrent des bases solides sur lesquelles vous pouvez vous appuyer dans vos travaux. Mais au-delà des principes, au jour le jour, vous vous buterez immanquablement à toutes sortes de petits problèmes. Quel module utiliser pour cette tâche précise? Que veut dire ce message d’erreur? Comment interpréter ce résultat? Pour tous les petits accrocs du quotidien en calcul scientifique, internet offre de nombreuses ressources qui sont très hétérogènes en qualité. Vous apprendrez à reconnaître les ressources fiables à celles qui sont douteuses. Les plateformes basées sur Stack Exchange, comme Stack Overflow et Cross Validated, m’ont souvent été d’une aide précieuse. Vous aurez avantage à vous construire une petite banque d’information avec un logiciel de prise de notes en collectant des liens, en prenant en notes certaines recettes et en suivant des sites d’intérêt avec des flux RSS."
  },
  {
    "objectID": "01-intro.html#à-propos-de-lauteur",
    "href": "01-intro.html#à-propos-de-lauteur",
    "title": "1  Introduction",
    "section": "1.9 À propos de l’auteur",
    "text": "1.9 À propos de l’auteur\nJe m’appelle Essi Parent. Je suis ingénieur écologue et professeur adjoint au Département des sols et de génie agroalimentaire de l’Université Laval, Québec, Canada. Je crois que la science est le meilleur moyen d’appréhender le monde pour prendre des décisions avisées."
  },
  {
    "objectID": "01-intro.html#un-cours-complémentaire-à-dautres-cours",
    "href": "01-intro.html#un-cours-complémentaire-à-dautres-cours",
    "title": "1  Introduction",
    "section": "1.10 Un cours complémentaire à d’autres cours",
    "text": "1.10 Un cours complémentaire à d’autres cours\nCe cours a été développé pour ouvrir des perspectives mathématiques en écologie et en agronomie à la FSAA de l’Université Laval. Il est complémentaire à certains cours offerts dans d’autres institutions académiques au Québec, dont ceux-ci.\n\nBIO2041. Biostatistiques 1, Université de Montréal\nBIO2042. Biostatistiques 2, Université de Montréal\nBIO109. Introduction à la programmation scientifique, Université de Sherbrooke\nBIO500. Méthodes en écologie computationnelle, Université de Sherbrooke."
  },
  {
    "objectID": "01-intro.html#contribuer-au-manuel",
    "href": "01-intro.html#contribuer-au-manuel",
    "title": "1  Introduction",
    "section": "1.11 Contribuer au manuel",
    "text": "1.11 Contribuer au manuel\nJe suis ouvert aux commentaires et suggestions. Pour contribuer directement, dirigez-vous sur le dépôt du manuel sur GitHub, puis ouvrez une Issue pour en discuter. Créez une nouvelle branche (fork), effectuez les modifications, puis lancer une requête de fusion (pull request)."
  },
  {
    "objectID": "02-R.html#statistiques-ou-science-des-données",
    "href": "02-R.html#statistiques-ou-science-des-données",
    "title": "2  La science des données avec R",
    "section": "2.1 Statistiques ou science des données?",
    "text": "2.1 Statistiques ou science des données?\nSelon Whitlock et Schluter (2015), la statistique est l’étude des méthodes pour décrire et mesurer des aspects de la nature à partir d’échantillon. Pour Grolemund et Wickham (2023), la science des données est une discipline excitante permettant de transformer des données brutes en compréhension, perspectives et connaissances. Oui, excitante! La différence entre les deux champs d’expertise est subtile, et certaines personnes n’y voient qu’une différence de ton.\n\n\nData Science is statistics on a Mac.\n\n— Big Data Borat (@BigDataBorat) 27 août 2013\n\n\nConfinées à ses applications traditionnelles, les statistiques sont davantage vouées à la définition de dispositifs expérimentaux et à l’exécution de tests d’hypothèses, alors que la science des données est moins linéaire, en particulier dans sa phase d’analyse, où de nouvelles questions (donc de nouvelles hypothèses) peuvent être posées au fur et à mesure de l’analyse. Cela arrive généralement davantage lorsque l’on fait face à de nombreuses observations sur lesquelles de nombreux paramètres sont mesurés.\nLa quantité de données et de mesures auxquelles nous avons aujourd’hui accès grâce aux technologies de mesure et de stockage relativement peu dispendieux rend la science des données une discipline particulièrement attrayante, pour ne pas dire sexy."
  },
  {
    "objectID": "02-R.html#débuter-en-r",
    "href": "02-R.html#débuter-en-r",
    "title": "2  La science des données avec R",
    "section": "2.2 Débuter en R",
    "text": "2.2 Débuter en R\nR est un langage de programmation dérivé du langage S, qui fut initialement lancé en 1976.\n\n\n\n\n\nFigure 2.2: Logo officiel du language R.\n\n\n\n\nR figure parmi les langages de programmation les plus utilisés au monde. Bien qu’il soit basé sur les langages statiques C et Fortran, R est un langage dynamique, c’est-à-dire que le code peut être exécuté ligne par ligne ou bloc par bloc: un avantage majeur pour des activités qui nécessitent des interactions fréquentes. Bien que R soit surtout utilisé pour le calcul statistique, il s’impose de plus en plus comme outil privilégié en sciences des données en raison des récents développements de modules d’analyse, de modélisation et de visualisation, dont plusieurs seront utilisés dans ce manuel.\nUn langage de programmation s’apprend un peu comme une langue. Au début, un code R peut sembler incompréhensible. Et face à son clavier, on ne sait pas trop comment exprimer ce que l’on désire. Au fur et à mesure de l’apprentissage, les symboles, les fonctions et le style deviennent de plus en plus familiers et on apprend tranquillement à traduire en code ce que l’on désire effectuer. Comme une langue s’apprend en la parlant dans la vie de tous les jours, un language de programmation s’apprend avantageusement en solutionnant vos propres problèmes (Figure 2.3).\n\n\n\n\n\nFigure 2.3: R avant et maintenant, Illustration de Allison Horst"
  },
  {
    "objectID": "02-R.html#préparer-son-flux-de-travail",
    "href": "02-R.html#préparer-son-flux-de-travail",
    "title": "2  La science des données avec R",
    "section": "2.3 Préparer son flux de travail",
    "text": "2.3 Préparer son flux de travail\nIl existe de nombreuses manières d’utiliser R. Parmi celles-ci, j’en couvrirai 3:\n\nInstallation classique (installation suggérée)\nInstallation avec Anaconda\nUtilisation infonuagique\n\n\n2.3.1 Installation classique\nInstallation suggérée. Sur Windows ou Mac, dirigez-vous ici, téléchargez et installez. Sur Linux, ouvrez votre gestionnaire d’application, chercher r-base (Ubuntu, Debian), R-base (openSuse) ou R-core (Fedora) et installez-le (assurez-vous que les librairies suivantes sont aussi installées: gcc, gcc-fortran, gcc-c++ et make), vous aurez peut-être besoin d’installer des librairies supplémentaires pour faire fonctionner certains modules.\n\nNote. Les modules présentés dans ce cours devraient être disponibles sur Linux, Windows et Mac. Ce n’est pas le cas pour tous les modules R. La plupart fonctionnent néanmoins sur Linux, dont les systèmes d’opération (je recommande Ubuntu ou l’une de ses dérivées comme elementary OS) sont de bonnes options pour le calcul scientifique.\n\nÀ cette étape, R devrait fonctionner dans un interpréteur de commande . Si vous lancez R dans un terminal (chercher cmd dans le menu si vous êtes sur Windows), vous obtiendrez quelque chose comme ceci.\n\n\n\n\n\nFigure 2.4: R dans le terminal.\n\n\n\n\nLe symbole &gt; indique que R attend que vos instructions. Vous voilà dans un état méditatif devant l’indéchiffrable vide du terminal 😵. Ne vous en faites pas: nous commencerons bientôt à jaser avec R.\nAvant cela, installons-nous au salon. Afin de travailler dans un environnement de travail plus confortable, je recommande l’installation de l’interface RStudio, gratuite et open source: téléchargez l’installateur et suivez les instructions. RStudio ressemble à ceci.\n\n\n\n\n\nFigure 2.5: Fenêtre de RStudio.\n\n\n\n\nEn haut à droite se trouve un menu Project (None). Il s’agit d’un menu de vos projets. Je recommande d’utiliser ces projets avec RStudio, qui vous permettront de mieux gérer vos sessions de travail, en particulier en lien avec les chemins vers vos données, graphiques, etc., que vous pouvez gérer relativement à l’emplacement de votre dossier de projet plutôt qu’à l’emplacement des fichiers sur votre machine: nous verrons plus en détails au chapitre 5.\n\nEn haut à gauche, vous avez vos feuilles de calcul, qui apparaîtront en tant qu’onglets. Une feuille de calcul R script est une série de commandes que vous lancez en séquence. Il peut aussi s’agir d’un document Quarto si vous choisissez de travailler ainsi. Ce format vous permettra de d’écrire du texte en format Markdown entre des blocs de code. Il est question du format Quarto au chapitre 5).\nEn bas à gauche apparaît la Console, où vous voyez les commandes envoyées à R ainsi que ses sorties.\nEn haut à droite, les différents onglets indiquent où vous en êtes dans vos calculs. En particulier, la liste sous Environment indique les objets qui ont été générés ou chargés jusqu’alors.\nEn bas à droite, on retrouve des onglets de nature variés. Files contient les sous-dossiers et fichiers du dossier de projets. Plots est l’endroit où apparaîtront vos graphiques. Packages contient la liste des modules déjà installés, ainsi qu’un outil de gestion des modules pour leur installation, leur désinstallation et leur mise à jour. Help affiche les fiches d’aide des fonctions (pour obtenir de l’aide sur une fonction dans RStudio, surlignez la fonction dans votre feuille de calcul, puis appuyez sur F1). Enfin, l’onglet Viewer affichera les sorties HTML, en particulier les graphiques interactifs que vous générerez par exemple avec le module plotly, ou alors le rendu de votre fichier Quarto. Si votre environnement de travail était un avion, R serait le moteur et RStudio serait le cockpit!\n\n\n\n\n\n\nFigure 2.6: Scène de Fifi Brindacier (Astrid Lindgren, 1945).\n\n\n\n\n\n\n2.3.2 Installation avec Anaconda\nSi vous cherchez une trousse complète d’analyse de données, comprenant R et Python, vous pourrez préférer Anaconda. Une fois installée, vous pourrez isoler un environnement de travail sur R, ou même isoler des environnements de travail particuliers pour vos projets. Une manière conviviale de créer des environnements de travail est de passer par l’interface Anaconda navigator, que vous lancerez soit dans le menu Windows, soit en ligne de commande anaconda-navigator sous Mac et Linux, puis d’installer r-essentials, rstudio et jupyterlab dans l’onglet Environment. Vous pourrez aussi installer RStudio et Jupyter lab via l’onglet Home de Anaconda navigator. Dans l’environnement de base, installez le package nb_conda_kernels pour vous assurer que tous les noyaux (R, Python, etc.) installés dans les environnements de travail soient automatiquement accessibles dans Jupyter. Si vous désirez utiliser dans Jupyter la version de R installée avec l’installation classique, référez-vous au guide présenté en extra au bas de la page.\n\n\n\n\n\nFigure 2.7: Anaconda navigator.\n\n\n\n\nJupyter lab est une interface notebook semblable à Quarto - les format Jupyter (*.ipynb) et Quarto (*.qmd) sont par ailleurs convertibles grâce au module jupytext. L’utilisation de R en Anaconda n’est pas tout à fait au point, et pourrait poser problème pour l’installation de certains modules. Si vous optez pour cette option, préparez-vous à avoir à bidouiller un peu. Plusieurs préfèrent Jupyter à RStudio (ce n’est pas mon cas).\n\n\n2.3.3 Utilisation infonuagique\nPas besoin d’avoir une machine super puissante pour travailler en R. Il existe une multitude de services infonuagiques (dans le cloud) vous permettant de lancer vos calculs sur des serveurs plutôt que sur votre Chromebook ou votre vieux laptop déglingué. Certains services sont gratuits, et d’autres souvent plus élaborés sont payants. Vous pouvez utiliser gratuitement Azure Notebooks ou un tour de passe-passe pour faire fonctionner Google colab en R. Une option gratuite de CoCalc vient avec un agressant bandeau rouge vif qui disparait avec l’option payante.\nÀ mon avis, le service Nextjournal est celui d’entre tous qui possède en ce moment les meilleures qualités dans sa version gratuite. Vous pourrez y travailler en mode collaboratif, comme dans Google docs. En outre, vous pouvez lancer ces notes de cours en les important dans Nextjournal. Vous devrez toutefois déposer les données dans l’interface, puis à chaque session installer les modules spécialisés. Le service gratuit offre peu de puissance de calcul, mais pour effectuer les applications de base, ça devrait être suffisant. La vidéo ci-dessous monter comment importer les notes de cours dans Nextjournal.\nVideo"
  },
  {
    "objectID": "02-R.html#premiers-pas-avec-r",
    "href": "02-R.html#premiers-pas-avec-r",
    "title": "2  La science des données avec R",
    "section": "2.4 Premiers pas avec R",
    "text": "2.4 Premiers pas avec R\nR ne fonctionne pas avec des menus, en faisant danser une souris sous une musique de clics. Vous devrez donc entrer des commandes avec votre clavier, que vous apprendrez par cœur au fur et à mesure, ou que vous retrouverez en lançant des recherches sur internet. Par expérience personnelle, lorsque je travaille avec R, j’ai toujours un navigateur ouvert prêt à recevoir une question.\nLes étapes qui suivent sont des premiers pas. Elles ne feront pas de vous des ceintures noires de la programmation. La plupart des utilisateurs de R ont appris en se pratiquant sur leurs données, en se butant sur des obstacles, en apprenant comment les surmonter ou les contourner…\nPour l’instant, ouvrez seulement un interpréteur de commande, et lancez R. Voyons si R est aussi libre qu’on le prétend.\n\n“La liberté, c’est la liberté de dire que deux et deux font quatre. Si cela est accordé, tout le reste suit.” - George Orwell, 1984\n\n\n2 + 2\n\n[1] 4\n\n\nEt voilà.\n\nLes opérations mathématiques sont effectuées telles que l’on devrait s’attendre.\n\n67.1 - 43.3\n\n[1] 23.8\n\n2 * 4\n\n[1] 8\n\n1 / 2\n\n[1] 0.5\n\n\nL’exposant peut être noté ^, comme c’est le cas dans Excel, ou ** comme c’est le cas en Python.\n\n2^4\n\n[1] 16\n\n\n\n2**4\n\n[1] 16\n\n\n\n1 / 2 # utilisez des espaces de part et d'autre des opérateurs (sauf pour l'exposant) pour éclaircir le code\n\n[1] 0.5\n\n\nR ne lit pas ce qui suit le caractère #. Cela vous laisse l’opportunité de commenter un code comprenant une séquence de plusieurs lignes. Remarquez également que la dernière opération comporte des espaces entre les nombres et l’opérateur /. Dans ce cas (ce n’est pas toujours le cas), les espaces ne signifient rien: ils aident seulement à éclaircir le code. Il existe des guides pour l’écriture de code en R. Je recommande fortement de suivre méticuleusement le guide de style de tidyverse.\nAssigner des objets à des variables est fondamental en programmation. En R, on assigne traditionnellement avec la flèche &lt;-, mais vous verrez parfois le =, qui est davantage utilisé comme standard dans d’autres langages de programmation. Par exemple.\n\na &lt;- 3\n\nTruc. Essayez d’inverser la flèche, e.g. 3 -&gt; a.\nTechniquement, a pointe vers le nombre entier 3. Conséquemment, on peut effectuer des opérations sur a.\n\na * 6\n\n[1] 18\n\n\n\nA + 2\n\nLe message d’erreur nous dit que A n’est pas défini. Sa version minuscule, a, l’est pourtant. La raison est que R considère la case dans la définition des objets. Utiliser la mauvaise case mène donc à des erreurs.\nNote. Les messages d’erreur ne sont pas toujours clairs, mais vous apprendrez à les comprendre. Dans tous les cas, ils sont fait pour vous aider. Lisez-les attentivement!\nEn général, le nom d’une variable doit toujours commencer par une lettre, et ne doit pas contenir de caractères réservés (espaces, +, *). Dans la définition des variables, plusieurs utilisent des symboles . pour délimiter les mots, mais la barre de soulignement _ est à préférer. En effet, dans d’autres langages de programmation comme Python, le . a une autre signification: son utilisation est à éviter autant que possible. De même, évitez l’utilisation de majuscules pour nommer vos objets (voir le guide de style de tidyverse pour nommer les objets).\nNote. À ce stade, vous serez probablement plus à l’aise de copier-coller ces commandes dans votre terminal.\n\nrendement_arbre &lt;- 50 # pomme/arbre\nnombre_arbre &lt;- 300 # arbre\nnombre_pomme &lt;- rendement_arbre * nombre_arbre\nnombre_pomme\n\n[1] 15000\n\n\nComme chez la plupart des langages de programmation, R respecte les conventions des priorités des opérations mathéatiques.\n\n10 - 9^0.5 * 2\n\n[1] 4\n\n\n\n2.4.1 Types de données\nJusqu’à maintenant, nous n’avons utilisé que des nombres entiers (integer ou int) et des nombres réels (numeric ou float64). R inclut d’autres types. La chaîne de caractère (string ou character) contient un ou plusieurs symboles. Elle est définie entre des doubles guillemets \" \" ou des apostrophes ' '. Il n’existe pas de standard sur l’utilisation de l’un ou de l’autre, mais en règle générale, on utilise les apostrophes pour les expressions courtes, contenant un simple mot ou une séquence de lettres, et les guillemets pour les phrases. Une raison pour cela: les guillemets sont utiles pour insérer des apostrophes dans une chaîne de caractère.\n\na &lt;- \"L'ours\"\nb &lt;- \"polaire\"\npaste(a, b)\n\n[1] \"L'ours polaire\"\n\n\nOn colle a et b avec la fonction paste. Notez que l’objet a a été défini précédemment. Il est possible en R de réassigner une variable, mais cela peut porter à confusion, jusqu’à générer des erreurs de calcul si une variable n’est pas assignée à l’objet auquel on voulait référer.\nCombien de caractères contient la chaîne \"L'ours polaire\"? R sait compter. Demandons-lui.\n\nc &lt;- paste(a, b)\nnchar(c)\n\n[1] 14\n\n\nQuatorze, c’est bien cela (comptez “L’ours polaire”, en incluant l’espace). Comme paste, nchar est une fonction incluse par défaut dans l’environnement de travail de R: plus précisément, ces fonctions sont incluses dans le module base, inclut par défaut lorsque R est lancé. La fonction est appelée en écrivant nchar(). Mais une fonction de quoi? Des arguments, qui se trouvent entre les parenthèses. Dans ce cas, il y a un seul argument: c.\nEn calcul scientifique, il est courant de lancer des requêtes déterminant si un résultat est vrai ou faux.\n\na &lt;- 17\na &lt; 10\n\n[1] FALSE\n\na &gt; 10\n\n[1] TRUE\n\na == 10\n\n[1] FALSE\n\na != 10\n\n[1] TRUE\n\na == 17\n\n[1] TRUE\n\n!(a == 17)\n\n[1] FALSE\n\n\nJe viens d’introduire un nouveau type de donnée: les données booléennes (boolean, ou logical), qui ne peuvent prendre que deux états - TRUE ou FALSE. En même temps, j’ai utilisé la fonction print parce que dans mon carnet, seule la dernière opération permet d’afficher le résultat. Si l’on veut forcer une sortie, on utilise print. Puis, on a vu plus haut que le symbole = est réservé pour assigner des objets: pour les tests d’égalité, on utilise le double égal, ==, ou != pour la non-égalité. Enfin, pour inverser une donnée de type booléenne, on utilise le point d’exclamation !.\n\n\n2.4.2 Les collections de données\nLes exercices précédents ont permis de présenter les types de données offerts par défaut sur R qui sont les plus importants pour le calcul scientifique: int (integer, ou nombre entier), numeric (nombre réel), character (string, ou chaîne de caractère) et logical (booléen). D’autres s’ajouteront tout au long du cours, comme les catégories (factor) et les unités de temps (date-heure).\nLorsque l’on procède à des opérations de calcul en science, nous utilisons rarement des valeurs uniques. Nous préférons les organiser et les traiter en collections. Par défaut, R offre quatre types importants de collections: les vecteurs, les matrices, les listes et les tableaux.\n\n2.4.2.1 Vecteurs\nD’abord, les vecteurs sont une série de variables de même type. Un vecteur est délimité par la fonction c( ) (c pour concaténation). Les éléments de la liste sont séparés par des virgules.\n\nespece &lt;- c(\"Petromyzon marinus\", \"Lepisosteus osseus\", \"Amia calva\", \"Hiodon tergisus\")\nespece\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n[4] \"Hiodon tergisus\"   \n\n\nPour accéder aux éléments d’une liste, one appelle la liste suivie de la position de l’objet désiré entre crochets.\n\nespece[1]\n\n[1] \"Petromyzon marinus\"\n\nespece[2]\n\n[1] \"Lepisosteus osseus\"\n\nespece[1:3]\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n\nespece[c(1, 3)]\n\n[1] \"Petromyzon marinus\" \"Amia calva\"        \n\n\nOn peut noter que le premier élément de la liste est noté 1, et non 0 comme c’est le cas de la plupart de langages. Le raccourcis 1:3 crée une liste de nombres entiers de 1 à 3 inclusivement, c’est-à-dire l’équivalent de c(1, 2, 3). En effet, on crée une liste d’indices pour soutirer des éléments d’une liste. On peut utiliser le symbole de soustraction pour retirer un ou plusieurs éléments d’un vecteur.\n\nespece[-c(1, 3)]\n\n[1] \"Lepisosteus osseus\" \"Hiodon tergisus\"   \n\n\nPour ajouter un élément à notre liste, on peut utiliser la fonction c( ).\n\nespece &lt;- c(espece, \"Cyprinus carpio\")\nespece\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n[4] \"Hiodon tergisus\"    \"Cyprinus carpio\"   \n\n\nNotez que l’on efface l’objet espece par une concaténation de l’objet espece, précédemment définie, et d’un autre élément.\nEn lançant espece[3] &lt;- \"Lepomis gibbosus\", il est possible de changer un élément de la liste.\n\nespece[3] &lt;- \"Lepomis gibbosus\"\nespece\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Lepomis gibbosus\"  \n[4] \"Hiodon tergisus\"    \"Cyprinus carpio\"   \n\n\n\n\n2.4.2.2 Matrices\nUne matrice est un vecteur de dimension plus élevée que 1. En écologie, on dépasse rarement la deuxième dimension, quoi que les matrices en N dimensions soient courantes en modélisation mathématique. Je ne considérerai pour le moment que des matrices 2D. Comme c’est la cas des vecteurs, les matrices contiennent des valeurs de même type. En R, on peut attribuer aux matrices 2D des noms de ligne et de colonne.\n\nmat &lt;- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), \n              ncol = 3)\nmat\n\n     [,1] [,2] [,3]\n[1,]    1    5    9\n[2,]    2    6   10\n[3,]    3    7   11\n[4,]    4    8   12\n\n\n\ncolnames(mat) &lt;- c(\"A\", \"B\", \"C\")\nrownames(mat) &lt;- c(\"site_1\", \"site_2\", \"site_3\", \"site_4\")\nmat\n\n       A B  C\nsite_1 1 5  9\nsite_2 2 6 10\nsite_3 3 7 11\nsite_4 4 8 12\n\n\nOn peut soutirer les noms de colonne et les noms de ligne. Le résultat est un vecteur.\n\ncolnames(mat)\n\n[1] \"A\" \"B\" \"C\"\n\nrownames(mat)\n\n[1] \"site_1\" \"site_2\" \"site_3\" \"site_4\"\n\n\n\n\n2.4.2.3 Listes\nLes listes sont des collections hétérogènes dans lesquelles on peut placer les objets désirés, sans distinction: elles peuvent même inclure d’autres listes. Chacun des éléments de la liste peut être identifié par une clé.\n\nma_liste &lt;- list(\n  especes = c(\n    \"Petromyzon marinus\", \"Lepisosteus osseus\",\n    \"Amia calva\", \"Hiodon tergisus\"\n  ),\n  site = \"A101\",\n  stations_meteos = c(\"746583\", \"783786\", \"856363\")\n)\nma_liste\n\n$especes\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n[4] \"Hiodon tergisus\"   \n\n$site\n[1] \"A101\"\n\n$stations_meteos\n[1] \"746583\" \"783786\" \"856363\"\n\n\nLes éléments de la liste peuvent être soutirés par le nom de la clé ou par l’indice, de cette manière.\n\nma_liste$especes\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n[4] \"Hiodon tergisus\"   \n\nma_liste[[1]]\n\n[1] \"Petromyzon marinus\" \"Lepisosteus osseus\" \"Amia calva\"        \n[4] \"Hiodon tergisus\"   \n\n\nExercice. Accéder au deuxième élément du vecteur d’espèces dans la liste ma_liste.\n\n\n2.4.2.4 Tableaux\nEnfin, le type de collection de données le plus important est le tableau, ou data.frame. Techniquement, il s’agit d’une liste composée de vecteurs de même longueur. Chaque colonne peut ainsi prendre un type de donnée indépendamment des autres colonnes.\n\ntableau &lt;- data.frame(\n  espece = c(\n    \"Petromyzon marinus\", \"Lepisosteus osseus\",\n    \"Amia calva\", \"Hiodon tergisus\"\n  ),\n  poids = c(10, 13, 21, 4),\n  longueur = c(35, 44, 50, 8)\n)\ntableau\n\n              espece poids longueur\n1 Petromyzon marinus    10       35\n2 Lepisosteus osseus    13       44\n3         Amia calva    21       50\n4    Hiodon tergisus     4        8\n\n\nEn programmation classique en R (nous verrons plus loin la méthode tidyverse), les éléments d’un tableau se manipulent comme ceux d’une matrice et les colonnes peuvent être appelés comme les éléments d’une liste.\n\ntableau[, 2:3]\n\n  poids longueur\n1    10       35\n2    13       44\n3    21       50\n4     4        8\n\ntableau$poids\n\n[1] 10 13 21  4\n\n\nVous verrez aussi, quoi que rarement, ce format, qui à la différence du format $ génère un tableau.\n\ntableau[\"poids\"]\n\n  poids\n1    10\n2    13\n3    21\n4     4\n\n\nLe tableau est le format de collection à privilégier pour manipuler des données. Récemment, le format de tableau tibble a été créé par l’équipe de RStudio pour offrir un format plus moderne.\n\n\n\n2.4.3 Les fonctions\nLorsque vous écrivez une commande suivit de parenthèses, comme data.frame(especes = ...), vous demandez à R de passer à l’action en appelant une fonction. De manière très générale, une fonction transforme quelque chose en quelque chose d’autre (Figure 2.8).\n\n\n\n\n\nFigure 2.8: Schéma simplifié d’une fonction.\n\n\n\n\nPar exemple, la fonction mean() prend une collection de nombre comme entrée, puis en sort vous devinez quoi.\n\nmean(tableau$poids)\n\n[1] 12\n\n\nLes entrées sont appelés les arguments de la fonction. Leur définition est toujours disponible dans la documentation.\nExercice. Familiarisez-vous avec la documentation de R en lançant ?mean. Truc: si vous avez pris de l’avance et que vous travaillez déjà en RStudio, mettez le terme en surbrillance, puis appuyez sur F1.\nVous verrez dans la documentation que la fonction mean() demande trois arguments, x, trim et na.rm. Or nous avons seulement placé un vecteur, sans spécifier d’argument!\nEn effet. En l’absence d’une définition des arguments, R supposera que les arguments dans la parenthèse, séparés par une virgule, sont présentés dans le même ordre que celui spécifié dans la définition de la fonction (celle qui est présentée dans le fichier d’aide). Dans le cas qui nous intéresse, mean(tableau$poids) est équivalent à mean(x = tableau$poids).\nMaintenant, selon la fiche d’aide, l’argument na.rm est un valeur logique spécifiant si oui (TRUE) ou non (FALSE) les valeurs manquantes doivent être considérées (une moyenne d’un vecteur comprenant au moins un NA sera de NA). En ne spécifiant rien, R prend la valeur par défaut, telle que spécifiée dans la documentation. Il en va de même pour l’argument trim, qui permet d’élaguer des valeurs extrêmes. Dans la fiche d’aide, mean(x, trim = 0, na.rm = FALSE, ...) signifie que par défaut, l’argument x est vide (il doit donc être spécifié), l’argument trim est de 0 et l’argument na.rm est FALSE.\n\nmean(c(6, 1, 7, 4, 9, NA, 1))\n\n[1] NA\n\nmean(c(6, 1, 7, 4, 9, NA, 1), na.rm = TRUE)\n\n[1] 4.666667\n\n\nVous n’êtes pas emprisonné par les fonctions offertes par R. Vous pouvez installer des modules qui complètent les fonctions de base de R: on le verra un peu plus loin dans ce chapitre. Mais pour l’instant, voyons comment vous pouvez créer vos propres fonctions. Disons que vous voulez créer une fonction qui calcule la sortie de \\(x^3-2y+a\\). Pour obtenir la réponse, on a besoin des arguments x, y et a. La sortie de la fonction est ici triviale: la réponse de l’équation. L’opération function permet de prendre ça en charge.\n\noperation_f &lt;- function(x, y, a = 10) {\n  return(x^3 - 2 * y + a)\n}\n\nNotez que a a une valeur par défaut. La sortie de la fonction est ce qui se trouve entre les parenthèses de return. Vous pouvez maintenant utiliser la fonction operation_f au besoin.\n\noperation_f(x = 2, y = 3, a = 1)\n\n[1] 3\n\n\nUne telle fonction est peu utile. Mais l’utilisation de fonctions personnalisées vous permettra d’éviter de répéter la même opération plusieurs fois dans un flux de travail, en évitant de générer trop de code, donc aussi de potentielles erreurs. Personnellement, j’utilise les fonctions surtout pour générer des graphiques personnalisés.\nExercice. Afin d’acquérir de l’autonomie, vous devrez être en mesure de trouver le nom des commandes dont vous avez besoin pour effectuer la tâche que vous désirez effectuer. Cela peut causer des frustrations, mais vous vous sentirez toujours plus à l’aise avec R jour après jour. L’exercice ici est de trouver par vous-même la commande qui vous permettra mesurer la longueur d’un vecteur.\n\n\n2.4.4 Les boucles\nLes boucles permettent d’effectuer une même suite d’opérations sur plusieurs objets. Pour faire suite à notre exemple, nous désirons obtenir le résultat de l’opération f pour des paramètres que nous enregistrons dans ce tableau.\n\nparams &lt;- data.frame(\n  x = c(2, 4, 1, 5, 6),\n  y = c(3, 4, 8, 1, 0),\n  a = c(6, 1, 8, 2, 5)\n)\nparams\n\n  x y a\n1 2 3 6\n2 4 4 1\n3 1 8 8\n4 5 1 2\n5 6 0 5\n\n\nNous créons un vecteur vide, puis nous effectuons une itération ligne par ligne en remplissant le vecteur.\n\noperation_res &lt;- c()\nfor (i in 1:nrow(params)) {\n  operation_res[i] &lt;- operation_f(x = params[i, 1], y = params[i, 2], a = params[i, 3])\n}\noperation_res\n\n[1]   8  57  -7 125 221\n\n\nEn faisant varier i sur des valeurs du vecteur donné par la séquence de nombres entiers de 1 au nombre de ligne du tableau de paramètres, nous demandons à R d’effectuer la suite d’opération entre les accolades {}. À chaque boucle, i prend une valeur de la séquence. i est utilisé ici comme indice de la ligne à soutirer du tableau params, qui correspond à l’indice dans le vecteur operation_res.\nAinsi, chaque résultat est calculé dans l’ordre des lignes du tableau de paramètres et l’on pourra très bien y coller nos résultats:\n\nparams$resultats &lt;- operation_res\nparams\n\n  x y a resultats\n1 2 3 6         8\n2 4 4 1        57\n3 1 8 8        -7\n4 5 1 2       125\n5 6 0 5       221\n\n\nNotez que puisque la colonne resultat n’existe pas dans le tableau params, R crée automatiquement une nouvelle colonne.\nLes boucles for vous permettront par exemple de générer en peu de temps 10, 100, 1000 graphiques (autant que vous voulez), chacun issu de simulations obtenues à partir de conditions initiales différentes, et de les enregistrer dans un répertoire sur votre ordinateur. Un travail qui pourrait prendre des semaines sur Excel peut être effectué en R en quelques secondes.\nUn second outil est disponible pour les itérations: les boucles while. Elles effectuent une opération tant qu’un critère n’est pas atteint. Elles sont utiles pour les opérations où l’on cherche une convergence. Je les couvre rapidement puisqu’elles sont rarement utilisées dans les flux de travail courants. En voici un petit exemple.\n\nx &lt;- 100\nwhile (x &gt; 1.1) {\n  x &lt;- sqrt(x)\n  print(x)\n}\n\n[1] 10\n[1] 3.162278\n[1] 1.778279\n[1] 1.333521\n[1] 1.154782\n[1] 1.074608\n\n\nNous avons initié x à une valeur de 100. Puis, tant que (while) le test x &gt; 1.1 est vrai, attribuer à x la nouvelle valeur calculée en extrayant la racine de la valeur précédente de x. Enfin, indiquer la valeur avec print.\n\n\n2.4.5 Conditions: if, else if, else\n\nSi la condition 1 est remplie, effectuer une suite d’instructions 1. Si la condition 1 n’est pas remplie, et si la condition 2 est remplie, effectuer la suite d’instructions 2. Sinon, effectuer la suite d’instruction 3.\n\nVoilà comment on exprime une suite de conditions. Prenons l’exemple simple d’une discrétisation d’une valeur continue. Si \\(x&lt;10\\), il est classé comme faible. Si \\(10 \\leq x &lt;20\\), il est classé comme moyen. Si \\(x \\geq 20\\), il est classé comme élevé. Plaçons cette classification dans une fonction.\n\nclassification &lt;- function(x, lim1 = 10, lim2 = 20) {\n  if (x &lt; lim1) {\n    categorie &lt;- \"faible\"\n  } else if (x &lt; lim2) {\n    categorie &lt;- \"moyen\"\n  } else {\n    categorie &lt;- \"élevé\"\n  }\n  return(categorie)\n}\nclassification(-10)\n\n[1] \"faible\"\n\nclassification(15.4)\n\n[1] \"moyen\"\n\nclassification(1000)\n\n[1] \"élevé\"\n\n\nUne condition est définie avec le if, suivi du test à vrai ou faux entre parenthèses. Si le test retourne un vrai (TRUE), l’instruction entre accolades est exécutée. Si elle est fausse, on passe au suivant.\nExercice. Explorer les commandes ifelse et cut et réfléchissez à la manière qu’elles pourraient être utilisées pour effectuer une discrétisation plus efficacement qu’avec les if et les else.\n\n\n2.4.6 Installer et charger un module\nLa plupart des opérations d’ordre général (comme les racines carrées, les tests statistiques, la gestion de matrices et de tableau, les graphiques, etc.) sont accessibles grâce aux modules de base de R, qui sont installés et chargés par défaut lors du démarrage de R. Des équipes de travail ont néanmoins développé plusieurs modules pour répondre à leurs besoins spécialisés, et les ont laissés disponibles au grand public dans des modules que vous pouvez installer d’un dépôt CRAN (le AppStore de R), d’un dépôt Anaconda (le AppStore de Anaconda, si vous utilisez cette plate-forme), d’un dépôt Github (dépôts décentralisés), etc.\nRStudio possède un pratique bouton Install qui vous permet d’y inscrire une liste de modules. Le navigateur anaconda offre aussi une interface d’installation. La commande R pour installer un module est install.packages(\"ggplot2\"), si par exemple vous désirez installer ggplot2, le module graphique par excellence en R. C’est la commande que RStudio lancera tout seul si vous lui demandez d’installer ggplot2.\nLes modules sont l’équivalent des applications spécialisées que vous installez sur un téléphone mobile. Pour les utiliser, il faut les ouvrir.\nGénéralement, j’ouvre toutes les applications nécessaires à mon flux de travail au tout début de ma feuille de calcul (la prochaine cellule retournera un message d’erreur si les packages ne sont pas installés).\n\nlibrary(\"tidyverse\") # méta-package qui charge entre autres dplyr et ggplot2\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(\"vegan\")\n\nLe chargement a nécessité le package : permute\nLe chargement a nécessité le package : lattice\nThis is vegan 2.6-4\n\nlibrary(\"nlme\")\n\n\nAttachement du package : 'nlme'\n\nL'objet suivant est masqué depuis 'package:dplyr':\n\n    collapse\n\n\nLes modules sont installés sur votre ordinateur à un endroit que vous pourrez retrouver avec la commande .libPaths()\nExercice. À partir d’ici jusqu’à la fin du cours, nous utiliserons RStudio. Ouvrez-le et familiarisez-vous avec l’interface! Quelques petits trucs:\n\npour lancer une ligne, placez votre curseur sur la ligne, puis appuyez sur Ctrl+Enter\npour lancer une partie de code précise, mettez le en surbrillance, puis Ctrl+Enter\nutilisez toujours le gestionnaire de projets, en haut à droite!\ninstallez le module tidyverse\nlancez data(\"iris\") pour obtenir un tableau d’exercice, puis cliquez sur l’objet dans la fenêtre environnement"
  },
  {
    "objectID": "02-R.html#enfin",
    "href": "02-R.html#enfin",
    "title": "2  La science des données avec R",
    "section": "2.5 Enfin…",
    "text": "2.5 Enfin…\nComme une langue, on n’apprend à s’exprimer en un langage informatique qu’en se mettant à l’épreuve, ce que vous ferez tout au long de ce cours. Pour vous encourager, voici quelques trucs pour apprendre à coder en R.\n\nR n’aime pas l’ambiguïté. Une simple virgule mal placée et il ne sait plus quoi faire. Cela peut être frustrant au début, mais cette rigidité est nécessaire pour effectuer du calcul scientifique.\nLe copier-coller est votre ami. En gardant à l’esprit que vous être responsable de votre code et que vous respectez les droits d’auteur, n’ayez pas peur de copier-coller des lignes de code et de personnaliser par la suite.\nL’erreur que vous obtenez: d’autres l’ont obtenue avant vous. Le site de question-réponse stackoverflow est une ressource inestimable où des gens ayant posté des questions ont reçu des réponses d’experts (les meilleures réponses et les meilleures questions apparaissent en premier). Apprenez à chercher intelligemment des réponses en formulant précisément vos questions!\nÉtudiez et pratiquez. Les messages d’erreur en R sont courants, même chez les personnes expérimentées. La meilleure manière d’apprendre une langue est de la parler, d’étudier ses susceptibilités, de les tester dans une conversation, etc."
  },
  {
    "objectID": "02-R.html#petit-truc",
    "href": "02-R.html#petit-truc",
    "title": "2  La science des données avec R",
    "section": "2.6 Petit truc!",
    "text": "2.6 Petit truc!\nRStudio peut être implémenté avec des extensions. L’une d’elle permet d’ajuster votre style de code. Par exemple, vous voulez vous assurer que toutes les allocations sont bien effectuées avec des &lt;- et non pas des =, qu’il y a bien des espaces de part et d’autre de &lt;-, que les retours de lignes sont bien placés, etc. Installez le module styler, et des options apparaîtront dans le menu Addins comme à la Figure 2.9.\n\n\n\n\n\nFigure 2.9: L’extension styler permet de formater votre code dans un style particulier"
  },
  {
    "objectID": "02-R.html#extra-jupyter",
    "href": "02-R.html#extra-jupyter",
    "title": "2  La science des données avec R",
    "section": "2.7 Extra: Utiliser R avec Jupyter",
    "text": "2.7 Extra: Utiliser R avec Jupyter\nPour utiliser R dans Jupyter notebook ou Jupyter lab, vous devez installer le module IRkernel dans la version de R que vous désirez utiliser avec Jupyter, puis de lancer la commande IRkernel::installspec(). La prochaine fois que vous ouvrirez Jupyter, le noyau de R devrait apparaître.\nJe n’ai aucune expérience sur Mac, mais semble-t-il cela fonctionne comme en Linux. Ouvrez R à partir d’un terminal (R + Enter), puis lancez IRkernel::installspec() après avoir installé IRkernel. Si vous travaillez en Windows, il vous faudra lancer R par son chemin complet dans l’invite de commande de Anaconda (Anaconda Powershell Prompt). Par exemple, ouvrir Anaconda Powershell Prompt, puis, si votre installation de R se trouve dans C:\\Program Files\\R\\R-3.6.2,\n(base) PS C:\\Users\\fifi&gt; cd \"C:\\Program Files\\R\\R-3.6.2\\bin\"\n(base) PS C:\\Program Files\\R\\R-3.6.2\\bin&gt; .\\R.exe\n\nR version 3.6.2 (2019-12-12) -- \"Dark and Stormy Night\"\nCopyright (C) 2019 The R Foundation for Statistical Computing\nPlatform: x86_64-w64-mingw32/x64 (64-bit)\n\nR est un logiciel libre livré sans AUCUNE GARANTIE.\nVous pouvez le redistribuer sous certaines conditions.\nTapez 'license()' ou 'licence()' pour plus de détails.\n\nR est un projet collaboratif avec de nombreux contributeurs.\nTapez 'contributors()' pour plus d'information et\n'citation()' pour la façon de le citer dans les publications.\n\nTapez 'demo()' pour des démonstrations, 'help()' pour l'aide\nen ligne ou 'help.start()' pour obtenir l'aide au format HTML.\nTapez 'q()' pour quitter R.\n\n&gt; install.packages(\"IRkernel\")\nInstallation du package dans 'C:/Users/fifi/Documents/R/win-library/3.6'\n(car 'lib' n'est pas spécifié)\n--- SVP sélectionner un miroir CRAN pour cette session ---\nessai de l'URL 'https://cloud.r-project.org/bin/windows/contrib/3.6/IRkernel_1.1.zip'\nContent type 'application/zip' length 138696 bytes (135 KB)\ndownloaded 135 KB\n\nle package 'IRkernel' a été décompressé et les sommes MD5 ont été vérifiées avec succés\n\nLes packages binaires téléchargés sont dans\n       C:\\Users\\fifi\\AppData\\Local\\Temp\\Rtmp6xJtB3\\downloaded_packages\n\n&gt; IRkernel::installspec()\n[InstallKernelSpec] Installed kernelspec ir in C:\\Users\\fifi\\AppData\\Roaming\\jupyter\\kernels\\ir\n&gt; qui()"
  },
  {
    "objectID": "03-tableaux.html#les-collections-de-données",
    "href": "03-tableaux.html#les-collections-de-données",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.1 Les collections de données",
    "text": "3.1 Les collections de données\nDans le chapitre 2, nous avons survolé différents types d’objets : réels, entiers, chaînes de caractères et booléens. Les données peuvent appartenir à d’autres types : dates, catégories ordinales (ordonnées : faible, moyen, élevé) et nominales (non ordonnées : espèces, cultivars, couleurs, unité pédologique, etc.). Comme mentionné en début de chapitre, une donnée est une valeur associée à une variable. Les données peuvent être organisées en collections.\nNous avons aussi vu au chapitre 2 que la manière privilégiée d’organiser des données était sous forme de tableaux. De manière générale, un tableau de données est une organisation de données en deux dimensions, comportant des lignes et des colonnes. Il est préférable de respecter la convention selon laquelle les lignes sont des observations et les colonnes sont des variables. Ainsi, un tableau est une liste de vecteurs de même longueur, chaque vecteur représentant une variable. Chaque variable est libre de prendre le type de données approprié. La position d’une donnée dans le vecteur correspond à une observation. Lorsque les vecteurs sont posés les uns à côté des autres, la position dans le vecteur devient une ligne qui définit les valeurs des variables d’une observation.\nImaginez que vous consignez des données météorologiques comme les précipitations totales ou la température moyenne pour chaque jour, pendant une semaine sur les sites A, B et C. Chaque site possède ses propres caractéristiques, comme la position en longitude-latitude. Il est redondant de répéter la position du site pour chaque jour de la semaine. Vous préférerez créer deux tableaux : un pour décrire vos observations, et un autre pour décrire les sites. De cette manière, vous créez une collection de tableaux interreliés : une base de données. Nous couvrirons cette notion un peu plus loin. R peut soutirer des données des bases de données grâce au module DBI, qui n’est pas couvert à ce stade de développement du cours.\nDans R, les données structurées en tableaux, ainsi que les opérations sur les tableaux, peuvent être gérées grâce aux modules readr, dplyr et tidyr, tous des modules faisant partie du méta-module tidyverse, qui est un genre de Microsoft Office sur R : plusieurs modules fonctionnant en interopérabilité. Mais avant de se lancer dans l’utilisation de ces modules, voyons quelques règles à suivre pour bien structurer ses données en format tidy, un jargon du tidyverse qui signifie proprement organisé."
  },
  {
    "objectID": "03-tableaux.html#organiser-un-tableau-de-données",
    "href": "03-tableaux.html#organiser-un-tableau-de-données",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.2 Organiser un tableau de données",
    "text": "3.2 Organiser un tableau de données\nAfin de repérer chaque cellule d’un tableau, on attribue à chaque ligne et à chaque colonne un identifiant unique, que l’on nomme indice pour les lignes et entête pour les colonnes.\n\nRègle no 1. Une variable par colonne, une observation par ligne, une valeur par cellule.\n\nLes unités expérimentales sont décrites par une ou plusieurs variables, par des chiffres ou des lettres. Chaque variable devrait être présente en une seule colonne, et chaque ligne devrait correspondre à une unité expérimentale où ces variables ont été mesurées. La règle parait simple, mais elle est rarement respectée. Prenez par exemple le tableau suivant.\n\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.4     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.0\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nTable 3.1: Rendements obtenus sur les sites expérimentaux selon les traitements.\n\n\nSite\nTraitement A\nTraitement B\nTraitement C\n\n\n\n\nSainte-Souris\n4.1\n8.2\n6.8\n\n\nSainte-Fourmi\n5.8\n5.9\nNA\n\n\nSaint-Ours\n2.9\n3.4\n4.6\n\n\n\n\n\n\nQu’est-ce qui cloche avec ce tableau? Chaque ligne est une observation, mais contient plusieurs observations d’une même variable, le rendement, qui devient étalé sur plusieurs colonnes. À bien y penser, le type de traitement est une variable et le rendement en est une autre:\n\n\n\n\nTable 3.2: Rendements obtenus sur les sites expérimentaux selon les traitements.\n\n\nSite\nTraitement\nRendement\n\n\n\n\nSainte-Souris\nTraitement A\n4.1\n\n\nSainte-Souris\nTraitement B\n8.2\n\n\nSainte-Souris\nTraitement C\n6.8\n\n\nSainte-Fourmi\nTraitement A\n5.8\n\n\nSainte-Fourmi\nTraitement B\n5.9\n\n\nSainte-Fourmi\nTraitement C\nNA\n\n\nSaint-Ours\nTraitement A\n2.9\n\n\nSaint-Ours\nTraitement B\n3.4\n\n\nSaint-Ours\nTraitement C\n4.6\n\n\n\n\n\n\nPlus précisément, l’expression à bien y penser suggère une réflexion sur la signification des données. Certaines variables peuvent parfois être intégrées dans une même colonne, parfois pas. Par exemple, les concentrations en cuivre, zinc et plomb dans un sol contaminé peuvent être placées dans la même colonne “Concentration” ou déclinées en plusieurs colonnes Cu, Zn et Pb. La première version trouvera son utilité pour créer des graphiques (chapitre 4), alors que la deuxième favorise le traitement statistique (chapitre 7). Il est possible de passer d’un format à l’autre grâce à la fonction pivot_longer() et pivot_wider() du module tidyr.\n\nRègle no 2. Un tableau par unité observationnelle: ne pas répéter les informations.\n\nReprenons la même expérience. Supposons que vous mesurez la précipitation à l’échelle du site.\n\n\n\n\nTable 3.3: Rendements et précipitations obtenus sur les sites expérimentaux selon les traitements.\n\n\nSite\nTraitement\nRendement\nPrécipitations\n\n\n\n\nSainte-Souris\nTraitement A\n4.1\n813\n\n\nSainte-Souris\nTraitement B\n8.2\n813\n\n\nSainte-Souris\nTraitement C\n6.8\n813\n\n\nSainte-Fourmi\nTraitement A\n5.8\n642\n\n\nSainte-Fourmi\nTraitement B\n5.9\n642\n\n\nSainte-Fourmi\nTraitement C\nNA\n642\n\n\nSaint-Ours\nTraitement A\n2.9\n1028\n\n\nSaint-Ours\nTraitement B\n3.4\n1028\n\n\nSaint-Ours\nTraitement C\n4.6\n1028\n\n\n\n\n\n\nSegmenter l’information en deux tableaux serait préférable.\n\n\n\n\nTable 3.4: Précipitations sur les sites expérimentaux.\n\n\nSite\nPrécipitations\n\n\n\n\nSainte-Souris\n813\n\n\nSainte-Fourmi\n642\n\n\nSaint-Ours\n1028\n\n\n\n\n\n\nLes tableaux Table 3.2 et Table 3.4, ensemble, forment une base de données (collection organisée de tableaux). Les opérations de fusion entre les tableaux peuvent être effectuées grâce aux fonctions de jointure (left_join(), par exemple) du module tidyr. Une jointure de Table 3.4 vers Table 3.2 donnera le tableau Table 3.3.\n\nRègle no 3. Ne pas bousiller les données.\n\nPar exemple.\n\nAjouter des commentaires dans des cellules. Si une cellule mérite d’être commentée, il est préférable de placer les commentaires soit dans un fichier décrivant le tableau de données, soit dans une colonne de commentaire juxtaposée à la colonne de la variable à commenter. Par exemple, si vous n’avez pas mesuré le pH pour une observation, n’écrivez pas “échantillon contaminé” dans la cellule, mais annoter dans un fichier d’explication que l’échantillon no X a été contaminé. Si les commentaires sont systématiques, il peut être pratique de les inscrire dans une colonne commentaire_pH.\nInscription non systématique. Il arrive souvent que des catégories d’une variable ou que des valeurs manquantes soient annotées différemment. Il arrive même que le séparateur décimal soit non systématique, parfois noté par un point, parfois par une virgule. Par exemple, une fois importés dans votre session, les catégories St-Ours et Saint-Ours seront traitées comme deux catégories distinctes. De même, les cellules correspondant à des valeurs manquantes ne devraient pas être inscrites parfois avec une cellule vide, parfois avec un point, parfois avec un tiret ou avec la mention NA. Le plus simple est de laisser systématiquement ces cellules vides.\nInclure des notes dans un tableau. La règle “une colonne, une variable” n’est pas respectée si on ajoute des notes un peu n’importe où sous ou à côté du tableau.\nAjouter des sommaires. Si vous ajoutez une ligne sous un tableau comprenant la moyenne de chaque colonne, qu’est-ce qui arrivera lorsque vous importerez votre tableau dans votre session de travail? La ligne sera considérée comme une observation supplémentaire.\nInclure une hiérarchie dans les entêtes. Afin de consigner des données de texture du sol, comprenant la proportion de sable, de limon et d’argile, vous organisez votre entête en plusieurs lignes. Une ligne pour la catégorie de donnée, Texture, fusionnée sur trois colonnes, puis trois colonnes intitulées Sable, Limon et Argile. Votre tableau est joli, mais il ne pourra pas être importé conformément dans un votre session de calcul : on recherche une entête unique par colonne. Votre tableau de données devrait plutôt porter les entêtes Texture sable, Texture limon et Texture argile. Un conseil : réserver le travail esthétique à la toute fin d’un flux de travail."
  },
  {
    "objectID": "03-tableaux.html#formats-de-tableau",
    "href": "03-tableaux.html#formats-de-tableau",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.3 Formats de tableau",
    "text": "3.3 Formats de tableau\nPlusieurs outils sont à votre disposition pour créer des tableaux. Je vous présente ici les plus communs.\n\n3.3.1 xls ou xlsx\nMicrosoft Excel est un logiciel de type tableur, ou chiffrier électronique. L’ancien format xls a été remplacé par le format xlsx avec l’arrivée de Microsoft Office 2010. Il s’agit d’un format propriétaire, dont l’alternative libre la plus connue est le format ods, popularisé par la suite bureautique LibreOffice. Les formats xls, xlsx ou ods sont davantage utilisés comme outils de calcul que d’entreposage de données. Ils contiennent des formules, des graphiques, du formatage de cellule, etc. Je ne les recommande pas pour stocker des données.\n\n\n3.3.2 csv\nLe format csv, pour comma separated values, est un fichier texte, que vous pouvez ouvrir avec n’importe quel éditeur de texte brut (Bloc note, VSCode, Notepad++, etc.). Chaque colonne doit être délimitée par un caractère cohérent (conventionnellement une virgule, mais en français un point-virgule ou une tabulation pour éviter la confusion avec le séparateur décimal) et chaque ligne du tableau est un retour de ligne. Il est possible d’ouvrir et d’éditer les fichiers csv dans un éditeur texte, mais il est plus pratique de les ouvrir avec des tableurs (LibreOffice Calc, Microsoft Excel, Google Sheets, etc.).\nEncodage des fichiers texte. Puisque le format csv est un fichier texte, un souci particulier doit être porté sur la manière dont le texte est encodé. Les caractères accentués pourraient être importés incorrectement si vous importez votre tableau en spécifiant le mauvais encodage. Pour les fichiers en langues occidentales, l’encodage UTF-8 devrait être utilisé. Toutefois, par défaut, Excel utilise un encodage de Microsoft. Si le csv a été généré par Excel, il est préférable de l’ouvrir avec votre éditeur texte et de l’enregistrer dans l’encodage UTF-8.\n\n\n3.3.3 json\nComme le format csv, le format json indique un fichier en texte clair. En permettant des structures de tableaux emboîtés et en ne demandant pas que chaque colonne ait la même longueur, le format json permet plus de souplesse que le format csv, mais il est plus compliqué à consulter et prend davantage d’espace sur le disque que le csv. Il est utilisé davantage pour le partage de données des applications web, mais en ce qui concerne la matière du cours, ce format est surtout utilisé pour les données géoréférencées. L’encodage est géré de la même manière qu’un fichier csv.\n\n\n3.3.4 SQLite\nSQLite est une application pour les bases de données relationnelles de type SQL qui n’a pas besoin de serveur pour fonctionner. Les bases de données SQLite sont encodés dans des fichiers portant l’extension db, qui peuvent être facilement partagés.\n\n\n3.3.5 Suggestion\nEn csv pour les petits tableaux, en sqlite pour les bases de données plus complexes. Ce cours se concentre toutefois sur les données de type csv."
  },
  {
    "objectID": "03-tableaux.html#entreposer-ses-données",
    "href": "03-tableaux.html#entreposer-ses-données",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.4 Entreposer ses données",
    "text": "3.4 Entreposer ses données\nLa manière la plus sécurisée pour entreposer ses données est de les confiner dans une base de données sécurisée sur un serveur sécurisé dans un environnement sécurisé et d’encrypter les communications. C’est aussi… la manière la moins accessible. Des espaces de stockage nuagiques, comme Dropbox ou d’autres options similaires, peuvent être pratiques pour les backups et le partage des données avec une équipe de travail (qui risque en retour de bousiller vos données). Le suivi de version est possible chez certains fournisseurs d’espace de stockage. Mais pour un suivi de version plus rigoureux, les espaces de développement (comme GitHub et GitLab) sont plus appropriés (couverts au chapitre 5). Dans tous les cas, il est important de garder (1) des copies anciennes pour y revenir en cas d’erreurs et (2) un petit fichier décrivant les changements effectués sur les données."
  },
  {
    "objectID": "03-tableaux.html#manipuler-des-données-en-mode-tidyverse",
    "href": "03-tableaux.html#manipuler-des-données-en-mode-tidyverse",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.5 Manipuler des données en mode tidyverse",
    "text": "3.5 Manipuler des données en mode tidyverse\nLe méta-module tidyverse regroupe une collection de précieux modules pour l’analyse de données en R. Il permet d’importer des données dans votre session de travail avec readr, de les explorer avec le module de visualisation ggplot2, de les transformer avec tidyr et dplyr et de les exporter avec readr. Les tableaux de classe data.frame, comme ceux de la plus moderne classe tibble, peuvent être manipulés à travers le flux de travail pour l’analyse et la modélisation. Comme ce sera le cas pour le chapitre sur la visualisation, ce chapitre est loin de couvrir les nombreuses fonctionnalités qui sont offertes dans le tidyverse.\n\n3.5.1 Importer vos données dans votre session de travail\nSupposons que vous avez bien organisé vos données en mode tidy. Pour les importer dans votre session et commencer à les inspecter, vous lancerez une des commandes du module readr, décrites dans la documentation dédiée.\n\nread_csv() si le séparateur de colonne est une virgule\nread_csv2() si le séparateur de colonne est un point-virgule et que le séparateur décimal est une virgule\nread_tsv() si le séparateur de colonne est une tabulation\nread_table() si le séparateur de colonne est un espace blanc\nread_delim() si le séparateur de colonne est un autre caractère (comme le point-virgule) que vous spécifierez dans l’argument delim = \";\"\n\nLes principaux arguments sont les suivants.\n\nfile: le chemin vers le fichier. Ce chemin peut aussi bien être une adresse locale (data/…) qu’une adresse internet (https://…).\ndelim: le symbole délimitant les colonnes dans le cas de read_delim.\ncol_names: si TRUE, la première ligne est l’entête du tableau, sinon FALSE. Si vous spécifiez un vecteur numérique, ce sont les numéros des lignes utilisées pour le nom de l’entête. Si vous utilisez un vecteur de caractères, ce sont les noms des colonnes que vous désirez donner à votre tableau.\nna: le symbole spécifiant une valeur manquante. L’argument na='' signifie que les cellules vides sont des données manquantes. Si les valeurs manquantes ne sont pas uniformes, vous pouvez les indiquer dans un vecteur, par exemple na = c(\"\", \"NA\", \"NaN\", \".\", \"-\").\nlocal: cet argument prend une fonction local() qui peut inclure des arguments de format de temps, mais aussi d’encodage (voir documentation)\n\nD’autres arguments peuvent être spécifiés au besoin, et les répéter ici dupliquerait l’information de la documentation de la fonction read_csv de readr.\nJe déconseille d’importer des données en format xls ou xlsx. Si toutefois cela vous convient, je vous réfère au module readxl.\nL’aide-mémoire de readr (Figure 3.1) est à afficher près de soi.\n\n\n\n\n\nFigure 3.1: Aide-mémoire de readr, Source: https://rstudio.github.io/cheatsheets/data-import.pdf\n\n\n\n\nNous allons charger des données de culture de la chicouté (Rubus chamaemorus), un petit fruit nordique, tiré de Parent et al. (2013). Ouvrons d’abord le fichier pour vérifier les séparateurs de colonnes et de décimales (Figure 3.2).\n\n\n\n\n\nFigure 3.2: Aperçu brut d’un fichier csv.\n\n\n\n\nLe séparateur de colonnes est un point-virgule et le décimal est une virgule.\nAvec Atom, mon éditeur texte préféré (il y en a d’autres), je vais dans Edit &gt; Select Encoding et j’obtiens bien le UTF-8 (Figure 3.3).\n\n\n\n\n\nFigure 3.3: Changer l’encodage d’un fichier csv.\n\n\n\n\nNous allons donc utiliser read_csv2() avec ses arguments par défaut.\n\nlibrary(\"tidyverse\")\nchicoute &lt;- read_csv2(\"data/chicoute.csv\")\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 90 Columns: 31\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr  (5): CodeTourbiere, Ordre, Traitement, DemiParcelle, SousTraitement\ndbl (26): ID, Site, Latitude_m, Longitude_m, Rendement_g_5m2, TotalRamet_nom...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nQuelques commandes utiles inspecter le tableau:\n\nhead() présente l’entête du tableau, soit ses 6 premières lignes\nstr() et glimpse() présentent les variables du tableau et leur type - glimpse()est la fonction tidyverse et str() est la fonction classique (je préfère str())\nsummary() présente des statistiques de base du tableau\nnames() ou colnames() sort les noms des colonnes sous forme d’un vecteur\ndim() donne les dimensions du tableau, ncol() son nombre de colonnes et nrow() son nombre de lignes\nskim est une fonction du module skimr montrant un portrait graphique et numérique du tableau\n\nExtra 1. Plusieurs modules ne se trouvent pas dans les dépôts CRAN, mais sont disponibles sur GitHub. Pour les installer, installez d’abord le module devtools disponible sur CRAN. Vous pourrez alors installer les packages de GitHub comme on le fait avec le package skimr.\nExtra 2. Lorsque je désire utiliser une fonction, mais sans charger le module dans la session, j’utilise la notation module::fonction. Comme dans ce cas, pour skimr.\n\nskimr::skim(chicoute)\n\n\nData summary\n\n\nName\nchicoute\n\n\nNumber of rows\n90\n\n\nNumber of columns\n31\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nnumeric\n26\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nCodeTourbiere\n0\n1.00\n1\n4\n0\n12\n0\n\n\nOrdre\n0\n1.00\n1\n2\n0\n20\n0\n\n\nTraitement\n50\n0.44\n6\n11\n0\n2\n0\n\n\nDemiParcelle\n50\n0.44\n4\n5\n0\n2\n0\n\n\nSousTraitement\n50\n0.44\n1\n7\n0\n3\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nID\n0\n1.00\n45.50\n26.12\n1.00\n23.25\n45.50\n67.75\n90.00\n▇▇▇▇▇\n\n\nSite\n0\n1.00\n6.33\n5.49\n1.00\n2.00\n4.00\n9.00\n20.00\n▇▃▁▁▁\n\n\nLatitude_m\n0\n1.00\n5701839.86\n1915.50\n5695688.00\n5701868.50\n5702129.00\n5702537.00\n5706394.00\n▁▂▅▇▁\n\n\nLongitude_m\n0\n1.00\n485295.54\n6452.33\n459873.00\n485927.00\n486500.00\n486544.75\n491955.00\n▁▁▁▂▇\n\n\nRendement_g_5m2\n50\n0.44\n13.33\n21.56\n0.00\n0.00\n0.95\n15.63\n72.44\n▇▁▁▁▁\n\n\nTotalRamet_nombre_m2\n0\n1.00\n251.26\n156.06\n40.74\n122.70\n212.92\n347.80\n651.90\n▇▇▃▂▂\n\n\nTotalVegetatif_nombre_m2\n4\n0.96\n199.02\n139.13\n22.92\n86.26\n161.25\n263.78\n580.60\n▇▇▂▂▁\n\n\nTotalFloral_nombre_m2\n4\n0.96\n52.08\n40.41\n4.80\n22.92\n43.00\n69.52\n198.62\n▇▅▂▁▁\n\n\nTotalMale_nombre_m2\n4\n0.96\n24.40\n26.87\n0.00\n3.30\n15.28\n36.51\n104.41\n▇▂▂▁▁\n\n\nTotalFemelle_nombre_m2\n4\n0.96\n27.53\n29.83\n2.55\n10.34\n17.19\n31.96\n187.17\n▇▁▁▁▁\n\n\nFemelleFruit_nombre_m2\n18\n0.80\n19.97\n23.79\n0.40\n7.64\n11.46\n22.83\n157.88\n▇▂▁▁▁\n\n\nFemelleAvorte_nombre_m2\n4\n0.96\n8.49\n14.52\n0.00\n1.27\n3.07\n10.14\n76.80\n▇▁▁▁▁\n\n\nSterileFleur_nombre_m2\n4\n0.96\n0.26\n0.71\n0.00\n0.00\n0.00\n0.00\n3.82\n▇▁▁▁▁\n\n\nC_pourc\n0\n1.00\n50.28\n1.61\n46.72\n49.14\n50.45\n51.58\n53.83\n▃▆▅▇▁\n\n\nN_pourc\n0\n1.00\n2.20\n0.40\n1.53\n1.89\n2.12\n2.58\n3.10\n▃▇▃▃▂\n\n\nP_pourc\n0\n1.00\n0.14\n0.04\n0.07\n0.12\n0.14\n0.16\n0.23\n▃▆▇▂▂\n\n\nK_pourc\n0\n1.00\n0.89\n0.27\n0.35\n0.69\n0.86\n1.13\n1.54\n▃▇▇▇▁\n\n\nCa_pourc\n0\n1.00\n0.39\n0.10\n0.19\n0.32\n0.37\n0.44\n0.88\n▅▇▂▁▁\n\n\nMg_pourc\n0\n1.00\n0.50\n0.08\n0.36\n0.45\n0.48\n0.52\n0.86\n▇▇▂▁▁\n\n\nS_pourc\n0\n1.00\n0.13\n0.04\n0.07\n0.11\n0.13\n0.14\n0.28\n▅▇▂▁▁\n\n\nB_pourc\n0\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n▂▅▃▇▃\n\n\nCu_pourc\n0\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n▇▁▁▁▁\n\n\nZn_pourc\n0\n1.00\n0.01\n0.00\n0.00\n0.01\n0.01\n0.01\n0.02\n▇▇▂▁▁\n\n\nMn_pourc\n0\n1.00\n0.03\n0.03\n0.00\n0.01\n0.03\n0.05\n0.10\n▇▅▃▂▁\n\n\nFe_pourc\n0\n1.00\n0.02\n0.01\n0.01\n0.01\n0.01\n0.02\n0.05\n▇▂▁▁▁\n\n\nAl_pourc\n0\n1.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.00\n0.01\n▇▅▁▁▁\n\n\n\n\n\nExercice. Inspectez le tableau.\n\n\n3.5.2 Comment sélectionner et filtrer des données ?\nOn utilise le terme sélectionner lorsque l’on désire choisir une ou plusieurs lignes et colonnes d’un tableau (la plupart du temps des colonnes). L’action de filtrer signifie de sélectionner des lignes selon certains critères.\n\n3.5.2.1 Sélectionner\nVoici 4 manières de sélectionner une colonne en R.\n\nUne méthode rapide mais peu expressive consiste à indiquer les valeurs numériques de l’indice de la colonne entre des crochets. Il s’agit d’appeler le tableau suivi de crochets. L’intérieur des crochets comprend deux éléments séparés par une virgule. Le premier élément sert à filtrer selon l’indice, le deuxième sert à sélectionner selon l’indice. Ainsi:\n\nchicoute[, 1]: sélectionner la première colonne\nchicoute[, 1:10]: sélectionner les 10 premières colonnes\nchicoute[, c(2, 4, 5)]: sélectionner les colonnes 2, 4 et 5\nchicoute[c(10, 13, 20), c(2, 4, 5)]: sélectionner les colonnes 2, 4 et 5 et les lignes 10, 13 et 20.\n\nUne autre méthode rapide, mais plus expressive, consiste à appeler le tableau, suivi du symbole $, puis le nom de la colonne, e.g. chicoute$Site.\n\n\nTruc. La plupart des IDE, comme RStudio, peuvent vous proposer des colonnes dans une liste. Après avoir saisi le $, taper sur la touche de tabulation: vous pourrez sélectionner la colonne dans une liste défilante (Figure 3.4).\n\n\n\n\n\n\nFigure 3.4: Autocomplétion dans RStudio.\n\n\n\n\n\nVous pouvez aussi inscrire le nom de la colonne, ou du vecteur des colonnes, entre des crochets suivant le nom du tableau, c’est-à-dire chicoute[c(\"Site\", \"Latitude_m\", \"Longitude_m\")].\nEnfin, dans une séquence d’opérations en mode pipeline (chaque opération est mise à la suite de la précédente en plaçant le pipe |&gt; entre chacune), il peut être préférable de sélectionner des colonnes avec la fonction select(), i.e.\n\n\nchicoute |&gt; \n  select(Site, Latitude_m, Longitude_m)\n\n\nNote sur le mode pipeline : Le pipe |&gt; a été introduit dans R-base en 2021. Auparavant, on utilisait la fonction %&gt;% introduite dans le module magrittr, inclus dans tidyverse. La plupart du temps, les deux fonctionnent sensiblement de la même façon, mais il existe quelques différences dans leur interaction avec certaines fonctions. Puisque |&gt; fait partie de R-base, je vous suggère de l’utiliser par défaut, mais il est fort probable que vous trouviez l’ancienne version %&gt;% lors de vos recherches sur internet (ou même dans ce guide si j’oublie d’effectuer les modifications). Pour insérer un pipe, il suffit d’utiliser le raccourci clavier Ctrl + Shift + M. Vous pouvez modifier la forme par défaut dans les options de RStudio, comme sur la Figure 3.5.\n\n\n\n\n\n\nFigure 3.5: Modifier le pipe par défaut dans RStudio.\n\n\n\n\nLa fonction select() permet aussi de travailler en exclusion. Ainsi pour enlever des colonnes, on placera un - (signe de soustraction) devant le nom de la colonne.\n⚠️ Attention. Plusieurs modules utilisent la fonction select (et filter, plus bas). Lorsque vous lancez select et que vous obtenez un message d’erreur comme\nError in select(., ends_with(\"pourc\")) : \n  argument inutilisé (ends_with(\"pourc\"))\nil se pourrait bien que R utilise la fonction select d’un autre module. Pour spécifier que vous désirez la fonction select du module dplyr, spécifiez dplyr::select.\nD’autre arguments de select() permettent une sélection rapide. Par exemple, pour obtenir les colonnes contenant des pourcentages:\n\nchicoute |&gt; \n  select(ends_with(\"pourc\")) |&gt; \n  head(3)\n\n# A tibble: 3 × 13\n  C_pourc N_pourc P_pourc K_pourc Ca_pourc Mg_pourc S_pourc B_pourc Cu_pourc\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1    51.5    1.72  0.108     1.21    0.435    0.470  0.0976 0.00258 0.000175\n2    51.3    2.18  0.0985    1.22    0.337    0.439  0.0996 0.00258 0.000407\n3    50.6    2.12  0.0708    1.05    0.373    0.420  0.104  0.00258 0.000037\n# ℹ 4 more variables: Zn_pourc &lt;dbl&gt;, Mn_pourc &lt;dbl&gt;, Fe_pourc &lt;dbl&gt;,\n#   Al_pourc &lt;dbl&gt;\n\n\n\n\n3.5.2.2 Filtrer\nComme c’est le cas de la sélection, on pourra filtrer un tableau de plusieurs manières. J’ai déjà présenté comment filtrer selon les indices des lignes. Les autres manières reposent néanmoins sur une opération logique ==, &lt;, &gt; ou %in% (le %in% signifie se trouve parmi et peut être suivi d’un vecteur de valeurs que l’on désire accepter).\nLes conditions booléennes peuvent être combinées avec les opérateurs et, &, et ou, |. Pour rappel,\n\n\n\nOpération\nRésultat\n\n\n\n\nVrai et Vrai\nVrai\n\n\nVrai et Faux\nFaux\n\n\nFaux et Faux\nFaux\n\n\nVrai ou Vrai\nVrai\n\n\nVrai ou Faux\nVrai\n\n\nFaux ou Faux\nFaux\n\n\n\n\nLa méthode classique consiste à appliquer une opération logique entre les crochets, par exemple chicoute[chicoute$CodeTourbiere == \"BEAU\", ]\nLa méthode tidyverse, plus pratique en mode pipeline, passe par la fonction filter(), i.e.\n\nchicoute |&gt; \n  filter(CodeTourbiere == \"BEAU\")\nCombiner le tout.\n\nchicoute |&gt; \n  filter(Ca_pourc &lt; 0.4 & CodeTourbiere %in% c(\"BEAU\", \"MB\", \"WTP\")) |&gt; \n  select(contains(\"pourc\"))\n\n# A tibble: 4 × 13\n  C_pourc N_pourc P_pourc K_pourc Ca_pourc Mg_pourc S_pourc B_pourc Cu_pourc\n    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;\n1    51.3    2.18  0.0985   1.22     0.337    0.439  0.0996 0.00258 0.000407\n2    50.6    2.12  0.0708   1.05     0.373    0.420  0.104  0.00258 0.000037\n3    53.8    2.04  0.115    0.947    0.333    0.472  0.106  0.00258 0.000037\n4    52.6    2.11  0.0847   0.913    0.328    0.376  0.111  0.00296 0.000037\n# ℹ 4 more variables: Zn_pourc &lt;dbl&gt;, Mn_pourc &lt;dbl&gt;, Fe_pourc &lt;dbl&gt;,\n#   Al_pourc &lt;dbl&gt;\n\n\n\n\n\n3.5.3 Le format long et le format large\nDans le tableau chicoute, chaque élément possède sa propre colonne. Si l’on voulait mettre en graphique les boxplot des facettes de concentrations d’azote, de phosphore et de potassium dans les différentes tourbières, il faudrait obtenir une seule colonne de concentrations.\nPour ce faire, nous utiliserons la fonction pivot_longer(). L’argument obligatoire (excluant le tableau, qui est implicite dans la chaîne d’opérations), est cols, le nom des colonnes à allonger. Pour obtenir des noms de colonnes allongées personnalisées, on spécifie le nom des variables consistant aux anciens noms de colonnes avec names_to et celui de la nouvelle colonne contenant les valeurs dans values_to. La suite consiste à décrire les colonnes à inclure ou à exclure. Dans le cas qui suit, j’exclue CodeTourbiere de la refonte et j’utilise slice_sample() pour présenter un échantillon aléatoire du résultat. Notez la ligne comprenant la fonction mutate, que l’on verra plus loin. Cette fonction ajoute une colonne au tableau. Dans ce cas-ci, j’ajoute une colonne constituée d’une séquence de nombres allant de 1 au nombre de lignes du tableau (il y en a 90). Cet identifiant unique pour chaque ligne permettra de reconstituer par la suite le tableau initial.\n\nchicoute_long &lt;- chicoute |&gt; \n  select(CodeTourbiere, N_pourc, P_pourc, K_pourc) |&gt; \n  mutate(ID = 1:n())  |&gt;  # mutate ajoute une colonne au tableau\n  # pour l'identifiant, on peut aussi utiliser la commande cur_group_rows()\n  pivot_longer(cols = contains(\"pourc\"), names_to = \"nutrient\", values_to = \"concentration\")\nchicoute_long |&gt;  slice_sample(n = 10)\n\n# A tibble: 10 × 4\n   CodeTourbiere    ID nutrient concentration\n   &lt;chr&gt;         &lt;int&gt; &lt;chr&gt;            &lt;dbl&gt;\n 1 2                21 P_pourc          0.233\n 2 1                75 K_pourc          0.684\n 3 2                12 K_pourc          1.24 \n 4 BEAU              1 K_pourc          1.21 \n 5 SSP              59 P_pourc          0.136\n 6 2                11 P_pourc          0.138\n 7 MB               32 N_pourc          2.09 \n 8 1                84 K_pourc          1.32 \n 9 SSP              57 N_pourc          1.66 \n10 1                78 N_pourc          2.31 \n\n\nL’opération inverse est pivot_wider(), avec laquelle nous sélectionnons une colonne spécifiant les nouvelles colonnes à construire (names_from) ainsi que les valeurs à placer dans ces colonnes (values_from).\n\nchicoute_large &lt;- chicoute_long |&gt; \n  pivot_wider(names_from = nutrient, values_from = concentration)\nchicoute_large |&gt;  slice_sample(n = 10)\n\n# A tibble: 10 × 5\n   CodeTourbiere    ID N_pourc P_pourc K_pourc\n   &lt;chr&gt;         &lt;int&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;\n 1 2                19    2.62  0.213    1.21 \n 2 NESP             41    1.73  0.148    0.851\n 3 BP                8    1.77  0.166    0.778\n 4 1                67    2.22  0.175    0.871\n 5 MB               35    2.11  0.0847   0.913\n 6 NTP              55    1.88  0.0776   0.419\n 7 2                17    2.61  0.142    1.01 \n 8 NBM              50    2.42  0.156    0.825\n 9 NESP             44    1.75  0.120    1.13 \n10 MR               38    1.95  0.113    0.906\n\n\n\n\n3.5.4 Combiner des tableaux\nNous avons introduit plus haut la notion de base de données. Nous voudrions peut-être utiliser le code des tourbières pour inclure leur nom, le type d’essai mené à ces tourbières, etc. Importons d’abord le tableau des noms liés aux codes.\n\ntourbieres &lt;- read_csv2(\"data/chicoute_tourbieres.csv\")\n\nℹ Using \"','\" as decimal and \"'.'\" as grouping mark. Use `read_delim()` for more control.\n\n\nRows: 11 Columns: 4\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \";\"\nchr (4): Tourbiere, CodeTourbiere, Type, TypeCulture\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ntourbieres\n\n# A tibble: 11 × 4\n   Tourbiere               CodeTourbiere Type        TypeCulture\n   &lt;chr&gt;                   &lt;chr&gt;         &lt;chr&gt;       &lt;chr&gt;      \n 1 Beaulieu                BEAU          calibration naturel    \n 2 Brador Path             BP            calibration naturel    \n 3 Lichen (BS2E)           2             validation  cultive sec\n 4 Mannys Brook            MB            calibration naturel    \n 5 Middle Bay Road         MR            calibration naturel    \n 6 North Est of Smelt Pond NESP          calibration naturel    \n 7 North of Blue Moon      NBM           calibration naturel    \n 8 South of Smelt Pond     SSP           calibration naturel    \n 9 Sphaigne (BS2F)         BS2           validation  cultive sec\n10 Sphaigne (BS2F)         1             calibration naturel    \n11 West of Trout Pond      WTP           calibration naturel    \n\n\nNotre information est organisée en deux tableaux, liés par la colonne CodeTourbiere. Comment fusionner l’information pour qu’elle puisse être utilisée dans son ensemble? La fonction left_join effectue cette opération typique avec les bases de données.\n\nchicoute_merge &lt;- left_join(x = chicoute, y = tourbieres, by = \"CodeTourbiere\")\n# ou bien chicoute |&gt;  left_join(y = tourbieres, by = \"CodeTourbiere\")\nchicoute_merge |&gt;  slice_head(n = 4)\n\n# A tibble: 4 × 34\n     ID CodeTourbiere Ordre  Site Traitement DemiParcelle SousTraitement\n  &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;         \n1     1 BEAU          A         1 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n2     2 BEAU          A         2 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n3     3 BEAU          A         3 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n4     4 BEAU          A         4 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n# ℹ 27 more variables: Latitude_m &lt;dbl&gt;, Longitude_m &lt;dbl&gt;,\n#   Rendement_g_5m2 &lt;dbl&gt;, TotalRamet_nombre_m2 &lt;dbl&gt;,\n#   TotalVegetatif_nombre_m2 &lt;dbl&gt;, TotalFloral_nombre_m2 &lt;dbl&gt;,\n#   TotalMale_nombre_m2 &lt;dbl&gt;, TotalFemelle_nombre_m2 &lt;dbl&gt;,\n#   FemelleFruit_nombre_m2 &lt;dbl&gt;, FemelleAvorte_nombre_m2 &lt;dbl&gt;,\n#   SterileFleur_nombre_m2 &lt;dbl&gt;, C_pourc &lt;dbl&gt;, N_pourc &lt;dbl&gt;, P_pourc &lt;dbl&gt;,\n#   K_pourc &lt;dbl&gt;, Ca_pourc &lt;dbl&gt;, Mg_pourc &lt;dbl&gt;, S_pourc &lt;dbl&gt;, …\n\n\nD’autres types de jointures sont possibles, et décrites en détails dans la documentation.\nGarrick Aden-Buie a préparé de jolies animations pour décrire les différents types de jointures.\nleft_join(x, y) colle y à x seulement ce qui dans y correspond à ce que l’on trouve dans x.\n\nright_join(x, y) colle y à x seulement ce qui dans x correspond à ce que l’on trouve dans y.\n\ninner_join(x, y) colle x et y en excluant les lignes où au moins une variable de jointure est absente dans x et y.\n\nfull_join(x, y)garde toutes les lignes et les colonnes de x et y.\n\n\n\n3.5.5 Opérations sur les tableaux\nLes tableaux peuvent être segmentés en éléments sur lesquels on calculera ce qui nous chante.\nOn pourrait vouloir obtenir :\n\nla somme avec la function sum()\nla moyenne avec la function mean() ou la médiane avec la fonction median()\nl’écart-type avec la function sd()\nles maximum et minimum avec les fonctions min() et max()\nun décompte d’occurrence avec la fonction n() ou count()\n\nPar exemple,\n\nmean(chicoute$Rendement_g_5m2, na.rm = TRUE)\n\n[1] 13.32851\n\n\nEn mode classique, pour effectuer des opérations sur des tableaux, on utilisera la fonction apply(). Cette fonction prend, comme arguments, le tableau, l’axe (opération par ligne = 1, opération par colonne = 2), puis la fonction à appliquer.\n\napply(chicoute |&gt;  select(contains(\"pourc\")), 2, mean)\n\n     C_pourc      N_pourc      P_pourc      K_pourc     Ca_pourc     Mg_pourc \n5.027911e+01 2.199411e+00 1.388959e-01 8.887000e-01 3.884391e-01 4.980142e-01 \n     S_pourc      B_pourc     Cu_pourc     Zn_pourc     Mn_pourc     Fe_pourc \n1.347177e-01 3.090922e-03 4.089891e-04 6.662155e-03 3.345239e-02 1.514885e-02 \n    Al_pourc \n2.694979e-03 \n\n\nLes opérations peuvent aussi être effectuées par ligne, par exemple une somme (je garde seulement les 10 premiers résultats).\n\napply(chicoute |&gt;  select(contains(\"pourc\")), 1, sum)[1:10]\n\n [1] 55.64299 55.76767 54.78856 55.84453 57.89671 55.53603 55.62526 55.10991\n [9] 55.06295 55.16774\n\n\nLa fonction à appliquer peut être personnalisée, par exemple:\n\napply(\n  chicoute |&gt;  select(contains(\"pourc\")), 2,\n  function(x) (prod(x))^(1 / length(x))\n)\n\n     C_pourc      N_pourc      P_pourc      K_pourc     Ca_pourc     Mg_pourc \n50.253429104  2.165246915  0.133754530  0.846193827  0.376192724  0.491763884 \n     S_pourc      B_pourc     Cu_pourc     Zn_pourc     Mn_pourc     Fe_pourc \n 0.129900753  0.003014675  0.000000000  0.006408775  0.024140327  0.014351745 \n    Al_pourc \n 0.002450982 \n\n\nVous reconnaissez cette fonction? C’était la moyenne géométrique (la fonction prod() étant le produit d’un vecteur).\nEn mode tidyverse, on aura besoin principalement des fonction suivantes:\n\ngroup_by() pour effectuer des opérations par groupe, l’opération group_by() sépare le tableau en plusieurs petits tableaux, en attendant de les recombiner. C’est un peu l’équivalent des facettes avec le module de visualisation ggplot2, que nous explorons au chapitre 4.\nsummarise() pour réduire plusieurs valeurs en une seule, il applique un calcul sur le tableau ou s’il y a lieu sur chaque petit tableau segmenté. Il en existe quelques variantes.\n\nsummarise_all() applique la fonction à toutes les colonnes\nsummarise_at() applique la fonction aux colonnes spécifiées\nsummarise_if() applique la fonction aux colonnes qui ressortent comme TRUE selon une opération booléenne\n\nmutate() pour ajouter une nouvelle colonne\n\nSi l’on désire ajouter une colonne à un tableau, par exemple le sommaire calculé avec summarise(). À l’inverse, la fonction transmute() retournera seulement le résultat, sans le tableau à partir duquel il a été calculé. De même que summarise(), mutate() et transmute() possèdent leurs équivalents _all(), _at() et _if().\n\narrange() pour réordonner le tableau\n\nCette fonction est parfois utile lors de la mise en page de tableaux ou de graphiques. Il ne s’agit pas d’une opération sur un tableau, mais plutôt un changement d’affichage en changeant l’ordre d’apparition des données.\n\n\nCes opérations sont décrites dans l’aide-mémoire Data Transformation Cheat Sheet (Figure 3.6).\n\n\n\n\n\nFigure 3.6: Aide-mémoire pour la transformation des données, https://rstudio.github.io/cheatsheets/data-transformation.pdf\n\n\n\n\nPour effectuer des statistiques par colonne, on utilisera summarise pour des statistiques effectuées sur une seule colonne. summarise peut prendre le nombre désiré de statistiques dont la sortie est un scalaire.\n\nchicoute |&gt; \n  summarise(\n    moyenne = mean(TotalFloral_nombre_m2, na.rm = TRUE),\n    ecart_type = sd(TotalFloral_nombre_m2, na.rm = TRUE)\n  )\n\n# A tibble: 1 × 2\n  moyenne ecart_type\n    &lt;dbl&gt;      &lt;dbl&gt;\n1    52.1       40.4\n\n\nSi l’on désire un sommaire sur toutes les variables sélectionnées, on utilisera summarise_all(). Pour spécifier que l’on désire la moyenne et l’écart-type, on inscrit les noms des fonctions dans list().\n\nchicoute |&gt; \n  select(contains(\"pourc\")) |&gt; \n  summarise_all(list(mean, sd))\n\n# A tibble: 1 × 26\n  C_pourc_fn1 N_pourc_fn1 P_pourc_fn1 K_pourc_fn1 Ca_pourc_fn1 Mg_pourc_fn1\n        &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;        &lt;dbl&gt;\n1        50.3        2.20       0.139       0.889        0.388        0.498\n# ℹ 20 more variables: S_pourc_fn1 &lt;dbl&gt;, B_pourc_fn1 &lt;dbl&gt;,\n#   Cu_pourc_fn1 &lt;dbl&gt;, Zn_pourc_fn1 &lt;dbl&gt;, Mn_pourc_fn1 &lt;dbl&gt;,\n#   Fe_pourc_fn1 &lt;dbl&gt;, Al_pourc_fn1 &lt;dbl&gt;, C_pourc_fn2 &lt;dbl&gt;,\n#   N_pourc_fn2 &lt;dbl&gt;, P_pourc_fn2 &lt;dbl&gt;, K_pourc_fn2 &lt;dbl&gt;,\n#   Ca_pourc_fn2 &lt;dbl&gt;, Mg_pourc_fn2 &lt;dbl&gt;, S_pourc_fn2 &lt;dbl&gt;,\n#   B_pourc_fn2 &lt;dbl&gt;, Cu_pourc_fn2 &lt;dbl&gt;, Zn_pourc_fn2 &lt;dbl&gt;,\n#   Mn_pourc_fn2 &lt;dbl&gt;, Fe_pourc_fn2 &lt;dbl&gt;, Al_pourc_fn2 &lt;dbl&gt;\n\n\nOn utilisera group_by() pour segmenter le tableau, et ainsi obtenir des statistiques pour chaque groupe.\n\nchicoute |&gt; \n  group_by(CodeTourbiere) |&gt; \n  summarise(\n    moyenne = mean(TotalFloral_nombre_m2, na.rm = TRUE),\n    ecart_type = sd(TotalFloral_nombre_m2, na.rm = TRUE)\n  )\n\n# A tibble: 12 × 3\n   CodeTourbiere moyenne ecart_type\n   &lt;chr&gt;           &lt;dbl&gt;      &lt;dbl&gt;\n 1 1                72.1      32.7 \n 2 2                37.1      32.9 \n 3 BEAU            149.       53.2 \n 4 BP               60.4      30.6 \n 5 BS2              27.2      15.5 \n 6 MB               64.7      40.8 \n 7 MR               35.1      10.5 \n 8 NBM              35.1      16.6 \n 9 NESP             21.4       4.88\n10 NTP              47.6      15.9 \n11 SSP              25.7      11.1 \n12 WTP              50.2      28.3 \n\n\nDans le cas de summarise_all, les résultats s’affichent de la même manière.\n\nchicoute |&gt; \n  group_by(CodeTourbiere) |&gt; \n  select(N_pourc, P_pourc, K_pourc) |&gt; \n  summarise_all(list(mean, sd))\n\nAdding missing grouping variables: `CodeTourbiere`\n\n\n# A tibble: 12 × 7\n   CodeTourbiere N_pourc_fn1 P_pourc_fn1 K_pourc_fn1 N_pourc_fn2 P_pourc_fn2\n   &lt;chr&gt;               &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;       &lt;dbl&gt;\n 1 1                    2.26      0.156        0.880      0.250      0.0193 \n 2 2                    2.76      0.181        1.12       0.178      0.0283 \n 3 BEAU                 2.00      0.0967       1.12       0.179      0.0172 \n 4 BP                   2.05      0.158        0.747      0.161      0.00625\n 5 BS2                  2.08      0.103        1.12       0.420      0.0218 \n 6 MB                   2.15      0.109        0.675      0.114      0.0165 \n 7 MR                   1.99      0.127        0.830      0.0802     0.0131 \n 8 NBM                  2.01      0.127        0.854      0.310      0.0202 \n 9 NESP                 1.76      0.135        0.945      0.149      0.0108 \n10 NTP                  1.83      0.0873       0.402      0.166      0.0103 \n11 SSP                  1.83      0.130        0.700      0.160      0.00383\n12 WTP                  1.79      0.0811       0.578      0.132      0.00587\n# ℹ 1 more variable: K_pourc_fn2 &lt;dbl&gt;\n\n\nPour obtenir des statistiques à chaque ligne, mieux vaut utiliser apply(), tel que vu précédemment. Le point, ., représente le tableau dans une fonction qui n’a pas été conçue pour fonctionner de facto avec dplyr.\n\nchicoute |&gt; \n  select(contains(\"pourc\")) |&gt; \n  apply(1, sum)\n\n [1] 55.64299 55.76767 54.78856 55.84453 57.89671 55.53603 55.62526 55.10991\n [9] 55.06295 55.16774 56.41123 55.47917 55.43537 55.79175 55.44561 54.85448\n[17] 54.34262 55.03075 54.40533 51.89319 54.70172 54.62176 54.30250 53.86976\n[25] 53.44731 53.86244 52.43280 54.34978 53.96756 51.46672 55.44267 54.70350\n[33] 55.30711 56.16200 56.64710 55.95499 54.76370 54.32775 54.95419 53.37094\n[41] 53.07855 53.04541 52.09520 52.40456 51.92376 53.33248 56.56405 56.35004\n[49] 56.27185 55.56986 53.81654 55.39638 55.51961 54.88098 54.74774 51.08921\n[57] 51.31462 53.46819 53.15640 52.82020 57.78038 57.94636 56.65558 56.28845\n[65] 55.54463 56.51751 55.36497 56.00594 55.64247 56.56967 56.81674 55.87070\n[73] 55.72308 56.14116 56.42611 55.35650 54.90469 54.03674 53.42991 53.99334\n[81] 53.09085 53.23222 53.28212 53.63192 53.48102 52.31131 51.72026 51.10534\n[89] 51.49055 51.59297\n\n\nPrenons ce tableau des espèces menacées issu de l’Union internationale pour la conservation de la nature distribué par l’OCDE.\n\nlibrary(\"tidyverse\")\nespeces_menacees &lt;- read_csv(\"data/WILD_LIFE_14012020030114795.csv\")\n\nNous exécutons le pipeline suivant.\n\nespeces_menacees |&gt; \n  dplyr::filter(IUCN == \"CRITICAL\", SPEC == \"VASCULAR_PLANT\") |&gt; \n  dplyr::select(Country, Value) |&gt; \n  dplyr::group_by(Country) |&gt; \n  dplyr::summarise(n_critical_plants = sum(Value)) |&gt; \n  dplyr::arrange(desc(n_critical_plants)) |&gt; \n  dplyr::slice_head(n = 10)\n\n# A tibble: 10 × 2\n   Country         n_critical_plants\n   &lt;chr&gt;                       &lt;dbl&gt;\n 1 United States                1222\n 2 Japan                         525\n 3 Canada                        315\n 4 Czech Republic                284\n 5 Spain                         271\n 6 Belgium                       253\n 7 Austria                       172\n 8 Slovak Republic               155\n 9 Australia                     148\n10 Italy                         128\n\n\nCe pipeline consiste à:\nprendre le tableau especes_menacees, puis\n  \nfiltrer pour n'obtenir que les espèces critiques dans la catégorie des plantes vasculaires, puis\n  \nsélectionner les colonnes des pays et des valeurs (nombre d'espèces), puis\n\nsegmenter le tableau en plusieurs tableaux selon le pays, puis\n\nappliquer la fonction sum pour chacun de ces petits tableaux (et recombiner ces sommaires), puis\n\ntrier les pays en nombre décroissant de décompte d'espèces, puis\n\nafficher le top 10\nNotez qu’il aurait aussi été possible d’utiliser la fonction dplyr::slice_max(n_critical_plants, n = 10) pour afficher directement le top 10, sans faire le tri préalable.\n\n\n3.5.6 Exemple (difficile)\nPour revenir à notre tableau chicoute, imaginez que vous aviez une station météo (station_A) située aux coordonnées (490640, 5702453) et que vous désiriez calculer la distance entre l’observation et la station. Prenez du temps pour réfléchir à la manière dont vous procéderez…\n\nOn pourra créer une fonction qui mesure la distance entre un point x, y et les coordonnées de la station A…\n\ndist_station_A &lt;- function(x, y) {\n  return(sqrt((x - 490640)^2 + (y - 5702453)^2))\n}\n\n… puis ajouter une colonne avec mutate grâce à une fonction prenant les arguments x et y spécifiés.\n\nchicoute |&gt; \n  mutate(dist = dist_station_A(x = Longitude_m, y = Latitude_m)) |&gt; \n  select(ID, CodeTourbiere, Longitude_m, Latitude_m, dist) |&gt; \n  slice_sample(n = 10)\n\n# A tibble: 10 × 5\n      ID CodeTourbiere Longitude_m Latitude_m     dist\n   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1    64 BS2                486530    5702199  4118.  \n 2    41 NESP               484875    5701888  5793.  \n 3    79 1                  486499    5702076  4158.  \n 4    53 NTP                487562    5704093  3488.  \n 5    14 2                  486538    5702562  4103.  \n 6     3 BEAU               490638    5702461     8.25\n 7    17 2                  486501    5702627  4143.  \n 8    26 2                  486315    5702540  4326.  \n 9    38 MR                 459880    5701971 30764.  \n10    28 2                  486353    5702478  4287.  \n\n\nNous pourrions procéder de la même manière pour fusionner des données climatiques. Le tableau chicoute ne possède pas d’indicateurs climatiques, mais il est possible de les soutirer de stations météo placées près des sites. Ces données ne sont pas disponibles pour le tableau de la chicouté, alors j’utiliserai des données fictives pour l’exemple.\nVoici ce qui pourrait être fait.\n\nCréer un tableau des stations météo ainsi que des indices météorologiques associés à ces stations.\nLier chaque site à une station (à la main où selon la plus petite distance entre le site et la station).\nFusionner les indices climatiques aux sites, puis les sites aux mesures de rendement.\n\nCes opérations demandent habituellement du tâtonnement. Il serait surprenant que même une personne expérimentée soit en mesure de compiler ces opérations sans obtenir de message d’erreur, et retravailler jusqu’à obtenir le résultat souhaité. L’objectif de cette section est de vous présenter un flux de travail que vous pourriez être amenés à effectuer et de fournir quelques éléments nouveaux pour mener à bien une opération. Il peut être frustrant de ne pas saisir toutes les opérations: passez à travers cette section sans jugement. Si vous devez vous frotter à un problème semblable, vous saurez que vous trouverez dans ce manuel une recette intéressante.\n\nmes_stations &lt;- data.frame(\n  Station = c(\"A\", \"B\", \"C\"),\n  Longitude_m = c(490640, 484870, 485929),\n  Latitude_m = c(5702453, 5701870, 5696421),\n  t_moy_C = c(13.8, 18.2, 16.30),\n  prec_tot_mm = c(687, 714, 732)\n)\nmes_stations\n\n  Station Longitude_m Latitude_m t_moy_C prec_tot_mm\n1       A      490640    5702453    13.8         687\n2       B      484870    5701870    18.2         714\n3       C      485929    5696421    16.3         732\n\n\nLa fonction suivante calcule la distance entre des coordonnées x et y et chaque station d’un tableau de stations, puis retourne le nom de la station dont la distance est la moindre.\n\ndist_station &lt;- function(x, y, stations_df) {\n  # stations est le tableau des stations à trois colonnes\n  # 1iere: nom de la station\n  # 2ieme: longitude\n  # 3ieme: latitude\n  distance &lt;- c()\n  for (i in 1:nrow(stations_df)) {\n    distance[i] &lt;- sqrt((x - stations_df[i, 2])^2 + (y - stations_df[i, 3])^2)\n  }\n  nom_station &lt;- as.character(stations_df$Station[which.min(distance)])\n  return(nom_station)\n}\n\nTestons la fonction avec des coordonnées.\n\ndist_station(x = 459875, y = 5701988, stations_df = mes_stations)\n\n[1] \"B\"\n\n\nNous appliquons cette fonction à toutes les lignes du tableau, puis en retournons un échantillon.\n\nchicoute |&gt; \n  rowwise() |&gt; \n  mutate(Station = dist_station(x = Longitude_m, y = Latitude_m, stations_df = mes_stations)) |&gt; \n  select(ID, CodeTourbiere, Longitude_m, Latitude_m, Station) |&gt; \n  slice_sample(n = 10)\n\n# A tibble: 90 × 5\n# Rowwise: \n      ID CodeTourbiere Longitude_m Latitude_m Station\n   &lt;dbl&gt; &lt;chr&gt;               &lt;dbl&gt;      &lt;dbl&gt; &lt;chr&gt;  \n 1     1 BEAU               490627    5702454 A      \n 2     2 BEAU               490634    5702452 A      \n 3     3 BEAU               490638    5702461 A      \n 4     4 BEAU               490647    5702453 A      \n 5     5 BEAU               490654    5702445 A      \n 6     6 BP                 484865    5706394 B      \n 7     7 BP                 484054    5706307 B      \n 8     8 BP                 484742    5702280 B      \n 9     9 BP                 484761    5706324 B      \n10    10 BP                 484780    5706364 B      \n# ℹ 80 more rows\n\n\nCela semble fonctionner. On peut y ajouter un left_join() pour joindre les données météo au tableau principal.\n\nchicoute_weather &lt;- chicoute |&gt; \n  rowwise() |&gt; \n  mutate(Station = dist_station(x = Longitude_m, y = Latitude_m, stations_df = mes_stations)) |&gt; \n  left_join(y = mes_stations, by = \"Station\")\nchicoute_weather |&gt;  slice_sample(n = 10)\n\n# A tibble: 90 × 36\n# Rowwise: \n      ID CodeTourbiere Ordre  Site Traitement DemiParcelle SousTraitement\n   &lt;dbl&gt; &lt;chr&gt;         &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;chr&gt;        &lt;chr&gt;         \n 1     1 BEAU          A         1 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 2     2 BEAU          A         2 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 3     3 BEAU          A         3 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 4     4 BEAU          A         4 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 5     5 BEAU          A         5 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 6     6 BP            H         1 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 7     7 BP            H         2 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 8     8 BP            H         3 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n 9     9 BP            H         4 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n10    10 BP            H         5 &lt;NA&gt;       &lt;NA&gt;         &lt;NA&gt;          \n# ℹ 80 more rows\n# ℹ 29 more variables: Latitude_m.x &lt;dbl&gt;, Longitude_m.x &lt;dbl&gt;,\n#   Rendement_g_5m2 &lt;dbl&gt;, TotalRamet_nombre_m2 &lt;dbl&gt;,\n#   TotalVegetatif_nombre_m2 &lt;dbl&gt;, TotalFloral_nombre_m2 &lt;dbl&gt;,\n#   TotalMale_nombre_m2 &lt;dbl&gt;, TotalFemelle_nombre_m2 &lt;dbl&gt;,\n#   FemelleFruit_nombre_m2 &lt;dbl&gt;, FemelleAvorte_nombre_m2 &lt;dbl&gt;,\n#   SterileFleur_nombre_m2 &lt;dbl&gt;, C_pourc &lt;dbl&gt;, N_pourc &lt;dbl&gt;, …\n\n\n\n\n3.5.7 Exporter un tableau\nSimplement avec write_csv().\n\nwrite_csv(chicoute_weather, \"data/chicoute_weather.csv\")\n\n\n\n3.5.8 Aller plus loin dans le tidyverse\nLe livre R for data science (2e), de Hadley Wickham et Garrett Grolemund (couverture à la Figure 3.7), est un incontournable.\n\n\n\n\n\nFigure 3.7: Couverture du libre de Hadley Wickham, Mine Çetinkaya-Rundel et Garrett Grolemund, Source: https://r4ds.hadley.nz/"
  },
  {
    "objectID": "03-tableaux.html#références",
    "href": "03-tableaux.html#références",
    "title": "3  Organisation des données et opérations sur des tableaux",
    "section": "3.6 Références",
    "text": "3.6 Références\nParent L.E., Parent, S.É., Herbert-Gentile, V., Naess, K. et Lapointe, L. 2013. Mineral Balance Plasticity of Cloudberry (Rubus chamaemorus) in Quebec-Labrador Bogs. American Journal of Plant Sciences, 4, 1508-1520. DOI: 10.4236/ajps.2013.47183"
  },
  {
    "objectID": "04-visualisation.html#pourquoi-explorer",
    "href": "04-visualisation.html#pourquoi-explorer",
    "title": "4  Visualisation",
    "section": "4.1 Pourquoi explorer graphiquement?",
    "text": "4.1 Pourquoi explorer graphiquement?\nLa plupart des graphiques que vous générerez ne seront pas destinés à être publiés. Ils viseront probablement d’abord à explorer des données. Cela vous permettra de mettre en évidence de nouvelles perspectives.\nPrenons par exemple deux variables, \\(X\\) et \\(Y\\). Vous calculez leur moyenne, écart-type et la corrélation entre les deux variables (nous verrons les statistiques plus en détail dans un prochain chapitre).\n\nlibrary(\"tidyverse\")\ndatasaurus &lt;- read_tsv(\"data/DatasaurusDozen.tsv\")\n\ncor_datasaurus &lt;- datasaurus |&gt; \n  group_by(dataset) |&gt; \n  summarise(cor = cor(x = x, y = y, method = \"pearson\"))\n\ndatasaurus |&gt; \n  group_by(dataset) |&gt; \n  summarise_all(list(mean = mean, sd = sd)) |&gt; \n  left_join(cor_datasaurus, by = \"dataset\")\n\n# A tibble: 13 × 6\n   dataset    x_mean y_mean  x_sd  y_sd     cor\n   &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;\n 1 away         54.3   47.8  16.8  26.9 -0.0641\n 2 bullseye     54.3   47.8  16.8  26.9 -0.0686\n 3 circle       54.3   47.8  16.8  26.9 -0.0683\n 4 dino         54.3   47.8  16.8  26.9 -0.0645\n 5 dots         54.3   47.8  16.8  26.9 -0.0603\n 6 h_lines      54.3   47.8  16.8  26.9 -0.0617\n 7 high_lines   54.3   47.8  16.8  26.9 -0.0685\n 8 slant_down   54.3   47.8  16.8  26.9 -0.0690\n 9 slant_up     54.3   47.8  16.8  26.9 -0.0686\n10 star         54.3   47.8  16.8  26.9 -0.0630\n11 v_lines      54.3   47.8  16.8  26.9 -0.0694\n12 wide_lines   54.3   47.8  16.8  26.9 -0.0666\n13 x_shape      54.3   47.8  16.8  26.9 -0.0656\n\n\nLes moyennes, écarts-types et corrélations sont à peu près les mêmes pour tous les groupes. Peut-on conclure que tous les groupes sont semblables? Pas encore.\nPour démontrer que ces statistiques ne vous apprendront pas grand chose sur la structure des données, Matejka et Fitzmaurice (2017) ont généré 12 jeux de données \\(X\\) et \\(Y\\), ayant chacun pratiquement les mêmes statistiques. Mais avec des structures bien différentes (Figure 4.2)!\n\n\n\n\n\nFigure 4.2: Animation montrant la progression du jeu de données Datasaurus pour toutes les formes visées. Source: Same Stats, Different Graphs: Generating Datasets with Varied Appearance and Identical Statistics through Simulated Annealing"
  },
  {
    "objectID": "04-visualisation.html#publier-un-graphique",
    "href": "04-visualisation.html#publier-un-graphique",
    "title": "4  Visualisation",
    "section": "4.2 Publier un graphique",
    "text": "4.2 Publier un graphique\nVous voilà sensibilisés à l’importance d’explorer les données graphiquement. Mais ce qui ultimement émanera d’un projet sera le rapport que vous déposerez, l’article scientifique que vous ferez publier ou le billet de blogue que vous partagerez sur les réseaux sociaux. Les graphiques inclus dans vos publications méritent une attention particulière pour que votre audience puisse comprendre les découvertes et perspectives offertes par vos travaux. Pour ce faire, un graphique doit répondre honnêtement à la question posée tout en étant attrayant.\n\n4.2.1 Cinq qualités d’un bon graphique\nAlberto Cairo, chercheur spécialisé en visualisation de données, a fait paraître en 2016 le livre The Truthful art. Il note cinq qualités d’une visualisation bien conçue (les citations de cette section proviennent de ma traduction de Alberto Cairo, The Truthful Art (2016), p. 45.).\n\n1- Elle est véritable, puisqu’elle est basée sur une recherche exhaustive et honnête.\n\nCela vaut autant pour les graphiques que pour l’analyse de données. Il s’agit froidement de présenter les données selon l’interprétation la plus exacte. Les pièges à éviter sont le picorage de cerises et la surinterprétation des données. Le picorage, c’est lorsqu’on réduit les perspectives afin de soutenir un argumentaire. Par exemple, retirer des données d’une région ou d’une décennie qui rendraient factice une conclusion fixée a priori. Ceci vaut autant pour les graphiques que pour les statistiques (nous parlerons du p-hacking au prochain chapitre). La surinterprétation, c’est lorsque l’on saute rapidement aux conclusions: par exemple, que l’on génère des corrélations, voire même des relations de causalités à partir de ce qui n’est que du bruit de fond. À ce titre, lors d’une conférence, Heather Krause insiste sur l’importance de faire en sorte que les représentations graphiques répondent correctement aux questions posées dans une étude (Figure 4.3).\n\n\n\n\n\nFigure 4.3: The F word: Protect your work from four hidden fallacies when working with data, une conférence de Heather Krause, 2018\n\n\n\n\n\n2- Elle est fonctionnelle, puisqu’elle constitue une représentation précise des données, et qu’elle est construite de manière à laisser les observateurs.trices prendre des initiatives conséquentes.\n\n“La seule chose qui est pire qu’un diagramme en pointe de tarte, c’est d’en présenter plusieurs” (Edward Tufte, designer, cité par Alberto Cairo, 2016, p. 50). Choisir le bon graphique pour représenter vos données est beaucoup moins une question de bon goût qu’une question de démarche rationnelle sur l’objectif visé par la présentation d’un graphique. Je présenterai des lignes guides pour sélectionner le type de graphique qui présentera vos données de manière fonctionnelle en fonction de l’objectif d’un graphique (d’ailleurs, avez-vous vraiment besoin d’un graphique?).\n\n3- Elle est attrayante et intrigante, et même esthétiquement plaisante pour l’audience visée - les scientifiques d’abord, mais aussi le public en général.\n\nEn sciences naturelles, la pensée rationnelle, la capacité à organiser la connaissance et créer de nouvelles avenues sont des qualités qui sont privilégiées au talent artistique. Que vous ayez où non des aptitudes en art visuel, présentez de l’information, pas des décorations. Excel vous permet d’ajouter une perspective 3D à un diagramme en barres. La profondeur contient-elle de l’information? Non. Cette décoration ne fait qu’ajouter de la confusion. Minimalisez, fournissez le plus d’information possible avec le moins d’éléments graphiques possibles. C’est ce que vous proposent les guides graphiques que j’introduirai plus loin.\n\n4- Elle est pertinente, puisqu’elle révèle des évidences scientifiques autrement difficilement accessibles.\n\nIl s’agit de susciter un eurêka, dans le sens qu’elle génère une idée, et parfois une initiative, en un coup d’œil. Le graphique en bâton de hockey est un exemple où l’on a spontanément une idée de la situation. Cette situation peut être la présence d’un phénomène comme l’augmentation de la température globale, mais aussi l’absence de phénomènes pourtant attendus.\n\n5- Elle est instructive, parce que si l’on saisit et accepte les évidences scientifiques qu’elle décrit, cela changera notre perception pour le mieux.\n\nEn présentant cette qualité, Alberto Cairo voulait inciter ses lecteurs.trices à choisir des sujets de discussion visuelle de manière à participer à un monde meilleur. En ce qui nous concerne, il s’agit de bien sélectionner l’information que l’on désire transmettre. Imaginez que vous avez travaillé quelques jours pour créer un graphique, dont vous êtes fier, mais vous (ou un collègue hiérarchiquement favorisé) vous rendez compte que le graphique soutient peu ou pas le propos ou l’objectif de votre thèse/mémoire/rapport/article. Si c’est bien le cas, vous feriez mieux de laisser tomber votre oeuvre et considérer votre démarche comme une occasion d’apprentissage.\nAlberto Cairo résume son livre The Truthful Art dans une entrevue avec le National Geographic."
  },
  {
    "objectID": "04-visualisation.html#choisir-type-graph",
    "href": "04-visualisation.html#choisir-type-graph",
    "title": "4  Visualisation",
    "section": "4.3 Choisir le type de graphique le plus approprié",
    "text": "4.3 Choisir le type de graphique le plus approprié\nDe nombreuses manières de présenter les données sont couramment utilisées, comme les nuages de points, les lignes, les histogrammes, les diagrammes en barres et en pointes de tarte. Les principaux types de graphiques seront couverts dans ce chapitre. D’autres types spécialisés seront couverts dans les chapitres appropriés (graphiques davantage orientés vers les statistiques, les biplots, les dendrogrammes, les diagrammes ternaires, les cartes, etc.).\nLa visualisation de données est aujourd’hui devenue un métier pour plusieurs personnes ayant des affinités pour la science, les arts et la communication, dont certaines partagent leur expertise sur le web. À ce titre, le site from data to viz est à conserver dans vos marque-pages. Il comprend des arbres décisionnels qui vous guident vers les options appropriées pour présenter vos données, puis fournissent des exemples pour produire ces visualisations en R. Également, je suggère le site internet de Ann K. Emery, qui présente des lignes guide pour présenter le graphique adéquat selon les données en main. De nombreuses recettes sont également proposées sur r-graph-gallery.com. En ce qui a trait aux couleurs, le choix n’est pas anodin. Si vous avez le souci des détails sur les éléments esthétiques de vos graphiques, je recommande la lecture de ce billet de blog de Lisa Charlotte Rost.\nRetenez néanmois que La couleur est une information. Les couleurs devraient être sélectionnées d’abord pour être lisibles par les personnes ne percevant pas les couleurs (Figure 4.4), selon le support (apte à être photocopié, lisible à l’écran, lisible sur des documents imprimés en noir et blanc) et selon le type de données. Vous pouvez aussi utiliser certains modules comme RColorBrewer comme expliqué dans le billet suivant qui permet d’adopter directement les palettes sélectionnées.\n\nDonnées continues ou catégorielles ordinales: gradient (transition graduelle d’une couleur à l’autre), séquence (transition saccadée selon des groupes de données continues) ou divergentes (transition saccadée d’une couleur à l’autre vers des couleurs divergentes, par exemple orange vers blanc vers bleu).\nDonnées catégorielles nominales: couleurs éloignées d’une catégorie à une autre (plus il y a de catégories, plus les couleurs sont susceptibles de se ressembler).\n\n\n\n\n\n\nFigure 4.4: Capture d’écran de colorbrewer2.org, qui propose des palettes de couleurs pour créer des cartes, mais l’information est pertinente pour tout type de graphique.\n\n\n\n\nLe Financial Times offre également ce guide visuel (Figure 4.5).\n\n\n\n\n\nFigure 4.5: Guide de sélection de graphique du Financial Times\n\n\n\n\nCairo (2016) propose de procéder en suivant ces étapes:\n\nRéfléchissez au message que vous désirez transmettre: comparer les catégories \\(A\\) et \\(B\\), visualiser une transition ou un changement de \\(A\\) vers \\(B\\), présenter une relation entre \\(A\\) et \\(B\\) ou la distribution de \\(A\\) et \\(B\\) sur une carte.\nEssayez différentes représentations: si le message que vous désirez transmettre a plusieurs volets, il se pourrait que vous ayez besoin de plus d’un graphique.\nMettez de l’ordre dans vos données. C’était le sujet du chapitre 3.\nTestez le résultat. “Hé, qu’est-ce que tu comprends de cela?” Si la personne hausse les épaules, il va falloir réévaluer votre stratégie."
  },
  {
    "objectID": "04-visualisation.html#choisir-son-outil-de-visualisation",
    "href": "04-visualisation.html#choisir-son-outil-de-visualisation",
    "title": "4  Visualisation",
    "section": "4.4 Choisir son outil de visualisation",
    "text": "4.4 Choisir son outil de visualisation\nLes modules et logiciels de visualisation sont basés sur des approches que l’on pourrait placer sur un spectre allant de l’impératif au déclaratif.\n\n4.4.1 Approche impérative\nSelon cette approche, vous indiquez comment placer l’information dans un espace graphique. Vous indiquer les symboles, les couleurs, les types de ligne, etc. Peu de choses sont automatisées, ce qui laisse une grande flexibilité, mais demande de vouer beaucoup d’énergie à la manière de coder pour obtenir le graphique désiré. Le module graphique de Excel, ainsi que le module graphique de base de R, utilisent des approches impératives.\n\n\n4.4.2 Approche déclarative\nLes stratégies d’automatisation graphique se sont grandement améliorées au cours des dernières années. Plutôt que de vouer vos énergies à créer un graphique, il est maintenant possible de spécifier ce que l’on veut présenter.\n\nLa visualisation déclarative vous permet de penser aux données et à leurs relations, plutôt que des détails accessoires.\nJake Vanderplas, Declarative Statistical Visualization in Python with Altair (ma traduction)\n\nL’approche déclarative passe souvent par une grammaire graphique, c’est-à-dire un langage qui explique ce que l’on veut présenter - en mode impératif, on spécifie plutôt comment on veut présenter les données. Le module ggplot2 est le module déclaratif par excellence en R."
  },
  {
    "objectID": "04-visualisation.html#visualisation-en-r",
    "href": "04-visualisation.html#visualisation-en-r",
    "title": "4  Visualisation",
    "section": "4.5 Visualisation en R",
    "text": "4.5 Visualisation en R\nEn R, votre trousse d’outils de visualisation mériterait de comprendre les modules suivants.\n\nbase. Le module de base de R contient des fonctions graphiques très polyvalentes. Les axes sont générés automatiquement, on peut y ajouter des titres et des légendes, on peut créer plusieurs graphiques sur une même figure, on peut y ajouter différentes géométries (points, lignes et polygones), avec différents types de points ou de traits, différentes couleurs, etc. Les modules spécialisés viennent souvent avec leurs graphiques spécialisés, construits à partir du module de base. En tant que module graphique impératif, on peut tout faire ou presque (pas d’interactivité), mais l’écriture du code est peut expressive.\nggplot2. C’est le module graphique par excellence en R (et j’ose dire: en calcul scientifique). ggplot2 se base sur une grammaire graphique. À partir d’un tableau de données, une colonne peut définir l’axe des x, une autre l’axe des y, une autre la couleur des points ou leur dimension. Une autre colonne définissant des catégories peut segmenter la visualisation en plusieurs graphiques alignés horizontalement ou verticalement. Des extensions de ggplot2 permettent de générer des cartes (ggmap), des diagrammes ternaires (ggtern), des animations (gganimate), etc.\nplotly. plotly est un module graphique particulièrement utile pour générer des graphiques interactifs. plotly offre une fonction toute simple pour rendre interactif un graphique ggplot2.\n\nNous survolerons rapidement le module de base, irons plus en profondeur avec ggplot2, puis je présenterai brièvement les graphiques interactifs avec plotly."
  },
  {
    "objectID": "04-visualisation.html#module-de-base-pour-les-graphiques",
    "href": "04-visualisation.html#module-de-base-pour-les-graphiques",
    "title": "4  Visualisation",
    "section": "4.6 Module de base pour les graphiques",
    "text": "4.6 Module de base pour les graphiques\nNous allons d’abord survoler le module de base, en mode impératif. La fonction de base pour les graphiques en R est plot(). Pour nous exercer avec cette fonction, chargeons d’abord le tableau de données d’exercice iris, publié en 1936 par le célèbre biostatisticien Ronald Fisher.\n\ndata(\"iris\")\nhead(iris)\n\n  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n1          5.1         3.5          1.4         0.2  setosa\n2          4.9         3.0          1.4         0.2  setosa\n3          4.7         3.2          1.3         0.2  setosa\n4          4.6         3.1          1.5         0.2  setosa\n5          5.0         3.6          1.4         0.2  setosa\n6          5.4         3.9          1.7         0.4  setosa\n\n\nLe tableau iris contient 5 colonnes, les 4 premières décrivant les longueurs et largeurs des pétales et sépales de différentes espèces d’iris dont le nom apparaît à la 5ième colonne. Vous avez déjà vu au chapitre précédent comment extraire les colonnes d’un tableau; une méthode consiste à appeler le tableau, suivi du $, puis du nom de la colonne, par exemple iris$Species. Pour générer un graphique avec la fonction plot():\n\nplot(iris$Sepal.Length, iris$Petal.Length)\n\n\n\n\nPar défaut, le premier argument est le vecteur définissant l’axe des x et le deuxième est celui définissant l’axe des y. Vous rencontrerez souvent de telles utilisations d’arguments implicites, mais je préfère être explicite en définissant bien les arguments: plot(x = iris$Sepal.Length, y = iris$Petal.Length). Le graphique précédent peut être amplement personnalisé en utilisant différents arguments (Figure 4.6).\n\n\n\n\n\nFigure 4.6: Éléments personnalisables d’un graphique de base\n\n\n\n\nExercice. Utilisez ces arguments dans la cellule de code de la figure plot(iris$Sepal.Length, iris$Petal.Length).\nRemarquez que la fonction a décidé toute seule de créer un nuage de point. La fonction plot() est conçue pour créer le graphique approprié selon le type des données spécifiées: lignes, boxplot, etc. Si l’on spécifiait les espèces comme argument x:\n\nplot(x = iris$Species, y = iris$Petal.Length)\n\n\n\n# ou bien\n# iris |&gt; \n#   select(Species, Petal.Length) |&gt; \n#   plot()\n\nDe même, la fonction plot() appliquée à un tableau de données générera une représentation bivariée.\n\nplot(iris)\n\n\n\n\nIl est possible d’encoder des attributs grâce à des vecteurs de facteurs (catégories).\n\nplot(iris, col = iris$Species)\n\n\n\n\nL’argument type = \"\" permet de personnaliser l’apparence:\n\ntype = \"p\": points\ntype = \"l\": ligne\ntype = \"o\" et type = \"b\": ligne et points\ntype = \"n\": ne rien afficher\n\nCréons un jeu de données.\n\ntime &lt;- seq(from = 0, to = 100, by = 10)\nheight &lt;- abs(time * 0.1 + rnorm(length(time), 0, 2)) \n# abs pour valeur absolue (changement de signe si négatif)\nplot(x = time, y = height, type = \"b\", lty = 2, lwd = 1)\n\n\n\n\nLe type de ligne est spécifié par l’argument lty (qui peut prendre un chiffre ou une chaîne de caractères, i.e. 1 est équivalent de \"solid\", 2 de \"dashed\", 3 de \"dotted\", etc.) et la largeur du trait (valeur numérique), par l’argument lwd.\nLa fonction hist() permet quant à elle de créer des histogrammes. Parmi ses arguments, breaks est particulièrement utile, car il permet d’ajuster la segmentation des incréments.\n\nhist(iris$Petal.Length, breaks = 60)\n\n\n\n\nExercice. Ajustez le titre de l’axe des x, ainsi que les limites de l’axe des x. Êtes-vous en mesure de colorer l’intérieur des barres en bleu?\nLa fonction plot() peut être suivie de plusieurs autres couches comme des lignes (lines() ou abline()), des points (points()), du texte (text()), des polygones (polygon(), des légendes (legend())), etc. On peut aussi personnaliser les couleurs, les types de points, les types de lignes, etc. L’exemple suivant ajoute une ligne au graphique. Ne prêtez pas trop attention aux fonctions predict() et lm() pour l’instant: nous les verrons au chapitre 7.\n\nplot(x = time, y = height)\nlines(x = time, y = predict(lm(height ~ time)))\n\n\n\n\nPour exporter un graphique, vous pouvez passer par le menu Export de RStudio. Mais pour des graphiques destinés à être publiés, je vous suggère d’exporter vos graphiques avec une haute résolution à la suite de la commande png() (ou jpg() ou svg()).\n\nsvg(filename = \"images/mon-graphique.svg\", width = 3000, height = 2000)\n# png(filename = 'images/mon-graphique.png', width = 3000, height=2000, res=300)\nplot(\n  x = iris$Petal.Length,\n  y = iris$Sepal.Length,\n  col = iris$Species,\n  cex = 3, # dimension des points\n  pch = 16 # type de points\n)\ndev.off()\n\npng \n  2 \n\n\nLe format svg crée une version vectorielle du graphique, c’est-à-dire que l’image exportée est un fichier contenant les formes, non pas les pixels. Cela vous permet d’éditer votre graphique dans un logiciel de dessin vectoriel (comme Inkscape).\nDans le bloc de code précédent, j’ai mis en commentaire (# ...) le format d’image png, utile pour les images de type graphique, avec des changements de couleurs drastiques. J’y ai spécifié une haute résolution, à 300 pixels par pouce. Pour les photos, vous préférerez le format jpg. Des éditeurs demanderont peut-être des formats vectoriels comme pdf ou eps. Si vous ne trouvez pas de moyen de modifier un aspect du graphique dans le code (bouger des étiquettes ou des légendes, ajouter des éléments graphiques), vous pouvez exporter votre graphique en format svg et éditer votre graphique dans Inkscape.\nLe module de base de R comprend une panoplie d’autres particularités que je ne couvrirai pas ici, en faveur du module ggplot2."
  },
  {
    "objectID": "04-visualisation.html#la-grammaire-graphique-ggplot2",
    "href": "04-visualisation.html#la-grammaire-graphique-ggplot2",
    "title": "4  Visualisation",
    "section": "4.7 La grammaire graphique ggplot2",
    "text": "4.7 La grammaire graphique ggplot2\nLe module esquisse est une extension de RStudio permettant de générer du code pour le module graphique ggplot2. La vidéo suivant, où j’utilise esquisse, montre ce en quoi consiste une grammaire graphique.\nVideo\nChaque colonne est un élément graphique qui peut être encodé pour former la position en x, en y, la taille des points, leur couleur, ou même le panneau (facet). Mais quelle forme prendra le bidule positionné? Des points, lignes, boxplots, barres? C’est ce que définit une grammaire graphique. Brièvement, une grammaire graphique permet de schématiser des données avec des marqueurs (points, lignes, etc.) sur des attributs visuels (couleurs, dimension, forme). Cette approche permet de dégager 5 composantes.\n\nLes données. Votre tableau est bien sûr un argument nécessaire pour générer le graphique.\nLes marqueurs. Un terme abstrait pour désigner les points, les lignes, les polygones, les barres, les flèches, etc. En ggplot2, ce sont des géométries, par exemple geom_point() pour définir une géométrie de points.\nLes attributs encodés. La position, la dimension, la couleur ou la forme que prendront les géométries. En ggplot2, on les nomme les aesthetics.\nLes attributs globaux. Les attributs sont globaux lorsqu’ils sont constants (ils ne dépendent pas d’une variable). Les valeurs par défaut conviennent généralement, mais certains attributs peuvent être spécifiés: par exemple la forme ou la couleur des points, le type de ligne, etc.\nLes thèmes. Le thème du graphique permet de personnaliser la manière dont le graphique est rendu. Il existe des thèmes prédéfinis, que vous pouvez ajuster, mais il est possible de créer vos propres thèmes (nous ne couvrirons pas cela dans ce cours).\n\n\n\n\n\n\nFigure 4.7: Créer une oeuvre d’art avec ggplot2, dessin de @allison_horst.\n\n\n\n\nLe flux de travail pour créer un graphique à partir d’une grammaire ressemble donc à ceci:\nAvec mon tableau,\nCréer un marqueur (\nencoder(position X = colonne A,\nposition Y = colonne B,\ncouleur = colonne C),\nforme globale = 1)\nAvec un thème noir et blanc\nLe module tidyverse installera des modules utilisés de manière récurrente dans ce cours, comme ggplot2, dplyr, tidyr et readr. Je recommande de le charger au début de vos sessions de travail.\n\nlibrary(\"tidyverse\")\n\nL’approche tidyverse est une grammaire des données. Le module ggplot2, qui en fait partie, est une grammaire graphique (d’où le gg de ggplot)."
  },
  {
    "objectID": "04-visualisation.html#mon-premier-ggplot",
    "href": "04-visualisation.html#mon-premier-ggplot",
    "title": "4  Visualisation",
    "section": "4.8 Mon premier ggplot",
    "text": "4.8 Mon premier ggplot\nPour notre premier exercice, je vais charger un tableau depuis le fichier de données abalone.data. Pour plus de détails sur les tableaux de données, consultez le chapitre 3. Le fichier de données porte sur un escargot de mer et comprend le sexe (M: mâle, F: femelle et I: enfant), des poids et dimensions des individus observés, et le nombre d’anneaux comptés dans la coquille.\n\nabalone &lt;- read_csv(\"data/abalone.csv\")\n\nRows: 4177 Columns: 9\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (1): Type\ndbl (8): LongestShell, Diameter, Height, WholeWeight, ShuckedWeight, Viscera...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nInspectons l’entête du tableau avec la fonction head().\n\nhead(abalone)\n\n# A tibble: 6 × 9\n  Type  LongestShell Diameter Height WholeWeight ShuckedWeight VisceraWeight\n  &lt;chr&gt;        &lt;dbl&gt;    &lt;dbl&gt;  &lt;dbl&gt;       &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;\n1 M            0.455    0.365  0.095       0.514        0.224         0.101 \n2 M            0.35     0.265  0.09        0.226        0.0995        0.0485\n3 F            0.53     0.42   0.135       0.677        0.256         0.142 \n4 M            0.44     0.365  0.125       0.516        0.216         0.114 \n5 I            0.33     0.255  0.08        0.205        0.0895        0.0395\n6 I            0.425    0.3    0.095       0.352        0.141         0.0775\n# ℹ 2 more variables: ShellWeight &lt;dbl&gt;, Rings &lt;dbl&gt;\n\n\nSuivant la grammaire graphique ggplot2, on pourra créer ce graphique de points comprenant les attributs suivants.\n\ndata = abalone, le fichier de données.\nmapping = aes(...), spécifié comme attribut de la fonction ggplot(), cet encodage (ou aesthetic) reste l’encodage par défaut pour tous les marqueurs du graphique. Toutefois, l’encodage mapping = aes() peut aussi être spécifié dans la fonction du marqueur (par exemple geom_point()). Dans l’encodage global du graphique, on place en x la longueur de la coquille (x = LongestShell) et on place en y le poids de la coquille (y = ShellWeight).\nPour ajouter une fonction à ggplot, comme une nouvelle couche de marqueur ou des éléments de thème, on utilise le +. Généralement, on change aussi de ligne.\nLe marqueur ajouté est un point, geom_point(), dans lequel on spécifie un encodage de couleur sur la variable Type (colour = Type) et un encodage de dimension du point sur la variable rings (size = Rings). L’attribut alpha = 0.5 se situe hors du mapping et de la fonction aes(): c’est un attribut identique pour tous les points.\n\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  geom_point(mapping = aes(colour = Type, size = Rings), alpha = 0.5)\n\n\n\n\nIl existe plusieurs types de marqueurs:\n\ngeom_point() pour les points\ngeom_line() pour les lignes\ngeom_bar() pour les diagrammes en barre en décompte, geom_col en terme de grandeur et geom_histogram pour les histogrammes\ngeom_boxplot() pour les boxplots\ngeom_errorbar(), geom_pointrange() ou geom_crossbar() pour les marges d’erreur\ngeom_map() pour les cartes\netc.\n\nIl existe plusieurs attributs d’encodage:\n\nla position x, y et z (z pertinent notamment pour le marqueur geom_tile())\nla taille size\nla forme des points shape\nla couleur, qui peut être discrète ou continue :\n\ncolour, pour la couleur des contours\nfill, pour la couleur de remplissage\n\nle type de ligne linetype\nla transparence alpha\net d’autres types spécialisés que vous retrouverez dans la documentation des marqueurs\n\nLes types de marqueurs et leurs encodages sont décrits dans la documentation de ggplot2, qui fournit des feuilles aide-mémoire qu’il est commode d’imprimer et d’afficher près de soi (Figure 4.8).\n\n\n\n\n\nFigure 4.8: Aide-mémoire de ggplot2, source: https://rstudio.github.io/cheatsheets/html/data-visualization.html\n\n\n\n\n\n4.8.0.1 Les facettes\nDans ggplot2, les facetttes sont un type spécial d’encodage utilisé pour définir des grilles de graphiques. Elles prennent deux formes:\n\nLe collage, facet_wrap(). Une variable catégorielle est utilisée pour segmenter les graphiques en plusieurs graphiques, qui sont placés l’un à la suite de l’autre dans un arrangement spécifié par un nombre de colonnes ou un nombre de lignes.\nLa grille, facet_grid(). Une ou deux variables segmentent les graphiques selon les colonnes et les lignes.\n\nLes facettes peuvent être spécifiées n’importe où dans la chaîne de commande de ggplot2 mais, conventionnellement, on les place tout de suite après la fonction ggplot().\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  facet_wrap(~Type, ncol = 2) +\n  geom_point(mapping = aes(colour = Type, size = Rings), alpha = 0.5)\n\n\n\n\nLa fonction cut() permet de discrétiser des variables continues en catégories ordonnées - les fonctions peuvent être utilisées à l’intérieur de la fonction ggplot.\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  facet_grid(Type ~ cut(Rings, breaks = seq(0, 30, 5))) +\n  geom_point(mapping = aes(colour = Type), alpha = 0.5)\n\n\n\n\nPar défaut, les axes des facettes, ainsi que leurs dimensions, sont les mêmes. Une telle représentation permet de comparer les facets sur une même échelle. Les axes peuvent être définis selon les données avec l’argument scales, tandis que l’espace des facettes peut être conditionné selon l’argument space - pour plus de détails, voir la fiche de documentation.\nExercice. Personnalisez le graphique avec les données abalone en remplaçant les variables et en réorganisant les facettes.\n\n\n4.8.1 Plusieurs sources de données\nIl peut arriver que les données pour générer un graphique proviennent de plusieurs tableaux. Lorsqu’on ne spécifie pas la source du tableau dans un marqueur, la valeur par défaut est le tableau spécifié dans l’amorce ggplot(). Il est néanmoins possible de définir une source personnalisée pour chaque marqueur en spécifiant data = ... comme argument du marqueur.\n\nabalone_siteA &lt;- data.frame(\n  LongestShell = c(0.3, 0.8, 0.7),\n  ShellWeight = c(0.05, 0.81, 0.77)\n)\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  geom_point(mapping = aes(colour = Type, size = Rings), alpha = 0.5) +\n  geom_point(data = abalone_siteA, size = 8, shape = 4)\n\n\n\n\n\n\n4.8.2 Exporter avec style\nLe fond gris est une marque distinctive de ggplot2. Il n’est toutefois pas apprécié de tout le monde. D’autres thèmes dits complets peuvent être utilisés (liste des thèmes complets). Les thèmes complets sont appelés avant la fonction theme(), qui permet d’effectuer des ajustements précis dont la liste exhaustive se trouve dans la documentation de ggplot2.\nVous pouvez aussi personnaliser le titre des axes (xlab() et ylab()) ou du graphique (ggtitle()), ou bien tout spécifier dans une même fonction ou bien tout en même temps dans labs(x = \"...\", y = \"...\", title = \"...\"). Il est possible d’utiliser des exposants dans le titre des axes avec la fonction expression(), par exemple labs(x = expression(\"Dose (kg ha\"^\"-1\"~\")\")) pour intituler l’axe des x avec \\(Dose~(kg~ha^{-1})\\). Aussi convient parfois de spécifier les limites (xlim() et ylim(), ou expand_limits(x = c(0, 1), y = c(0, 1))).\nPour exporter un ggplot, on pourra utiliser les commandes de R png(), svg() ou pdf(), ou les outils de RStudio. Toutefois, ggplot2 offre la fonction ggsave(), que l’on place en remorque du graphique, en spécifiant les dimensions (width et height) ainsi que la résolution (dpi). La résolution d’un graphique destiné à la publication est typiquement de plus de 300 dpi.\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  geom_point(mapping = aes(colour = Type, size = Rings), alpha = 0.5) +\n  #xlab(\"Length (mm)\") +\n  #ylab(\"Shell weight (g)\") +\n  #ggtitle(\"Abalone\") + # préférablement dans une même ligne\n  labs(x = \"Length (mm)\", y = \"Shell weight (g)\", title = \"Abalone\") +\n  xlim(c(0, 1)) +\n  theme_classic() +\n  theme(\n    axis.title = element_text(size = 20),\n    axis.text = element_text(size = 20),\n    axis.text.y = element_text(size = 20, angle = 90, hjust = 0.5),\n    legend.box = \"horizontal\"\n  )\n\n\n\nggsave(\"images/abalone.png\", width = 8, height = 8, dpi = 300)\n\nNous allons maintenant couvrir différents types de graphiques, accessibles selon différents marqueurs:\n\nles nuages de points\nles diagrammes en ligne\nles boxplots\nles histogrammes\nles diagrammes en barres\n\n\n\n4.8.3 Nuages de points\nL’exemple précédent est un nuage de points, que nous avons généré avec le marqueur geom_point(), qui a déjà été passablement introduit. L’exploration de ces données a permis de détecter une croissance exponentielle du poids de la coquille en fonction de sa longueur. Il est clair que les abalones juvéniles (Type I) sont plus petits et moins lourds, mais nous devrons probablement procéder à des tests statistiques pour vérifier s’il y a des différences entre mâles et femelles.\nLe graphique étant très chargé, nous avons utilisé des stratégies pour l’alléger en utilisant de la transparence et des facettes. Le marqueur geom_jitter() peut permettre de mieux apprécier la dispersion des points en ajoutant une dispersion randomisée en x ou en y.\n\nggplot(data = abalone, mapping = aes(x = LongestShell, y = ShellWeight)) +\n  geom_jitter(mapping = aes(colour = Type, size = Rings), alpha = 0.5, width = 0.05, height = 0.1)\n\n\n\n\nDans ce cas-ci, ça ne change pas beaucoup, mais retenons-le pour la suite.\n\n\n4.8.4 Diagrammes en lignes\nLes lignes sont utilisées pour exprimer des liens entre une suite d’information. Dans la plupart des cas, il s’agit d’une suite d’information dans le temps que l’on appelle les séries temporelles (plus sur ce sujet au chapitre 13. En l’occurrence, les lignes devraient être évitées si la séquence entre les variables n’est pas évidente. Nous allons utiliser un tableau de données de R portant sur la croissance des orangers.\n\ndata(\"Orange\")\nhead(Orange)\n\n  Tree  age circumference\n1    1  118            30\n2    1  484            58\n3    1  664            87\n4    1 1004           115\n5    1 1231           120\n6    1 1372           142\n\n\nLa première colonne spécifie le numéro de l’arbre mesuré, la deuxième son âge et la troisième sa circonférence. Le marqueur geom_line() permet de tracer la tendance de la circonférence selon l’âge. En encodant la couleur de la ligne à l’arbre, nous pourrons tracer une ligne pour chacun d’entre eux.\n\nggplot(data = Orange, mapping = aes(x = age, y = circumference)) +\n  geom_line(aes(colour = Tree))\n\n\n\n\nLa légende ne montre pas les numéros d’arbre en ordre croissant. En effet, la légende (tout comme les facettes) classe les catégories prioritairement selon l’ordre des catégories si elles sont ordinales, ou par ordre alphabétique si les catégories sont nominales. Inspectons la colonne Tree en inspectant le tableau avec la commande str() - la commande glimpse() du tidyverse donne un sommaire moins complet que str().\n\nstr(Orange)\n\nClasses 'nfnGroupedData', 'nfGroupedData', 'groupedData' and 'data.frame':  35 obs. of  3 variables:\n $ Tree         : Ord.factor w/ 5 levels \"3\"&lt;\"1\"&lt;\"5\"&lt;\"2\"&lt;..: 2 2 2 2 2 2 2 4 4 4 ...\n $ age          : num  118 484 664 1004 1231 ...\n $ circumference: num  30 58 87 115 120 142 145 33 69 111 ...\n - attr(*, \"formula\")=Class 'formula'  language circumference ~ age | Tree\n  .. ..- attr(*, \".Environment\")=&lt;environment: R_EmptyEnv&gt; \n - attr(*, \"labels\")=List of 2\n  ..$ x: chr \"Time since December 31, 1968\"\n  ..$ y: chr \"Trunk circumference\"\n - attr(*, \"units\")=List of 2\n  ..$ x: chr \"(days)\"\n  ..$ y: chr \"(mm)\"\n\n\nEn effet, la colonne Tree est un facteur ordinal dont les niveaux sont dans le même ordre que celui la légende.\n\n\n4.8.5 Les histogrammes\nNous avons vu les histogrammes dans la brève section sur les fonctions graphiques de base dans R: il s’agit de segmenter l’axe des x en incréments, puis de présenter sur l’axe de y le nombre de données que l’on retrouve dans cet incrément. Le marqueur à utiliser est geom_histogram().\nRevenons à nos escargots. Comment présenteriez-vous la longueur de la coquille selon la variable Type? Selon des couleurs ou des facettes? La couleur, dans le cas des histogrammes, est celle du pourtour des barres. Pour colorer l’intérieur des barres, l’argument à utiliser est fill.\n\nggplot(data = abalone, mapping = aes(x = LongestShell)) +\n  geom_histogram(mapping = aes(fill = Type), colour = \"black\")\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nOn n’y voit pas grand chose. Essayons plutôt les facettes.\n\nggplot(data = abalone, mapping = aes(x = LongestShell)) +\n  facet_grid(Type ~ .) +\n  geom_histogram()\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\nLes facettes permettent maintenant de bien distinguer la distribution des longueurs des juvéniles. L’argument bins, tout comme l’argument breaks du module graphique de base, permet de spécifier le nombre d’incréments, ce qui peut être très utile en exploration de données.\n\nggplot(data = abalone, mapping = aes(x = LongestShell)) +\n  facet_grid(Type ~ .) +\n  geom_histogram(bins = 60, colour = \"white\")\n\n\n\n\nLe nombre d’incréments est un paramètre qu’il ne faut pas sous-estimer. À preuve, ce tweet de @NicholasStrayer:\n\n\nHistograms are fantastic, but make sure your bin-width/number is chosen well. This is the exact same data, plotted with different bin-widths. Notice that the pattern doesn't necessarily get clearer as bin num increases. #dataviz pic.twitter.com/3MhSFwTVPH\n\n— Nick Strayer (@NicholasStrayer) 7 août 2018\n\n\n\n\n4.8.6 Boxplots\nLes boxplots sont une autre manière de visualiser des distributions. L’astuce est de créer une boîte qui s’étend du premier quartile (valeur à laquelle 25% des données ont une valeur inférieure) au troisième quartile (valeur à laquelle 75% des données ont une valeur inférieure). Une barre à l’intérieur de cette boîte est placée à la médiane (qui est en fait le second quartile). De part et d’autre de la boîte, on retrouve des lignes spécifiant l’étendue hors quartiles. Cette étendue peut être déterminée de plusieurs manières, mais dans le cas de ggplot2, il s’agit de 1.5 fois l’étendue de la boîte (l’écart interquartile). Au-delà de ces lignes, on retrouve les points représentant les valeurs extrêmes. Le marqueur à utiliser est geom_boxplot(). L’encodage x est la variable catégorielle et l’encodage y est la variable continue.\n\nggplot(data = abalone, mapping = aes(x = Type, y = LongestShell)) +\n  geom_boxplot()\n\n\n\n\nExercice. On suggère parfois de présenter les mesures sur les boxplots. Utiliser geom_jitter() avec un bruit horizontal.\n\n\n4.8.7 Les diagrammes en barre\nLes diagrammes en barre représentent une variable continue associée à une catégorie. Les barres sont généralement horizontales et ordonnées. Nous y reviendrons à la fin de ce chapitre, mais retenez pour l’instant que dans tous les cas, les diagrammes en barre doivent inclure le zéro pour éviter les mauvaises interprétations.\nPour les diagrammes en barre, nous allons utiliser les données de l’union internationale pour la conservation de la nature distribuées par l’OCDE.\n\n# Certaines  colonnes de caractères sont considérées comme booléennes\n# mieux vaut définir leur type pour s'assurer que le bon type\n# soit attribué\nespeces_menacees &lt;- read_csv(\"data/WILD_LIFE_14012020030114795.csv\",\n  col_types = list(\n    \"c\", \"c\", \"c\", \"c\",\n    \"c\", \"c\", \"c\", \"c\",\n    \"d\", \"c\", \"c\", \"c\",\n    \"d\", \"c\", \"c\"\n  )\n)\nhead(especes_menacees)\n\n# A tibble: 6 × 15\n  IUCN       `IUCN Category`       SPEC  Species COU   Country `Unit Code` Unit \n  &lt;chr&gt;      &lt;chr&gt;                 &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt;       &lt;chr&gt;\n1 TOT_KNOWN  Total number of know… MAMM… Mammals AUS   Austra… NBR         Numb…\n2 ENDANGERED Number of endangered… MAMM… Mammals AUS   Austra… NBR         Numb…\n3 CRITICAL   Number of critically… MAMM… Mammals AUS   Austra… NBR         Numb…\n4 VULNERABLE Number of vulnerable… MAMM… Mammals AUS   Austra… NBR         Numb…\n5 THREATENED Total number of thre… MAMM… Mammals AUS   Austra… NBR         Numb…\n6 TOT_KNOWN  Total number of know… MAMM… Mammals AUT   Austria NBR         Numb…\n# ℹ 7 more variables: `PowerCode Code` &lt;dbl&gt;, PowerCode &lt;chr&gt;,\n#   `Reference Period Code` &lt;chr&gt;, `Reference Period` &lt;chr&gt;, Value &lt;dbl&gt;,\n#   `Flag Codes` &lt;chr&gt;, Flags &lt;chr&gt;\n\n\nL’exercice consiste à créer un diagramme en barres horizontales du nombre de plantes vasculaires menacées de manière critique pour les 10 pays qui en contiennent le plus. Je vais effectuer quelques opérations sur ce tableau afin d’en arriver avec un tableau que nous pourrons convenablement mettre en graphique: si vous avez bien suivi le dernier chapitre, ces opérations devraient vous être familières!\nNous allons filtrer le tableau pour obtenir le nombre de plantes vasculaires critiquement menacées, sélectionner seulement le pays et le nombre d’espèces, les grouper par pays, additionner toutes les espèces pour chaque pays et enfin sélectionner et arranger les 10 premiers en ordre décroissant. Comme vous le voyez, la création de graphique est liée de près avec la manipulation des tableaux!\n\nespeces_crit &lt;- especes_menacees |&gt; \n  filter(IUCN == \"CRITICAL\", SPEC == \"VASCULAR_PLANT\") |&gt; \n  dplyr::select(Country, Value) |&gt; \n  group_by(Country) |&gt; \n  summarise(n_critical_species = sum(Value)) |&gt; \n  slice_max(n = 10, order_by = n_critical_species)\nespeces_crit\n\n# A tibble: 10 × 2\n   Country         n_critical_species\n   &lt;chr&gt;                        &lt;dbl&gt;\n 1 United States                 1222\n 2 Japan                          525\n 3 Canada                         315\n 4 Czech Republic                 284\n 5 Spain                          271\n 6 Belgium                        253\n 7 Austria                        172\n 8 Slovak Republic                155\n 9 Australia                      148\n10 Italy                          128\n\n\nLe premier type de diagramme en barre que nous allons couvrir est obtenu par le marqueur geom_col().\n\nggplot(data = especes_crit, mapping = aes(x = Country, y = n_critical_species)) +\n  geom_col()\n\n\n\n\nCe graphique est perfectible. Les barres sont verticales et non ordonnées. Souvenons-nous que ggplot2 ordonne par ordre alphabétique si aucun autre ordre est spécifié. Nous pouvons changer l’ordre en changeant l’ordre des niveaux de la variable Country selon le nombre d’espèces grâce à la fonction fct_reorder.\n\nespeces_crit &lt;- especes_crit %&gt;%\n  mutate(Country = fct_reorder(Country, n_critical_species))\n\nPour faire pivoter le graphique, nous ajoutons coord_flip() à la séquence.\n\nggplot(data = especes_crit, mapping = aes(x = Country, y = n_critical_species)) +\n  geom_col() +\n  coord_flip()\n\n\n\n\nUne autre méthode, geom_bar(), est un raccourci permettant de compter le nombre d’occurrence d’une variable unique. Par exemple, dans le tableau abalone, le nombre de fois que chaque niveau de la variable Type.\n\nggplot(data = abalone, mapping = aes(x = Type)) +\n  geom_bar() +\n  coord_flip()\n\n\n\n\nPersonnellement, j’aime bien passer par un diagramme en lignes avec le marqueur geom_segment(). Cela me donne la flexibilité pour définir un largeur de trait et éventuellement d’ajouter un point au bout pour en faire un diagramme en suçon. Tenez, j’en profite aussi pour y ajouter du texte (décalé horizontalement) et étendre les limtes pour m’assurer que les chiffres apparaissent bien.\n\nggplot(data = especes_crit, mapping = aes(x = Country, y = n_critical_species)) +\n  geom_segment(mapping = aes(xend = Country, yend = 0), lwd = 2) +\n  geom_point(size = 5, colour = \"black\") +\n  geom_text(aes(label = n_critical_species), hjust = -0.5) + # si ce ne sont pas des valeurs entières, arrondir avec signif()\n  expand_limits(y = c(0, 1300)) +\n  coord_flip() +\n  theme_bw()\n\n\n\n\nLes diagrammes en barre peuvent être placés en relation avec d’autres. Reprenons notre manipulation de données précédente, mais en incluant tous les pays, pour les trois niveaux d’alerte, pour les poissons.\n\nespeces_pays_iucn &lt;- especes_menacees |&gt; \n  filter(IUCN %in% c(\"ENDANGERED\", \"VULNERABLE\", \"CRITICAL\"), SPEC == \"FISH_TOT\") |&gt; \n  dplyr::select(IUCN, Country, Value) |&gt; \n  group_by(Country, IUCN) |&gt; \n  summarise(n_species = sum(Value)) |&gt; \n  group_by(Country) |&gt; \n  mutate(n_tot = sum(n_species)) |&gt; \n  ungroup() |&gt;  # pour pouvoir modifier Country, non modifiable tant qu'elle est une variable de regroupement (voir group_by)\n  mutate(Country = fct_reorder(Country, n_tot))\n\n`summarise()` has grouped output by 'Country'. You can override using the\n`.groups` argument.\n\nhead(especes_pays_iucn)\n\n# A tibble: 6 × 4\n  Country   IUCN       n_species n_tot\n  &lt;fct&gt;     &lt;chr&gt;          &lt;dbl&gt; &lt;dbl&gt;\n1 Australia CRITICAL           8    48\n2 Australia ENDANGERED        16    48\n3 Australia VULNERABLE        24    48\n4 Austria   CRITICAL           6    39\n5 Austria   ENDANGERED        18    39\n6 Austria   VULNERABLE        15    39\n\n\nPour placer les barres les unes à côté des autres, nous spécifions position = \"dodge\".\n\nggplot(data = especes_pays_iucn, mapping = aes(x = Country, y = n_species)) +\n  geom_col(aes(fill = IUCN), position = \"dodge\") +\n  coord_flip()\n\n\n\n\nIl est parfois plus pratique d’utiliser les facettes.\n\nggplot(data = especes_pays_iucn, mapping = aes(x = Country, y = n_species)) +\n  facet_grid(IUCN ~ .) +\n  geom_col() +\n  coord_flip()\n\n\n\n\nPour perfectionner encore ce graphique, on pourrait réordonner les facettes individuellement, mais ne nous égarons par trop.\n\n\n4.8.8 Exporter un graphique\nPlus besoin d’utiliser la fonction png() en mode ggplot2. Utilisons plutôt ggsave().\n\nggplot(data = especes_pays_iucn, mapping = aes(x = Country, y = n_species)) +\n  facet_grid(IUCN ~ .) +\n  geom_col(aes(fill = IUCN)) +\n  coord_flip()\n\n\n\nggsave(\"images/especes_pays_iucn.png\", width = 6, height = 8, dpi = 300)"
  },
  {
    "objectID": "04-visualisation.html#les-graphiques-comme-outil-dexploration-des-données",
    "href": "04-visualisation.html#les-graphiques-comme-outil-dexploration-des-données",
    "title": "4  Visualisation",
    "section": "4.9 Les graphiques comme outil d’exploration des données",
    "text": "4.9 Les graphiques comme outil d’exploration des données\n\n\n\n\n\nFigure 4.9: Explorer les données avec ggplot2, dessin de @allison_horst.\n\n\n\n\nLa plupart des graphiques que vous créerez ne seront pas destinés à être publiés, mais serviront d’outil d’exploration des données. Le jeu de données datasaurus, présenté en début de chapitre, permet de saisir l’importance des outils graphiques pour bien comprendre les données.\n\ndatasaurus &lt;- read_tsv(\"data/DatasaurusDozen.tsv\")\n\nRows: 1846 Columns: 3\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \"\\t\"\nchr (1): dataset\ndbl (2): x, y\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nhead(datasaurus)\n\n# A tibble: 6 × 3\n  dataset     x     y\n  &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt;\n1 dino     55.4  97.2\n2 dino     51.5  96.0\n3 dino     46.2  94.5\n4 dino     42.8  91.4\n5 dino     40.8  88.3\n6 dino     38.7  84.9\n\n\nProjetons d’abord les coordonnées x et y sur un graphique.\n\nggplot(data = datasaurus, mapping = aes(x = x, y = y)) +\n  geom_point()\n\n\n\n\nCe graphique pourrait ressembler à une distribution binormale, ou un coup de 12 dans une porte de grange. Mais on aperçoit des données alignées, parfois de manière rectiligne, parfois en forme d’ellipse. Le tableau datasaurus a une colonne d’information supplémentaire. Utilisons-la comme catégorie pour générer des couleurs différentes.\n\nggplot(data = datasaurus, mapping = aes(x = x, y = y)) +\n  geom_point(mapping = aes(colour = dataset))\n\n\n\n\nCe n’est pas vraiment plus clair. Il y a toutefois des formes qui se dégagent, comme des ellipses et des lignes. Et si je regarde bien, j’y vois une étoile. La catégorisation pourrait-elle être mieux utilisée si on segmentait par facettes au lieu des couleurs?\n\nggplot(data = datasaurus, mapping = aes(x = x, y = y)) +\n  facet_wrap(~dataset, nrow = 2) +\n  geom_point(size = 0.5) +\n  coord_equal()\n\n\n\n\nVoilà! Fait intéressant : ni les statistiques, ni les algorithmes de regroupement ne nous auraient été utiles pour différencier les groupes!\n\n4.9.1 Des graphiques interactifs!\nLes graphiques sont traditionnellement des images statiques. Toutefois, les graphiques n’étant pas dépendants de supports papiers peuvent être utilisés de manière différente, en ajoutant une couche d’interaction. Conçue à Montréal, plotly est un module graphique interactif en soi. Il peut être utilisé grâce à son outil web, tout comme il peut être interfacé avec R, Python, javascript, etc. Mais ce qui retient notre attention ici est son interface avec ggplot2.\nLes graphiques ggplot2 peuvent être enregistrés en tant qu’objets. Il peuvent conséquemment être manipulés par des fonctions. La fonction ggplotly permet de rendre votre ggplot interactif.\n\nlibrary(\"plotly\")\n\n\nAttachement du package : 'plotly'\n\n\nL'objet suivant est masqué depuis 'package:ggplot2':\n\n    last_plot\n\n\nL'objet suivant est masqué depuis 'package:stats':\n\n    filter\n\n\nL'objet suivant est masqué depuis 'package:graphics':\n\n    layout\n\nespeces_crit_bar &lt;- ggplot(data = especes_crit, mapping = aes(x = Country, y = n_critical_species)) +\n  geom_segment(mapping = aes(xend = Country, yend = 0), lwd = 2) +\n  geom_point(size = 6) +\n  coord_flip()\nggplotly(especes_crit_bar)\n\n\n\n\n\nVous pouvez publier votre graphique plotly en ligne pour le partager ou l’inclure dans une publication web. Il vous faudra créer un compte plotly, puis générer une clé d’utilisation dans Settings &gt; API Keys &gt; Generate key. Pour des raisons de sécurité, la clé du bloc ci-dessous ne fonctionnera pas. J’ai désactivé le bloc de code, mais le résultat se trouve en suivant le lien généré par plotly: https://plot.ly/~essicolo/152/.\nSys.setenv(\"plotly_username\"=\"essicolo\")\nSys.setenv(\"plotly_api_key\"=\"iavd1ycE2iiqOp9YD45I\")\n\nchart_link &lt;- api_create(x = ggplotly(especes_crit_bar), \n                         filename = \"public-graph\",\n                         sharing = \"public\",\n                         fileopt = \"overwrite\")\nchart_link\n\n\n4.9.2 Des extensions de ggplot2\nggplot2 est un module graphique élégant et polyvalent. Il a pourtant bien des limitations. Justement, le module est conçu pour être implémenté avec des extensions. Vous en trouverez plusieurs sur exts.ggplot2.tidyverse.org, mais en trouverez de nombreuses autres en cherchant avec le terme ggplot2 sur github.com, probablement la plate-forme (voire un réseau social) de développement de logiciels la plus utilisée dans le monde. En voici quelques unes.\n\nggthemr: spécifier un thème graphique une seule fois dans votre session, et tout le reste suit.\ncowplot et patchwork permettent de créer des graphiques prêts pour la publication, par exemple en créant des grilles de plusieurs ggplots, en les numérotant, etc.\nSi les thèmes de base ne vous conviennent pas, vous en trouverez d’autres en installant ggthemes.\nggmap et ggspatial sont deux extensions pour créer des cartes. Un chapitre sur les données spatiales est en développement.\nggtern permet de créer des diagrammes ternaires, qui sont utiles pour la visualisation de proportions incluant trois composantes, par exemple pour la granulométrie des sols.\nggprism permet de personnaliser les ggplots et leur donner un aspect similaire aux graphiques du logiciel statistique prism\n\n\n\n4.9.3 Aller plus loin avec ggplot2\n\nClaus O. Wilke est professeur en biologie intégrative à l’Université du Texas à Austin. Son livre Fundamentals of Data Visualization est un guide théorique et pratique pour la visualisation de données avec ggplot2.\nLe site data-to-viz.com vous accompagne dans le choix du graphique à créer selon vos données.\nLe site r-graph-gallery.com offre des recettes pour créer des graphiques avec ggplot2.\nLe livre R Graphics Cookbook, disponible entièrement en ligne, offre aussi des recettes pour réaliser différents graphiques."
  },
  {
    "objectID": "04-visualisation.html#extra-règles-particulières",
    "href": "04-visualisation.html#extra-règles-particulières",
    "title": "4  Visualisation",
    "section": "4.10 Extra: Règles particulières",
    "text": "4.10 Extra: Règles particulières\n\nLes mauvais graphiques peuvent survenir à cause de l’ignorance, bien sûr, mais souvent ils existent pour la même raison que la boeuferie [bullhist] verbale ou écrite. Parfois, les gens ne se soucient pas de la façon dont ils présentent les données aussi longtemps que ça appuie leurs arguments et, parfois, ils ne se soucient pas que ça porte à confusion tant qu’ils ont l’air impressionnant. \\(-\\) Carl Bergstorm et Jevin West, Calling Bullshit Read-Along Week 6: Data Visualization\n\nUne représentation visuelle est un outil tranchant qui peut autant présenter un état véritable des données qu’une perspective trompeuse. Bien souvent, une ou plusieurs des 5 qualités ne sont pas respectées. Les occasions d’erreur ne manquent pas - j’en ai fait mention dans la section Choisir le bon type de graphique. Maintenant, notons quelques règles particulières.\n\n4.10.1 Ne tronquez pas inutilement l’axe des \\(y\\)\nTronquer l’axe vertical peut amener à porter de fausses conclusions.\n\n\n\n\n\nFigure 4.10: Effets sur la perception d’utiliser différentes références. Source: Yau (2015), Real Chart Rules to Follow.\n\n\n\n\n\n\n\nEffets sur la perception d’utiliser différentes références. Source: Yau (2015), Real Chart Rules to Follow.\n\n\nLa règle semble simple: les diagrammes en barre (utilisés pour représenter une grandeur) devraient toujours présenter le 0 et les diagrammes en ligne (utilisés pour présenter des tendances) ne requièrent pas nécessairement le zéro (Bergstrom et West, Calling bullshit: Misleading axes on graphs. Mais le zéro n’est pas toujours lié à une quantité particulière : par exemple, la température ou un log-ratio. De plus, avec un diagramme en ligne, on pourra toujours magnifier des tendances en zoomant sur une variation somme toute mineure. On arrive donc moins à une règle qu’une qualité d’un bon graphique, en particulier la qualité no 1 de Cairo: offrir une représentation honnête des données. Par exemple, Nathan Yau, auteur du blogue Flowing Data, propose de présenter des résultats de manière relative à la mesure initiale. C’est d’ailleurs ce qui a été fait pour générer le graphique de Michael Mann et al. au tout début de ce chapitre à la Figure 4.1, où le zéro correspond à la moyenne des températures enregistrées entre 1961 et 1990.\nIl peut être tentant de tronquer l’axe des \\(y\\) lorsque l’on désire superposer deux axes verticaux. Souvent, l’utilisation de plusieurs axes verticaux amène une perception de causalité dans des situations de fausses corrélations. On ne devrait pas utiliser plusieurs axes verticaux.\n\n\n4.10.2 Utilisez un encrage proportionnel\nCette règle a été proposée par Edward Tufte dans Visual Display of Quantitative Information. Une des raisons pour lesquelles on évite de tronquer l’axe des \\(y\\) en particulier pour les diagrammes en barre est que l’aire représentant une mesure (la quantité d’“encre” nécessaire pour la dessiner) devrait être proportionnelle à sa magnitude. Les diagrammes en barre sont particulièrement sensibles à cette règle, étant donnée que la largeur des barres peuvent amplifier l’aire occupée. Deux solutions dans ce cas: (1) utiliser des barres minces ou (2) préférer des “diagrammes de points” (dot charts, à ne pas confondre aux nuages de points).\nL’encrage a beau être proportionnel, la difficulté que les humains éprouvent à comparer la dimension des cercles, et a fortiori la dimension de parties de cercle, donne peu d’avantage à utiliser des diagrammes en pointe de tarte, souvent utilisés pour illustrer des proportions. Nathan Yau suggère de les utiliser avec suspicions et d’explorer d’autres options.\n\nPour comparer deux proportions, une avenue intéressante est le diagramme en pente, suggéré notamment par Ann K. Emery.\n\nPar extension, le diagramme en pente devient un diagramme en ligne lorsque plusieurs types de proportions sont comparées, ou lorsque des proportions évoluent selon des données continues.\nDe la même manière, les diagrammes en bulles ne devraient pas être représentatifs de la quantité, mais permettent plutôt de contextualiser des données. Justement, le graphique tiré des données de Gap minder présenté plus haut est une contextualisation: l’aire d’un cercle ne permet pas de saisir la population d’un pays, mais de comparer grossièrement la population d’un pays par rapport aux autres.\n\n\n4.10.3 Publiez vos données\nVous avez peut-être déjà feuilleté un article et voulu avoir accès aux données incluses dans un graphique. Il existe des outils pour digitaliser des graphiques pour en extraire les données. Mais le processus est fastidieux, long, souvent peu précis. De plus en plus, les chercheurs sont encouragés à publier leurs données et leurs calculs. Matplotlib et Seaborn sont des outils graphiques classiques qui devraient être accompagnés des données et calculs ayant servi à les générer. Mais ce n’est pas idéal non plus. En revanche, les outils graphiques modernes comme Plotly et Altair peuvent être exportés en code javascipt, qui contient toutes les informations sur les données et la manière de les représenter graphiquement. Ce chapitre a pour objectif de vous familiariser avec les outils de base les plus communément utilisés en calcul scientifique avec R, mais je vous encourage à explorer la nouvelle génération d’outils graphiques. Nous verrons ça au chapitre 5.\n\n\n4.10.4 Visitez Junk Charts de temps à autre\nLe statisticien et blogueur Kaiser Fung s’affaire quotidiennement à proposer des améliorations à de mauvais graphiques sur son blogue Junk Charts."
  },
  {
    "objectID": "05-github.html",
    "href": "05-github.html",
    "title": "5  Science ouverte et reproductibilité",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "06-python.html",
    "href": "06-python.html",
    "title": "6  Introduction à Python",
    "section": "",
    "text": "Il peut arriver que, pour une raison ou une autre, vous puissiez bénéficier de travailler avec Python. Par exemple, si vous travaillez en géomatique avec QGIS ou même ArcGIS, Python peut être utilisé pour faire vos manipulations de données et vos analyses spatiales. Le fonctionnement de Python ressemble assez à R et vous remarquerez qu’une fois la première barrière de programmation franchie, les langages subséquents sont beaucoup plus faciles à assimiler.\nL’auteur de ce manuel, Essi Parent, a publié l’automne dernier une introduction au calcul numérique avec Python. Pour le consulter, vous pouvez soit créer une fork sur votre github et cloner le répertoire, ou alors consulter les fichiers directement dans le navigateur. Il est possible que la présente section soit bonifiée au cours de la session, mais à première vue le répertoire de Essi semble concis et bien fait. Sinon, comme pour R, il existe plusieurs bons manuels, en anglais toutefois. Rappelez-vous que cette section est facultative; vous pourrez y revenir dans le futur lorsque le besoin se présentera!"
  },
  {
    "objectID": "07a-biostats.html",
    "href": "07a-biostats.html",
    "title": "7  Biostatistiques",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "07b-bayes.html",
    "href": "07b-bayes.html",
    "title": "8  Introduction à l’analyse bayésienne en écologie",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "08-regression.html",
    "href": "08-regression.html",
    "title": "9  Régression",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "09-explorer.html",
    "href": "09-explorer.html",
    "title": "10  Explorer R",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "10-ordination.html",
    "href": "10-ordination.html",
    "title": "11  Association, partitionnement et ordination",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "11-imputation.html",
    "href": "11-imputation.html",
    "title": "12  Détection de valeurs aberrantes et imputation de données manquantes",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "12-series-temporelles.html",
    "href": "12-series-temporelles.html",
    "title": "13  Les séries temporelles",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "13-autoapprentissage.html",
    "href": "13-autoapprentissage.html",
    "title": "14  Introduction à l’autoapprentissage",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "14-donnees-spatiales.html",
    "href": "14-donnees-spatiales.html",
    "title": "15  Les données géospatiales",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "15-modelisation.html",
    "href": "15-modelisation.html",
    "title": "16  Modélisation de mécanismes écologiques",
    "section": "",
    "text": "À venir"
  },
  {
    "objectID": "05-github.html#un-code-reproductible",
    "href": "05-github.html#un-code-reproductible",
    "title": "5  Science ouverte et reproductibilité",
    "section": "5.1 Un code reproductible",
    "text": "5.1 Un code reproductible\n\n\n\n\n\nA Guide to Reproducible Code in Ecology and Evolution, BES 2017\n\n\n\n\nLa British ecological society offre des lignes guide pour créer un flux de travail reproductible (BES, 2017). En outre, les principes suivants doivent être respectés (ma traduction, avec ajouts).\n\nCommencez votre analyse à partir d’une copie des données brutes. Les données doivent être fournies dans un format ouvert (csv, json, sqlite, etc.). Évitez de démarrer une analyse par un chiffrier électronique ou un logiciel propriétaire (qui n’est pas open source). En ce sens, démarrer avec Excel (xls ou xlsx) est à éviter, tout comme les sont les données encodées pour SPSS ou SAS.\nToute opération sur les données, que ce soit du nettoyage, des fusions, des transformations, etc. devrait être effectuée avec du code, non pas manuellement. S’il s’agit d’une erreur de frappe dans un tableau, on peut déroger à la règle. Mais s’il s’agit par exemple d’élimier des outliers, ne supprimez pas des entrées de vos données brutes. De même, n’effectuez pas de transformation de vos données brutes à l’extérieur du code. En somme, vos calculs devraient être en mesure d’être lancés d’un seul coup, sans opérations manuelles intermédiaires.\nSéparez vos opérations en unités logiques thématiques. Par exemple, vous pourriez séparer votre code en parties: (i) charger, fusionner et nettoyer les données, (ii) analyser les données, (iii) créer des fichiers comme des tableaux et des figures.\nÉliminez la duplication du code en créant des fonctions personnalisées. Assurez-vous de commenter vos fonctions en détails, expliquez ce qui est attendu comme entrées et comme sorties, ce qu’elles font et pourquoi.\nDocumentez votre code et vos données à même les feuilles de calcul ou dans un fichier de documentation séparé.\nTout fichier intermédiaire devrait être séparé de vos données brutes.\n\n\n5.1.1 Structure d’un projet\nUn projet de calcul devrait être contenu en un seul dossier. Si vous n’avez que quelques projets, il est assez facile de garder l’info en mémoire. Toutefois, en particulier en milieu d’entreprise, il se pourrait fort bien que vous ayez à mener plusieurs projets de front. Certaines entreprises créent des numéros de projet: vous aurez avantage à nommer vos dossiers avec ces numéros, incluant une brève description. Pour ma part, j’ordonne mes projets chronologiquement par année, avec un descriptif.\n📁 2019_abeille-canneberge\nNotez que je n’utilise ni espace, ni caractère spécial dans le nom du fichier, pour éviter les erreurs potentielles avec des logiciels capricieux.\nÀ l’intérieur du dossier racine du projet, j’inclus l’information générale: données source (souvent des fichiers Excel), manuscrit (mémoire, thèse, article, etc.) documentation particulière (pour les articles, j’utilise Zotero, un gestionnaire de référence), photos et, évidemment, mon dossier de code (par exemple rstats).\n\n📁 2019_abeille-canneberge\n|-📁 documentation\n|-📁 manuscrit\n|-📁 photos\n|-📁 rstats\n|-📁 source\n\nSi vous rédigez votre manuscrit à même votre code (en Latex, Lyx, markdown ou R markdown que nous verrons cela plus loin), vous pouvez très bien l’inclure dans votre fichier de calcul.\nÀ l’intérieur du fichier de calcul, vous aurez votre projet RStudio et vos feuilles de calcul séquencées. J’utilise 01-, et non pas 1- pour éviter que le 10- suive le 1- dans le classement en ordre alpha-numérique au cas où j’aurais plus de 10 feuilles de calcul. J’inclus un fichier README.md (extension md pour markdown), qui contient les informations générales de mes calculs. Les données brutes (csv) sont placées dans un dossier data, mes graphiques sont exportés dans un dossier image, mes tableaux sont exportés dans un dossier tables et mes fonctions externes sont exportées dans un dossier lib.\n\n📁 rstats\n|-📁 data\n|-📁 images\n|-📁 lib\n|-📁 tables\n📄 bees.Rproj\n📄 01_clean-data.R\n📄 02_data-mining.R\n📄 03_data-analysis.R\n📄 04_data-modeling.R\n📄 README.md\n\nJe décris les noms de fichiers dans la langue de communication utile pour le rendu final du projet, souvent en anglais lors de publications académiques. J’évite les noms de fichier qui ne sont pas informatifs, par exemple 01.R ou Rplot1.png, ainsi que les majuscules, les caractères spéciaux et les espaces comme dans Deuxième essai.R (le README.md est une exception).\nPour partager un dossier de projet sur R, on n’a qu’à le compresser (zip), puis l’envoyer. Pour que le code fonctionne sur un autre ordinateur, les liens vers les fichiers de données à importer ou les graphiques exportés doivent être relatifs au fichier R ouvert dans votre projet, non pas le chemin complet sur votre ordinateur.\n\n\n\n\n\nRetrouvez votre chemin, dessin de Allison Horst\n\n\n\n\nTout comme la BSE, l’organisme sans but lucratif rOpenSci offre un guide sur la reproductibilité.\n\n\n5.1.2 Le format R markdown\nUn code reproductible est un code bien décrit. La structure de projet présentée précédemment propose de segmenter le code en plusieurs fichiers R. Cette manière de procéder est optionnelle. Si le fichier de calcul n’est pas trop encombrant, on pourra n’en utiliser qu’un seul, par exemple stats.R. À l’intérieur même des feuilles de calcul R, vous devrez commenter votre code pour en expliquer les étapes, par exemple:\n#############\n## Titre 1 ##\n#############\n\n# Titre 2\n## Titre 3\ndata &lt;- read_csv(\"data/abeilles.csv\") # commentaire particulier\n\nRStudio a développé une approche plus conviviale avec son format R markdown. Le langage markdown permet de formater un texte avec un minimum de décorations, et R markdown permet d’intégrer du texte et des codes. Ces notes de cours sont par ailleurs entièrement écrites en R markdown.\n\n\n\n\n\nLa magie de R markdown, dessin de Allison Horst\n\n\n\n\n\n5.1.2.1 Le langage markdown\nUn fichier portant l’extension .md ou .markdown est un fichier texte clair (que vous pouvez ouvrir et éditer dans n’importe votre éditeur texte préféré), tout comme un fichier .R. Il existe néanmoins de nombreux éditeurs de texte spécialisés en édition markdown - mon préféré est Typora. Les décorations principales en markdown sont les suivantes (les citations utilisées ci-après sont tirées du roman Dune, de Frank Herbert).\nItalique. Pour emphaser en italique, balisez le texte avec des astérisques. Par exemple, “Pourrais-je porter parmi vous le nom de *Paul-Muad'dib*?” devient “Pourrais-je porter parmi vous le nom de Paul-Muad’dib?”\nGras. Pour emphaser en gras, balisez le texte avec des doubles astérisques. Par exemple, “L'espérance **ternit** l'observation.” devient “L’espérance ternit l’observation”.\nLargeur fixe. Pour un texte à largeur fixe (signifiant du code), balisez le texte avec des accents graves. Par exemple, “Quel nom donnez-vous à la petite `souris`, celle qui saute ?” devient “Quel nom donnez-vous à la petite souris, celle qui saute?”\nListes. Pour effectuer une liste numérotée, utilisez le chiffre 1. Par exemple,\n\n1. Paul\n1. Leto\n1. Alia\n\ndevient\n\nPaul\nJessica\nAlia\n\nDe même, pour une liste à puces, changez le 1. par le - ou le *.\nEntêtes. Les titres sont précédés par des #. Un # pour un titre 1, deux ## pour un titre 2, etc. Par exemple,\n\n# Imperium\n## Landsraad\n### Maison des Atréides\n### Maison des Harkonnen\n## CHOAM\n# Guilde des navigateurs\n\nInsérera les titres appropriés (que je n’insère pas pour ne pas bousiller la structure de ce texte).\nLiens. Pour insérer des liens, le texte est entre crochet directement suivi du lien entre parenthèses. Par exemple, “Longue vie aux [combattants](https://youtu.be/Cv87NJ2xX0k?t=59)” devient “Longue vie aux combattants”.\nÉquations. Les équations suivent la syntaxe Latex entre deux $$ pour les équations sur une ligne et entre des doubles $$$$ pour les équations sur un paragraphe. Par exemple, $c = \\sqrt{a^2 + b^2}$ devient \\(c = \\sqrt{a^2 + b^2}\\).\nImages. Pour insérer une image, ![nom de l'image](images/spice-must-flow.png).\nUne liste exhaustive des balises markdown est disponible sous forme d’aide-mémoire. L’extension de RStudio remedy, installable tout comme un module, fera apparaître une section REMEDY dans le menu Addins, où vous trouverez toutes sortes d’options de formatage automatique (figure @ref(fig:git-remedy)).\n\n\n\n\n\nMenu des extensions de RStudio, avec l’extension remedy\n\n\n\n\n\n\n5.1.2.2 R markdown\nDans RStudio, ouvrez un R markdown par File &gt; New file &gt; R Markdown. Si le module rmarkdown n’est pas installé, RStudio vous demandera de l’installer. Une fenêtre apparaîtra.\n\n\n\n\n\nNouveau fichier R markdown\n\n\n\n\nLes options d’exportation pourront être modifiées par la suite.\nUn fichier d’exemple sera créé, et vous pourrez le modifier. Les parties de texte sont écrits en markdown, et le code R est enchâssé entre les balises ```{r} et ```. Je nommerai ces parties de code des cellules de code.\nDes options de code l’intérieur peuvent être utilisées à l’intérieur des accolades {r}. Par exemple\n\n{r, filtre-outliers} donne le nom filtre-outliers au bloc de code, qui permet nommément de nommer les images créer dans le bloc de code.\n{r, eval = FALSE} permet d’activer (TRUE, valeur par défaut) ou de désactiver (FALSE) le calcul de la cellule.\n{r, echo = FALSE} permet de n’afficher que la sortie de la cellule de code en n’affichant pas le code, par exemple un graphique ou le sommaire d’une régression.\n{r, results = FALSE} permet de n’afficher que le code, mais pas la sortie.\n{r, warning = FALSE, message = FALSE, error = FALSE} n’affichera pas les avertissements, les messages automatiques et les messages d’erreur.\n{r, fig.width = 10, fig.height = 5, fig.align = \"center\"} affichera les graphiques dans les dimensions voulues, alignée au centre (\"center\"), à gauche (\"left\") ou à droite (\"right\").\n\nNotez que vous pouvez exécuter rapidement du code sur une ligne avec la formulation `r `, par exemple la moyenne des nombres `\\r a&lt;-round(runif(4, 0, 10)); a` est de `\\r mean(a)`, en enlevant les \\ devant les r (ajoutées artificiellement pour éviter que le code soit calculé) sera la moyenne des nombres 7, 2, 2, 8 est de 4.75\nUne fois que vous serez satisfait de votre document, cliquer sur Knit  et le fichier de sortie sera généré. Le guide qui permet de générer le fichier de sortie est tout en haut du fichier. Nous l’appelons le YAML (acronyme récursif de YAML Ain’t Markup Language). Prenez le YAML suivant.\n---\ntitle: \"Dune\"\nauthor: \"Frank Herbert\"\ndate: \"1965-08-01\"\noutput: github_document\n---\nLe titre, l’auteur et la date sont spécifiées. Pour indiquer la date courante, on peut simplement la générer avec R en remplaçant \"1965-08-01\" par 2024-01-23. La spécification output indique le type de document à générer, par exemple html_document pour une page web, pdf_document pour un pdf, ou word_document pour un docx. Dans ce cas-ci, j’indique github_document pour créer un fichier markdown comprenant nommément des liens relatifs vers les images des graphiques générés. Pourquoi un github_document? C’est le sujet de la prochaine sous-section. Mais avant cela, je vous réfère à un autre aide-mémoire.\n\n\n\n\n\nAide-mémoire pour R Markdown, Source: RStudio"
  },
  {
    "objectID": "05-github.html#introduction-à-github",
    "href": "05-github.html#introduction-à-github",
    "title": "5  Science ouverte et reproductibilité",
    "section": "5.2 Introduction à GitHub",
    "text": "5.2 Introduction à GitHub\nLe system de suivi de version git (open source) a été créé par Linus Torvalds, aussi connu pour avoir créé Linux. git prend une photo de votre répertoire de projet à chaque fois que vous commettez un changement. Vous pourrez revenir sans problème sur d’anciennes versions si quelque chose tourne mal, et vous pourrez publier le résultat final sur un service d’hébergement utilisant git.\nIl existe plusieurs services pour rendre git utilisable en ligne, mais GitHub est définitivement le plus utilisé d’entre tous. La plateforme GitHub est presque devenue un réseau social de développement. GitHub, maintenant la propriété de Microsoft, n’est en soi pas open source. Si comme moi vous avez un penchant pour l’open source, je vous redirige vers la plateforme GitLab, qui fonctionne à peu près de la même manière que GitHub, mais dans sa version gratuite GitLab vous octroie autant de répertoires privés que vous désirez. Seul hic, alors que la plateforme GitHub sera fort probablement toujours vivante dans plusieurs années, on en est moins sûr pour GitLab. C’est pourquoi, en règle générale, j’utilise GitHub à des fins professionnelles mais GitLab à des fins personnelles.\nPour suivre cette partie du cours, je vous invite à créer un compte sur GitHub ou GitLab, à votre choix. Créez un nouveau dépôt (New repository).\n\n\n\n\n\nNouveau dépôt avec GitHub\n\n\n\n\n\n\n\n\n\nNouveau dépôt avec GitLab\n\n\n\n\nPour utiliser git, vous pourrez toujours travailler en ligne de commande, mais je vous suggère d’utiliser GitHub Desktop (qui fonctionne aussi sur GitLab) - évidemment, d’autres logiciels similaires existent. Github Desktop vous permettra d’abord de cloner un répertoire en ligne. Le clonage vous permet de créer une copie locale (sur votre ordinateur) du répertoire.\n\n\n\n\n\nCloner dépôt avec GitHub\n\n\n\n\n\n\n\n\n\nCloner dépôt avec GitLab\n\n\n\n\nUne fois que le dépôt est cloné, il est sur votre ordinateur. Lorsque vous effectuez un changement, vous devez commettre (commit), puis envoyer (push) vos changements vers le dépôt en ligne. Pour que votre document markdown soit lisible par GitHub et GitLab, il doit être exporté sous forme de github_document. Un fichier .md sera créé, et inclura les détails de votre feuille de calculs, images y compris!\n\n\n\n\n\nCommettre et déployer un dépôt avec GitHub\n\n\n\n\nL’interface de GitHub Desktop vous permet de revenir en arrière en éliminant des commits précédents.\n\n\n\n\n\nRevenir en arrière avec GitHub desktop\n\n\n\n\nVous pourrez ajouter des collaborateurs à votre dépôt, pour que plusieurs personnes travaillent de front sur un même dépôt. Il est aussi possible de créer une branche d’un dépôt, fusionner la branche de développement avec la branche principale, commenter les codes, suggérer des changements, etc., mais cela sort du cadre d’un cours sur la reproductibilité.\nEnfin, pour renvoyer un article vers votre matériel supplémentaire, insérez le lien dans la section méthodologie. Il peut s’agit du lien complet, ou bien d’un lien raccourci avec git.io. Par exemple,\n\nThe data and the R code used to compute the results are both available as supplementary material at https://git.io/fhHEj.\n\nNotez que RStudio offre une interface pour utiliser git via un onglet afiché en haut à droite dans l’affichage par défaut. Ne l’ayant jamais utilisé, et je ne me sens pas à l’aise d’en suggérer l’utilisation, mais libre à vous d’explorer cet outil et de vous l’approprier!\n\n\n\n\n\nL’outil Git de RStudio"
  },
  {
    "objectID": "05-github.html#introduction-à-pakrat",
    "href": "05-github.html#introduction-à-pakrat",
    "title": "5  Science ouverte et reproductibilité",
    "section": "5.3 Introduction à Pakrat 📦🐀",
    "text": "5.3 Introduction à Pakrat 📦🐀\nAlors que les modules sont continuellement mis à jour, on doit s’assurer que l’on sache exactement quelle version a été utilisée si l’on désire être stricte sur la reproductibilité. Lorsque je révise un article, je demande à ce que le nom des modules utilisés et leur numéro de version soient explicitement cités et référencés. Par exemple, dans un article sur l’analyse de compositions foliaires de laitues inoculées par une bactérie, j’écrivais:\n\nComputations were performed in the R statistical language version 3.4.1 (R Development Core Team, 2017). The main packages used in the data analysis workflow were the vegan package version 2.4-3 (Oksanen et al., 2017) for ordination, the compositions package version 1.40-1 (van den Boogaart and Tolosana-Delgado, 2013) for ilr transformations, the nlme version 3.1-131 (Pinheiro et al., 2017) package to compute the random experimental effect, the mvoutlier package version 2.0.8 (Filzmoser and Gschwandtner, 2017) for multivariate outlier detection, and the ggplot2 package version 2.2.1 (Wickham and Chang, 2017) for data visualization. The data and computations are publicly available at https://github.com/essicolo/Nicolas-et-al_Infected-lettuce-ionomics. Nicolas et al., 2019\n\nDe cette manière, une personne (que ce soit vos collègues, quiconque voudra auditer ou évaluer votre code ou vous-même dans le futur) pourra reproduire le code publié sur GitHub en installant les versions de R et des modules cités. Mais cela est fastidieux. C’est pourquoi l’équipe de RStudio (oui, encore ceux-là) ont développé le module packrat, qui permet d’installer les modules à même voter dossier de projet (le dossier contenant le fichier .Rproj).\nPour l’utiliser à tout moment en cours de projet,\n\n\n\n\n\nL’outil Packrat de RStudio\n\n\n\n\nLe .gitignore contient tous les documents et les types de documents qui sont ignorés par git. L’option par défaut est d’ignorer le dossier lib, qui contient les modules installés, mais de garder le dossier src, qui contient la source des modules non installés (qui devront être installés par les autres personnes utilisant votre projet). Mieux vaut garder les options par défaut. Initialiser Packrat revient à scanner vos documents de projet pour trouver les modules utilisés et créer un paquet contenant tout cela à même votre projet, dans un dossier packrat.\n\n📁 rstats\n|-📁 data\n|-📁 images\n|-📁 lib\n|-📁 packrat\n|-📁 tables\n📄 sentier-d-or.Rproj\n📄 stats.Rmd\n📄 README.md\n\nCe dossier contiendra tout ce qu’il faut pour utiliser les modules du projet d’une personne que l’on nommera Leto. Lorsqu’une autre personne, appellons-la Ghanima, utilisera le projet de Leto, RStudio vérifiera si le module packrat est bien installé, et l’installera s’il ne l’est pas (Leto et Ghanima sont deux personnage de la série de science-fiction Dune). Pour utiliser les modules du projet et non pas les modules de son ordinateur, Ghanima lancera la fonction packrat::restore(). Si Leto décide de mettre à jour ses modules en cours de projet, il lancera la fonction packrat::snapshot() pour que ces nouveaux modules soit intégrés à son projet. Lorsque Leto commettra (commit) ses changements dans git et les publiera (push) sur GitHub, puis lorsque Ghanima mettra à jour (fetch) son dépôt local git lié au dépôt GitHub, elle devra à nouveau lancer packrat::restore() pour que les modules soient bel et bien ceux utilisés par Leto."
  },
  {
    "objectID": "05-github.html#pour-terminer-le-reprex",
    "href": "05-github.html#pour-terminer-le-reprex",
    "title": "5  Science ouverte et reproductibilité",
    "section": "5.4 Pour terminer, le reprex",
    "text": "5.4 Pour terminer, le reprex\nLorsque j’ai découvert un bogue dans le module weathercan, j’ai ouvert une issue sur GitHub en indiquant le message d’erreur obtenu, en espérant que l’origine du bogue puisse être facilement déduit. Un développeur de weathercan m’a demandé un reprex. J’ai été déçu lorsque j’ai compris que le reprex n’était pas une espèce de dinosaure, mais plutôt un exemple reproductible (reproducible example).\n\n📗 Reprex: Un exemple reproductible.\n\nJ’ai essayé d’isoler le problème pour reproduire l’erreur avec le minimum de code possible. À partir d’un code de plus de 7000 lignes (les présentes notes de cours), j’en suis arrivé à ceci:\n\nstations &lt;- data.frame(A = 1)\n\nlibrary(\"weathercan\")\nmont_bellevue &lt;- weather_dl(\n  station_ids = c(5397, 48371),\n  start = \"2019-02-01\",\n  end = \"2019-02-07\",\n  interval = \"hour\",\n  verbose = TRUE\n)\n\n, qui me retournait l’erreur\nGetting station: 5397\nFormatting station data: 5397\nError in strptime(xx, f, tz = tz) : valeur 'tz' incorrecte\nLe bogue: la fonction weather_dl() utilisait à l’interne un objet nommé stations, qui entrait en conflit avec un objet stations s’il était défini hors de la fonction.\nSynthétiser une question n’est pas facile (créer cet exemple reprductible m’a pris près de 2 heures). Mais répondre à une question non synthétisée, c’est encore plus difficile. C’est pourquoi on (moi y compris) vous demandera systématiquement un reprex lorsque vous poserez une question liée à une erreur systématique, le plus souvent en programmation.\n\nUn exemple reproductible permet à quelqu’un de recréer l’erreur que vous avez obtenue simplement en copiant-collant votre code. - Hadley Wickham\n\nSelon Hadley Wickham (gourou de R), un reprex devrait comprendre quatre éléments (je joue à l’hérétique en me permettant d’adapter le document du gourou):\n\nLes modules devraient être chargés en début de code.\nPuis vous chargez des données, qui peuvent être des données d’exemple ou des données incluses à même le code R (comme des données générées au hasard).\nAssurez-vous que voter code est un exemple minimal (retirer le superflu) et qu’il soit facilement lisible.\nIncluez la sortie de la fonction sessionInfo(), qui indique la plateforme matérielle et logicielle sur laquelle vous avez généré l’erreur. Ceci est important en particulier s’il s’agit d’un bogue.\n\nLorsque vous pensez avoir généré votre reprex, redémarrez R (Session &gt; Restart R dans RStudio), puis lancez votre code pour vous assurer que l’erreur puisse être générée dans un nouvel environnement tout propre."
  }
]